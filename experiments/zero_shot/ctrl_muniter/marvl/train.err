WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

12/02/2021 15:15:11 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
12/02/2021 15:15:11 - INFO - volta.task_utils -   Loading NLVR2 Dataset with batch size 32
12/02/2021 15:15:11 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/iglue/marvl/ctrl_muniter_base/NLVR2_ctrl_muniter_base
12/02/2021 15:15:12 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/iglue/pretrain/ctrl_muniter/ctrl_muniter_base/pytorch_model_9.bin
12/02/2021 15:15:22 - INFO - volta.utils -   
12/02/2021 15:15:22 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['bert.embeddings.image_token_type_embeddings.weight', 'clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
12/02/2021 15:15:22 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
12/02/2021 15:15:31 - INFO - __main__ -   ** ** * Saving model * ** ** 
/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
12/02/2021 15:15:39 - INFO - __main__ -   >> Parameters:
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |Name                                                       |Dtype            |Shape            |#Params     |Trainable|
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.word_embeddings.weight                     |torch.float32    |(119547, 768)    |91812096    |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.position_embeddings.weight                 |torch.float32    |(512, 768)       |393216      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.token_type_embeddings.weight               |torch.float32    |(2, 768)         |1536        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)         |3840        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768         |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.t_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.t_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.v_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432      |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |bert.v_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.weight                         |torch.float32    |(1536, 2048)     |3145728     |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.bias                           |torch.float32    |(1536,)          |1536        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.weight                         |torch.float32    |(1536,)          |1536        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.bias                           |torch.float32    |(1536,)          |1536        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.weight                         |torch.float32    |(2, 1536)        |3072        |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.bias                           |torch.float32    |(2,)             |2           |True    |
12/02/2021 15:15:39 - INFO - __main__ -   -----------------------------------------------------------------------------------------------------------------------
12/02/2021 15:15:39 - INFO - __main__ -   >> # TrainableParams:       	183.57	M
12/02/2021 15:15:39 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
12/02/2021 15:15:39 - INFO - __main__ -   >> # TotalParams:           	183.57	M
Epoch:   0%|          | 0/20 [00:00<?, ?it/s]/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
12/02/2021 15:16:01 - INFO - volta.train_utils -   [NLVR2]: iter 40 Ep: 0.01 loss 0.216 score 0.247 lr 1.94516e-08 
12/02/2021 15:16:22 - INFO - volta.train_utils -   [NLVR2]: iter 80 Ep: 0.03 loss 0.217 score 0.243 lr 5.65024e-08 
12/02/2021 15:16:43 - INFO - volta.train_utils -   [NLVR2]: iter 120 Ep: 0.04 loss 0.212 score 0.254 lr 9.35532e-08 
12/02/2021 15:17:04 - INFO - volta.train_utils -   [NLVR2]: iter 160 Ep: 0.06 loss 0.208 score 0.257 lr 1.30604e-07 
12/02/2021 15:17:26 - INFO - volta.train_utils -   [NLVR2]: iter 200 Ep: 0.07 loss 0.201 score 0.254 lr 1.67655e-07 
12/02/2021 15:17:47 - INFO - volta.train_utils -   [NLVR2]: iter 240 Ep: 0.09 loss 0.199 score 0.235 lr 2.04705e-07 
12/02/2021 15:18:09 - INFO - volta.train_utils -   [NLVR2]: iter 280 Ep: 0.10 loss 0.187 score 0.257 lr 2.41756e-07 
12/02/2021 15:18:30 - INFO - volta.train_utils -   [NLVR2]: iter 320 Ep: 0.12 loss 0.185 score 0.243 lr 2.78807e-07 
12/02/2021 15:18:52 - INFO - volta.train_utils -   [NLVR2]: iter 360 Ep: 0.13 loss 0.178 score 0.267 lr 3.15858e-07 
12/02/2021 15:19:13 - INFO - volta.train_utils -   [NLVR2]: iter 400 Ep: 0.15 loss 0.177 score 0.268 lr 3.52908e-07 
12/02/2021 15:19:35 - INFO - volta.train_utils -   [NLVR2]: iter 440 Ep: 0.16 loss 0.176 score 0.255 lr 3.89959e-07 
12/02/2021 15:19:56 - INFO - volta.train_utils -   [NLVR2]: iter 480 Ep: 0.18 loss 0.174 score 0.267 lr 4.2701e-07 
12/02/2021 15:20:17 - INFO - volta.train_utils -   [NLVR2]: iter 520 Ep: 0.19 loss 0.178 score 0.252 lr 4.64061e-07 
12/02/2021 15:20:39 - INFO - volta.train_utils -   [NLVR2]: iter 560 Ep: 0.21 loss 0.176 score 0.271 lr 5.01112e-07 
12/02/2021 15:21:00 - INFO - volta.train_utils -   [NLVR2]: iter 600 Ep: 0.22 loss 0.174 score 0.267 lr 5.38162e-07 
12/02/2021 15:21:22 - INFO - volta.train_utils -   [NLVR2]: iter 640 Ep: 0.24 loss 0.174 score 0.266 lr 5.75213e-07 
12/02/2021 15:21:43 - INFO - volta.train_utils -   [NLVR2]: iter 680 Ep: 0.25 loss 0.173 score 0.285 lr 6.12264e-07 
12/02/2021 15:22:05 - INFO - volta.train_utils -   [NLVR2]: iter 720 Ep: 0.27 loss 0.174 score 0.271 lr 6.49315e-07 
12/02/2021 15:22:26 - INFO - volta.train_utils -   [NLVR2]: iter 760 Ep: 0.28 loss 0.173 score 0.278 lr 6.86365e-07 
12/02/2021 15:22:47 - INFO - volta.train_utils -   [NLVR2]: iter 800 Ep: 0.30 loss 0.174 score 0.274 lr 7.23416e-07 
12/02/2021 15:23:09 - INFO - volta.train_utils -   [NLVR2]: iter 840 Ep: 0.31 loss 0.171 score 0.273 lr 7.60467e-07 
12/02/2021 15:23:30 - INFO - volta.train_utils -   [NLVR2]: iter 880 Ep: 0.33 loss 0.173 score 0.278 lr 7.97518e-07 
12/02/2021 15:23:52 - INFO - volta.train_utils -   [NLVR2]: iter 920 Ep: 0.34 loss 0.176 score 0.275 lr 8.34568e-07 
12/02/2021 15:24:13 - INFO - volta.train_utils -   [NLVR2]: iter 960 Ep: 0.36 loss 0.171 score 0.276 lr 8.71619e-07 
12/02/2021 15:24:35 - INFO - volta.train_utils -   [NLVR2]: iter 1000 Ep: 0.37 loss 0.170 score 0.286 lr 9.0867e-07 
12/02/2021 15:24:56 - INFO - volta.train_utils -   [NLVR2]: iter 1040 Ep: 0.39 loss 0.173 score 0.279 lr 9.45721e-07 
12/02/2021 15:25:18 - INFO - volta.train_utils -   [NLVR2]: iter 1080 Ep: 0.40 loss 0.171 score 0.286 lr 9.82771e-07 
12/02/2021 15:25:39 - INFO - volta.train_utils -   [NLVR2]: iter 1120 Ep: 0.41 loss 0.169 score 0.281 lr 1.01982e-06 
12/02/2021 15:26:01 - INFO - volta.train_utils -   [NLVR2]: iter 1160 Ep: 0.43 loss 0.173 score 0.282 lr 1.05687e-06 
12/02/2021 15:26:23 - INFO - volta.train_utils -   [NLVR2]: iter 1200 Ep: 0.44 loss 0.172 score 0.277 lr 1.09392e-06 
12/02/2021 15:26:44 - INFO - volta.train_utils -   [NLVR2]: iter 1240 Ep: 0.46 loss 0.168 score 0.290 lr 1.13097e-06 
12/02/2021 15:27:07 - INFO - volta.train_utils -   [NLVR2]: iter 1280 Ep: 0.47 loss 0.166 score 0.294 lr 1.16803e-06 
12/02/2021 15:27:28 - INFO - volta.train_utils -   [NLVR2]: iter 1320 Ep: 0.49 loss 0.165 score 0.286 lr 1.20508e-06 
12/02/2021 15:27:50 - INFO - volta.train_utils -   [NLVR2]: iter 1360 Ep: 0.50 loss 0.168 score 0.287 lr 1.24213e-06 
12/02/2021 15:28:11 - INFO - volta.train_utils -   [NLVR2]: iter 1400 Ep: 0.52 loss 0.170 score 0.295 lr 1.27918e-06 
12/02/2021 15:28:33 - INFO - volta.train_utils -   [NLVR2]: iter 1440 Ep: 0.53 loss 0.169 score 0.297 lr 1.31623e-06 
12/02/2021 15:28:54 - INFO - volta.train_utils -   [NLVR2]: iter 1480 Ep: 0.55 loss 0.170 score 0.286 lr 1.35328e-06 
12/02/2021 15:29:16 - INFO - volta.train_utils -   [NLVR2]: iter 1520 Ep: 0.56 loss 0.168 score 0.295 lr 1.39033e-06 
12/02/2021 15:29:37 - INFO - volta.train_utils -   [NLVR2]: iter 1560 Ep: 0.58 loss 0.166 score 0.295 lr 1.42738e-06 
12/02/2021 15:29:59 - INFO - volta.train_utils -   [NLVR2]: iter 1600 Ep: 0.59 loss 0.167 score 0.294 lr 1.46443e-06 
12/02/2021 15:30:20 - INFO - volta.train_utils -   [NLVR2]: iter 1640 Ep: 0.61 loss 0.163 score 0.300 lr 1.50148e-06 
12/02/2021 15:30:42 - INFO - volta.train_utils -   [NLVR2]: iter 1680 Ep: 0.62 loss 0.162 score 0.306 lr 1.53853e-06 
12/02/2021 15:31:03 - INFO - volta.train_utils -   [NLVR2]: iter 1720 Ep: 0.64 loss 0.164 score 0.295 lr 1.57558e-06 
12/02/2021 15:31:25 - INFO - volta.train_utils -   [NLVR2]: iter 1760 Ep: 0.65 loss 0.167 score 0.297 lr 1.61263e-06 
12/02/2021 15:31:46 - INFO - volta.train_utils -   [NLVR2]: iter 1800 Ep: 0.67 loss 0.173 score 0.277 lr 1.64969e-06 
12/02/2021 15:32:07 - INFO - volta.train_utils -   [NLVR2]: iter 1840 Ep: 0.68 loss 0.165 score 0.292 lr 1.68674e-06 
12/02/2021 15:32:29 - INFO - volta.train_utils -   [NLVR2]: iter 1880 Ep: 0.70 loss 0.164 score 0.295 lr 1.72379e-06 
12/02/2021 15:32:50 - INFO - volta.train_utils -   [NLVR2]: iter 1920 Ep: 0.71 loss 0.167 score 0.293 lr 1.76084e-06 
12/02/2021 15:33:12 - INFO - volta.train_utils -   [NLVR2]: iter 1960 Ep: 0.73 loss 0.164 score 0.294 lr 1.79789e-06 
12/02/2021 15:33:34 - INFO - volta.train_utils -   [NLVR2]: iter 2000 Ep: 0.74 loss 0.166 score 0.298 lr 1.83494e-06 
12/02/2021 15:33:56 - INFO - volta.train_utils -   [NLVR2]: iter 2040 Ep: 0.76 loss 0.165 score 0.285 lr 1.87199e-06 
12/02/2021 15:34:17 - INFO - volta.train_utils -   [NLVR2]: iter 2080 Ep: 0.77 loss 0.163 score 0.304 lr 1.90904e-06 
12/02/2021 15:34:39 - INFO - volta.train_utils -   [NLVR2]: iter 2120 Ep: 0.79 loss 0.162 score 0.306 lr 1.94609e-06 
12/02/2021 15:35:00 - INFO - volta.train_utils -   [NLVR2]: iter 2160 Ep: 0.80 loss 0.165 score 0.301 lr 1.98314e-06 
12/02/2021 15:35:22 - INFO - volta.train_utils -   [NLVR2]: iter 2200 Ep: 0.82 loss 0.163 score 0.311 lr 2.02019e-06 
12/02/2021 15:35:43 - INFO - volta.train_utils -   [NLVR2]: iter 2240 Ep: 0.83 loss 0.166 score 0.297 lr 2.05724e-06 
12/02/2021 15:36:05 - INFO - volta.train_utils -   [NLVR2]: iter 2280 Ep: 0.84 loss 0.163 score 0.310 lr 2.09429e-06 
12/02/2021 15:36:26 - INFO - volta.train_utils -   [NLVR2]: iter 2320 Ep: 0.86 loss 0.163 score 0.311 lr 2.13134e-06 
12/02/2021 15:36:48 - INFO - volta.train_utils -   [NLVR2]: iter 2360 Ep: 0.87 loss 0.161 score 0.311 lr 2.1684e-06 
12/02/2021 15:37:09 - INFO - volta.train_utils -   [NLVR2]: iter 2400 Ep: 0.89 loss 0.158 score 0.318 lr 2.20545e-06 
12/02/2021 15:37:31 - INFO - volta.train_utils -   [NLVR2]: iter 2440 Ep: 0.90 loss 0.164 score 0.303 lr 2.2425e-06 
12/02/2021 15:37:52 - INFO - volta.train_utils -   [NLVR2]: iter 2480 Ep: 0.92 loss 0.163 score 0.300 lr 2.27955e-06 
12/02/2021 15:38:14 - INFO - volta.train_utils -   [NLVR2]: iter 2520 Ep: 0.93 loss 0.171 score 0.296 lr 2.3166e-06 
12/02/2021 15:38:35 - INFO - volta.train_utils -   [NLVR2]: iter 2560 Ep: 0.95 loss 0.163 score 0.308 lr 2.35365e-06 
12/02/2021 15:38:57 - INFO - volta.train_utils -   [NLVR2]: iter 2600 Ep: 0.96 loss 0.161 score 0.316 lr 2.3907e-06 
12/02/2021 15:39:18 - INFO - volta.train_utils -   [NLVR2]: iter 2640 Ep: 0.98 loss 0.159 score 0.314 lr 2.42775e-06 
12/02/2021 15:39:39 - INFO - volta.train_utils -   [NLVR2]: iter 2680 Ep: 0.99 loss 0.158 score 0.316 lr 2.4648e-06 
12/02/2021 15:40:35 - INFO - volta.train_utils -   Eval task TASK12 on iteration 2698 
12/02/2021 15:40:35 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.638 score 62.815 
12/02/2021 15:40:35 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:   5%|         | 1/20 [25:15<8:00:02, 1515.90s/it]12/02/2021 15:41:17 - INFO - volta.train_utils -   [NLVR2]: iter 2738 Ep: 1.01 loss 0.158 score 0.321 lr 2.51019e-06 
12/02/2021 15:41:38 - INFO - volta.train_utils -   [NLVR2]: iter 2778 Ep: 1.03 loss 0.162 score 0.297 lr 2.55558e-06 
12/02/2021 15:41:59 - INFO - volta.train_utils -   [NLVR2]: iter 2818 Ep: 1.04 loss 0.157 score 0.303 lr 2.59263e-06 
12/02/2021 15:42:21 - INFO - volta.train_utils -   [NLVR2]: iter 2858 Ep: 1.06 loss 0.164 score 0.311 lr 2.62968e-06 
12/02/2021 15:42:42 - INFO - volta.train_utils -   [NLVR2]: iter 2898 Ep: 1.07 loss 0.157 score 0.316 lr 2.66673e-06 
12/02/2021 15:43:04 - INFO - volta.train_utils -   [NLVR2]: iter 2938 Ep: 1.09 loss 0.159 score 0.314 lr 2.70378e-06 
12/02/2021 15:43:25 - INFO - volta.train_utils -   [NLVR2]: iter 2978 Ep: 1.10 loss 0.168 score 0.302 lr 2.74083e-06 
12/02/2021 15:43:47 - INFO - volta.train_utils -   [NLVR2]: iter 3018 Ep: 1.12 loss 0.162 score 0.307 lr 2.77788e-06 
12/02/2021 15:44:09 - INFO - volta.train_utils -   [NLVR2]: iter 3058 Ep: 1.13 loss 0.158 score 0.302 lr 2.81493e-06 
12/02/2021 15:44:30 - INFO - volta.train_utils -   [NLVR2]: iter 3098 Ep: 1.15 loss 0.157 score 0.321 lr 2.85198e-06 
12/02/2021 15:44:52 - INFO - volta.train_utils -   [NLVR2]: iter 3138 Ep: 1.16 loss 0.164 score 0.300 lr 2.88903e-06 
12/02/2021 15:45:13 - INFO - volta.train_utils -   [NLVR2]: iter 3178 Ep: 1.18 loss 0.159 score 0.309 lr 2.92608e-06 
12/02/2021 15:45:35 - INFO - volta.train_utils -   [NLVR2]: iter 3218 Ep: 1.19 loss 0.156 score 0.308 lr 2.96313e-06 
12/02/2021 15:45:56 - INFO - volta.train_utils -   [NLVR2]: iter 3258 Ep: 1.21 loss 0.162 score 0.301 lr 3.00019e-06 
12/02/2021 15:46:18 - INFO - volta.train_utils -   [NLVR2]: iter 3298 Ep: 1.22 loss 0.161 score 0.311 lr 3.03724e-06 
12/02/2021 15:46:39 - INFO - volta.train_utils -   [NLVR2]: iter 3338 Ep: 1.24 loss 0.159 score 0.314 lr 3.07429e-06 
12/02/2021 15:47:01 - INFO - volta.train_utils -   [NLVR2]: iter 3378 Ep: 1.25 loss 0.162 score 0.305 lr 3.11134e-06 
12/02/2021 15:47:23 - INFO - volta.train_utils -   [NLVR2]: iter 3418 Ep: 1.27 loss 0.158 score 0.305 lr 3.14839e-06 
12/02/2021 15:47:44 - INFO - volta.train_utils -   [NLVR2]: iter 3458 Ep: 1.28 loss 0.156 score 0.317 lr 3.18544e-06 
12/02/2021 15:48:06 - INFO - volta.train_utils -   [NLVR2]: iter 3498 Ep: 1.30 loss 0.157 score 0.324 lr 3.22249e-06 
12/02/2021 15:48:27 - INFO - volta.train_utils -   [NLVR2]: iter 3538 Ep: 1.31 loss 0.156 score 0.321 lr 3.25954e-06 
12/02/2021 15:48:48 - INFO - volta.train_utils -   [NLVR2]: iter 3578 Ep: 1.33 loss 0.160 score 0.309 lr 3.29659e-06 
12/02/2021 15:49:10 - INFO - volta.train_utils -   [NLVR2]: iter 3618 Ep: 1.34 loss 0.157 score 0.318 lr 3.33364e-06 
12/02/2021 15:49:32 - INFO - volta.train_utils -   [NLVR2]: iter 3658 Ep: 1.36 loss 0.157 score 0.318 lr 3.37069e-06 
12/02/2021 15:49:53 - INFO - volta.train_utils -   [NLVR2]: iter 3698 Ep: 1.37 loss 0.150 score 0.332 lr 3.40774e-06 
12/02/2021 15:50:15 - INFO - volta.train_utils -   [NLVR2]: iter 3738 Ep: 1.38 loss 0.159 score 0.314 lr 3.44479e-06 
12/02/2021 15:50:37 - INFO - volta.train_utils -   [NLVR2]: iter 3778 Ep: 1.40 loss 0.154 score 0.323 lr 3.48185e-06 
12/02/2021 15:50:58 - INFO - volta.train_utils -   [NLVR2]: iter 3818 Ep: 1.41 loss 0.158 score 0.309 lr 3.5189e-06 
12/02/2021 15:51:20 - INFO - volta.train_utils -   [NLVR2]: iter 3858 Ep: 1.43 loss 0.151 score 0.330 lr 3.55595e-06 
12/02/2021 15:51:41 - INFO - volta.train_utils -   [NLVR2]: iter 3898 Ep: 1.44 loss 0.155 score 0.327 lr 3.593e-06 
12/02/2021 15:52:02 - INFO - volta.train_utils -   [NLVR2]: iter 3938 Ep: 1.46 loss 0.154 score 0.307 lr 3.63005e-06 
12/02/2021 15:52:24 - INFO - volta.train_utils -   [NLVR2]: iter 3978 Ep: 1.47 loss 0.158 score 0.315 lr 3.6671e-06 
12/02/2021 15:52:46 - INFO - volta.train_utils -   [NLVR2]: iter 4018 Ep: 1.49 loss 0.158 score 0.319 lr 3.70415e-06 
12/02/2021 15:53:07 - INFO - volta.train_utils -   [NLVR2]: iter 4058 Ep: 1.50 loss 0.154 score 0.332 lr 3.7412e-06 
12/02/2021 15:53:29 - INFO - volta.train_utils -   [NLVR2]: iter 4098 Ep: 1.52 loss 0.153 score 0.321 lr 3.77825e-06 
12/02/2021 15:53:50 - INFO - volta.train_utils -   [NLVR2]: iter 4138 Ep: 1.53 loss 0.151 score 0.326 lr 3.8153e-06 
12/02/2021 15:54:12 - INFO - volta.train_utils -   [NLVR2]: iter 4178 Ep: 1.55 loss 0.154 score 0.334 lr 3.85235e-06 
12/02/2021 15:54:34 - INFO - volta.train_utils -   [NLVR2]: iter 4218 Ep: 1.56 loss 0.154 score 0.325 lr 3.8894e-06 
12/02/2021 15:54:55 - INFO - volta.train_utils -   [NLVR2]: iter 4258 Ep: 1.58 loss 0.157 score 0.316 lr 3.92645e-06 
12/02/2021 15:55:17 - INFO - volta.train_utils -   [NLVR2]: iter 4298 Ep: 1.59 loss 0.144 score 0.335 lr 3.96351e-06 
12/02/2021 15:55:39 - INFO - volta.train_utils -   [NLVR2]: iter 4338 Ep: 1.61 loss 0.157 score 0.316 lr 4.00056e-06 
12/02/2021 15:56:00 - INFO - volta.train_utils -   [NLVR2]: iter 4378 Ep: 1.62 loss 0.159 score 0.326 lr 4.03761e-06 
12/02/2021 15:56:22 - INFO - volta.train_utils -   [NLVR2]: iter 4418 Ep: 1.64 loss 0.153 score 0.324 lr 4.07466e-06 
12/02/2021 15:56:44 - INFO - volta.train_utils -   [NLVR2]: iter 4458 Ep: 1.65 loss 0.148 score 0.324 lr 4.11171e-06 
12/02/2021 15:57:05 - INFO - volta.train_utils -   [NLVR2]: iter 4498 Ep: 1.67 loss 0.153 score 0.325 lr 4.14876e-06 
12/02/2021 15:57:27 - INFO - volta.train_utils -   [NLVR2]: iter 4538 Ep: 1.68 loss 0.152 score 0.321 lr 4.18581e-06 
12/02/2021 15:57:48 - INFO - volta.train_utils -   [NLVR2]: iter 4578 Ep: 1.70 loss 0.150 score 0.330 lr 4.22286e-06 
12/02/2021 15:58:10 - INFO - volta.train_utils -   [NLVR2]: iter 4618 Ep: 1.71 loss 0.152 score 0.319 lr 4.25991e-06 
12/02/2021 15:58:31 - INFO - volta.train_utils -   [NLVR2]: iter 4658 Ep: 1.73 loss 0.152 score 0.328 lr 4.29696e-06 
12/02/2021 15:58:53 - INFO - volta.train_utils -   [NLVR2]: iter 4698 Ep: 1.74 loss 0.158 score 0.331 lr 4.33401e-06 
12/02/2021 15:59:14 - INFO - volta.train_utils -   [NLVR2]: iter 4738 Ep: 1.76 loss 0.159 score 0.316 lr 4.37106e-06 
12/02/2021 15:59:35 - INFO - volta.train_utils -   [NLVR2]: iter 4778 Ep: 1.77 loss 0.149 score 0.332 lr 4.40811e-06 
12/02/2021 15:59:57 - INFO - volta.train_utils -   [NLVR2]: iter 4818 Ep: 1.79 loss 0.153 score 0.321 lr 4.44516e-06 
12/02/2021 16:00:18 - INFO - volta.train_utils -   [NLVR2]: iter 4858 Ep: 1.80 loss 0.144 score 0.346 lr 4.48222e-06 
12/02/2021 16:00:40 - INFO - volta.train_utils -   [NLVR2]: iter 4898 Ep: 1.81 loss 0.148 score 0.334 lr 4.51927e-06 
12/02/2021 16:01:02 - INFO - volta.train_utils -   [NLVR2]: iter 4938 Ep: 1.83 loss 0.148 score 0.330 lr 4.55632e-06 
12/02/2021 16:01:23 - INFO - volta.train_utils -   [NLVR2]: iter 4978 Ep: 1.84 loss 0.149 score 0.332 lr 4.59337e-06 
12/02/2021 16:01:44 - INFO - volta.train_utils -   [NLVR2]: iter 5018 Ep: 1.86 loss 0.141 score 0.329 lr 4.63042e-06 
12/02/2021 16:02:06 - INFO - volta.train_utils -   [NLVR2]: iter 5058 Ep: 1.87 loss 0.153 score 0.326 lr 4.66747e-06 
12/02/2021 16:02:27 - INFO - volta.train_utils -   [NLVR2]: iter 5098 Ep: 1.89 loss 0.160 score 0.320 lr 4.70452e-06 
12/02/2021 16:02:49 - INFO - volta.train_utils -   [NLVR2]: iter 5138 Ep: 1.90 loss 0.157 score 0.323 lr 4.74157e-06 
12/02/2021 16:03:10 - INFO - volta.train_utils -   [NLVR2]: iter 5178 Ep: 1.92 loss 0.152 score 0.339 lr 4.77862e-06 
12/02/2021 16:03:31 - INFO - volta.train_utils -   [NLVR2]: iter 5218 Ep: 1.93 loss 0.147 score 0.332 lr 4.81567e-06 
12/02/2021 16:03:53 - INFO - volta.train_utils -   [NLVR2]: iter 5258 Ep: 1.95 loss 0.150 score 0.323 lr 4.85272e-06 
12/02/2021 16:04:14 - INFO - volta.train_utils -   [NLVR2]: iter 5298 Ep: 1.96 loss 0.152 score 0.321 lr 4.88977e-06 
12/02/2021 16:04:35 - INFO - volta.train_utils -   [NLVR2]: iter 5338 Ep: 1.98 loss 0.148 score 0.336 lr 4.92682e-06 
12/02/2021 16:04:56 - INFO - volta.train_utils -   [NLVR2]: iter 5378 Ep: 1.99 loss 0.144 score 0.346 lr 4.96388e-06 
12/02/2021 16:05:54 - INFO - volta.train_utils -   Eval task TASK12 on iteration 5396 
12/02/2021 16:05:54 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.614 score 65.983 
12/02/2021 16:05:54 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  10%|         | 2/20 [50:36<7:35:08, 1517.17s/it]12/02/2021 16:06:37 - INFO - volta.train_utils -   [NLVR2]: iter 5436 Ep: 2.01 loss 0.145 score 0.346 lr 4.99578e-06 
12/02/2021 16:06:58 - INFO - volta.train_utils -   [NLVR2]: iter 5476 Ep: 2.03 loss 0.149 score 0.327 lr 4.99393e-06 
12/02/2021 16:07:20 - INFO - volta.train_utils -   [NLVR2]: iter 5516 Ep: 2.04 loss 0.155 score 0.338 lr 4.98981e-06 
12/02/2021 16:07:41 - INFO - volta.train_utils -   [NLVR2]: iter 5556 Ep: 2.06 loss 0.152 score 0.321 lr 4.98569e-06 
12/02/2021 16:08:02 - INFO - volta.train_utils -   [NLVR2]: iter 5596 Ep: 2.07 loss 0.151 score 0.327 lr 4.98158e-06 
12/02/2021 16:08:24 - INFO - volta.train_utils -   [NLVR2]: iter 5636 Ep: 2.09 loss 0.149 score 0.336 lr 4.97746e-06 
12/02/2021 16:08:45 - INFO - volta.train_utils -   [NLVR2]: iter 5676 Ep: 2.10 loss 0.153 score 0.332 lr 4.97334e-06 
12/02/2021 16:09:06 - INFO - volta.train_utils -   [NLVR2]: iter 5716 Ep: 2.12 loss 0.147 score 0.329 lr 4.96923e-06 
12/02/2021 16:09:28 - INFO - volta.train_utils -   [NLVR2]: iter 5756 Ep: 2.13 loss 0.146 score 0.330 lr 4.96511e-06 
12/02/2021 16:09:49 - INFO - volta.train_utils -   [NLVR2]: iter 5796 Ep: 2.15 loss 0.145 score 0.345 lr 4.96099e-06 
12/02/2021 16:10:10 - INFO - volta.train_utils -   [NLVR2]: iter 5836 Ep: 2.16 loss 0.145 score 0.331 lr 4.95688e-06 
12/02/2021 16:10:32 - INFO - volta.train_utils -   [NLVR2]: iter 5876 Ep: 2.18 loss 0.148 score 0.330 lr 4.95276e-06 
12/02/2021 16:10:53 - INFO - volta.train_utils -   [NLVR2]: iter 5916 Ep: 2.19 loss 0.142 score 0.338 lr 4.94864e-06 
12/02/2021 16:11:15 - INFO - volta.train_utils -   [NLVR2]: iter 5956 Ep: 2.21 loss 0.148 score 0.337 lr 4.94453e-06 
12/02/2021 16:11:36 - INFO - volta.train_utils -   [NLVR2]: iter 5996 Ep: 2.22 loss 0.146 score 0.336 lr 4.94041e-06 
12/02/2021 16:11:57 - INFO - volta.train_utils -   [NLVR2]: iter 6036 Ep: 2.24 loss 0.140 score 0.344 lr 4.93629e-06 
12/02/2021 16:12:19 - INFO - volta.train_utils -   [NLVR2]: iter 6076 Ep: 2.25 loss 0.149 score 0.339 lr 4.93218e-06 
12/02/2021 16:12:40 - INFO - volta.train_utils -   [NLVR2]: iter 6116 Ep: 2.27 loss 0.135 score 0.338 lr 4.92806e-06 
12/02/2021 16:13:01 - INFO - volta.train_utils -   [NLVR2]: iter 6156 Ep: 2.28 loss 0.149 score 0.338 lr 4.92394e-06 
12/02/2021 16:13:23 - INFO - volta.train_utils -   [NLVR2]: iter 6196 Ep: 2.30 loss 0.139 score 0.350 lr 4.91983e-06 
12/02/2021 16:13:44 - INFO - volta.train_utils -   [NLVR2]: iter 6236 Ep: 2.31 loss 0.145 score 0.346 lr 4.91571e-06 
12/02/2021 16:14:06 - INFO - volta.train_utils -   [NLVR2]: iter 6276 Ep: 2.33 loss 0.145 score 0.334 lr 4.91159e-06 
12/02/2021 16:14:27 - INFO - volta.train_utils -   [NLVR2]: iter 6316 Ep: 2.34 loss 0.145 score 0.334 lr 4.90748e-06 
12/02/2021 16:14:49 - INFO - volta.train_utils -   [NLVR2]: iter 6356 Ep: 2.35 loss 0.141 score 0.355 lr 4.90336e-06 
12/02/2021 16:15:10 - INFO - volta.train_utils -   [NLVR2]: iter 6396 Ep: 2.37 loss 0.149 score 0.323 lr 4.89924e-06 
12/02/2021 16:15:31 - INFO - volta.train_utils -   [NLVR2]: iter 6436 Ep: 2.38 loss 0.147 score 0.327 lr 4.89513e-06 
12/02/2021 16:15:53 - INFO - volta.train_utils -   [NLVR2]: iter 6476 Ep: 2.40 loss 0.135 score 0.351 lr 4.89101e-06 
12/02/2021 16:16:14 - INFO - volta.train_utils -   [NLVR2]: iter 6516 Ep: 2.41 loss 0.144 score 0.342 lr 4.88689e-06 
12/02/2021 16:16:36 - INFO - volta.train_utils -   [NLVR2]: iter 6556 Ep: 2.43 loss 0.142 score 0.338 lr 4.88278e-06 
12/02/2021 16:16:57 - INFO - volta.train_utils -   [NLVR2]: iter 6596 Ep: 2.44 loss 0.143 score 0.350 lr 4.87866e-06 
12/02/2021 16:17:19 - INFO - volta.train_utils -   [NLVR2]: iter 6636 Ep: 2.46 loss 0.141 score 0.345 lr 4.87454e-06 
12/02/2021 16:17:40 - INFO - volta.train_utils -   [NLVR2]: iter 6676 Ep: 2.47 loss 0.139 score 0.350 lr 4.87043e-06 
12/02/2021 16:18:01 - INFO - volta.train_utils -   [NLVR2]: iter 6716 Ep: 2.49 loss 0.142 score 0.344 lr 4.86631e-06 
12/02/2021 16:18:23 - INFO - volta.train_utils -   [NLVR2]: iter 6756 Ep: 2.50 loss 0.140 score 0.348 lr 4.86219e-06 
12/02/2021 16:18:44 - INFO - volta.train_utils -   [NLVR2]: iter 6796 Ep: 2.52 loss 0.143 score 0.346 lr 4.85808e-06 
12/02/2021 16:19:06 - INFO - volta.train_utils -   [NLVR2]: iter 6836 Ep: 2.53 loss 0.136 score 0.349 lr 4.85396e-06 
12/02/2021 16:19:27 - INFO - volta.train_utils -   [NLVR2]: iter 6876 Ep: 2.55 loss 0.142 score 0.341 lr 4.84984e-06 
12/02/2021 16:19:49 - INFO - volta.train_utils -   [NLVR2]: iter 6916 Ep: 2.56 loss 0.135 score 0.354 lr 4.84572e-06 
12/02/2021 16:20:10 - INFO - volta.train_utils -   [NLVR2]: iter 6956 Ep: 2.58 loss 0.146 score 0.347 lr 4.84161e-06 
12/02/2021 16:20:32 - INFO - volta.train_utils -   [NLVR2]: iter 6996 Ep: 2.59 loss 0.144 score 0.349 lr 4.83749e-06 
12/02/2021 16:20:53 - INFO - volta.train_utils -   [NLVR2]: iter 7036 Ep: 2.61 loss 0.137 score 0.348 lr 4.83337e-06 
12/02/2021 16:21:15 - INFO - volta.train_utils -   [NLVR2]: iter 7076 Ep: 2.62 loss 0.144 score 0.344 lr 4.82926e-06 
12/02/2021 16:21:37 - INFO - volta.train_utils -   [NLVR2]: iter 7116 Ep: 2.64 loss 0.148 score 0.341 lr 4.82514e-06 
12/02/2021 16:21:58 - INFO - volta.train_utils -   [NLVR2]: iter 7156 Ep: 2.65 loss 0.136 score 0.351 lr 4.82102e-06 
12/02/2021 16:22:20 - INFO - volta.train_utils -   [NLVR2]: iter 7196 Ep: 2.67 loss 0.143 score 0.344 lr 4.81691e-06 
12/02/2021 16:22:42 - INFO - volta.train_utils -   [NLVR2]: iter 7236 Ep: 2.68 loss 0.142 score 0.347 lr 4.81279e-06 
12/02/2021 16:23:04 - INFO - volta.train_utils -   [NLVR2]: iter 7276 Ep: 2.70 loss 0.141 score 0.348 lr 4.80867e-06 
12/02/2021 16:23:26 - INFO - volta.train_utils -   [NLVR2]: iter 7316 Ep: 2.71 loss 0.143 score 0.352 lr 4.80456e-06 
12/02/2021 16:23:47 - INFO - volta.train_utils -   [NLVR2]: iter 7356 Ep: 2.73 loss 0.144 score 0.346 lr 4.80044e-06 
12/02/2021 16:24:09 - INFO - volta.train_utils -   [NLVR2]: iter 7396 Ep: 2.74 loss 0.137 score 0.357 lr 4.79632e-06 
12/02/2021 16:24:31 - INFO - volta.train_utils -   [NLVR2]: iter 7436 Ep: 2.76 loss 0.131 score 0.362 lr 4.79221e-06 
12/02/2021 16:24:53 - INFO - volta.train_utils -   [NLVR2]: iter 7476 Ep: 2.77 loss 0.130 score 0.366 lr 4.78809e-06 
12/02/2021 16:25:15 - INFO - volta.train_utils -   [NLVR2]: iter 7516 Ep: 2.78 loss 0.140 score 0.353 lr 4.78397e-06 
12/02/2021 16:25:37 - INFO - volta.train_utils -   [NLVR2]: iter 7556 Ep: 2.80 loss 0.137 score 0.361 lr 4.77986e-06 
12/02/2021 16:25:58 - INFO - volta.train_utils -   [NLVR2]: iter 7596 Ep: 2.81 loss 0.135 score 0.353 lr 4.77574e-06 
12/02/2021 16:26:20 - INFO - volta.train_utils -   [NLVR2]: iter 7636 Ep: 2.83 loss 0.140 score 0.357 lr 4.77162e-06 
12/02/2021 16:26:42 - INFO - volta.train_utils -   [NLVR2]: iter 7676 Ep: 2.84 loss 0.132 score 0.355 lr 4.76751e-06 
12/02/2021 16:27:04 - INFO - volta.train_utils -   [NLVR2]: iter 7716 Ep: 2.86 loss 0.133 score 0.354 lr 4.76339e-06 
12/02/2021 16:27:26 - INFO - volta.train_utils -   [NLVR2]: iter 7756 Ep: 2.87 loss 0.135 score 0.362 lr 4.75927e-06 
12/02/2021 16:27:48 - INFO - volta.train_utils -   [NLVR2]: iter 7796 Ep: 2.89 loss 0.129 score 0.363 lr 4.75516e-06 
12/02/2021 16:28:09 - INFO - volta.train_utils -   [NLVR2]: iter 7836 Ep: 2.90 loss 0.127 score 0.373 lr 4.75104e-06 
12/02/2021 16:28:31 - INFO - volta.train_utils -   [NLVR2]: iter 7876 Ep: 2.92 loss 0.136 score 0.359 lr 4.74692e-06 
12/02/2021 16:28:53 - INFO - volta.train_utils -   [NLVR2]: iter 7916 Ep: 2.93 loss 0.130 score 0.364 lr 4.74281e-06 
12/02/2021 16:29:15 - INFO - volta.train_utils -   [NLVR2]: iter 7956 Ep: 2.95 loss 0.138 score 0.352 lr 4.73869e-06 
12/02/2021 16:29:36 - INFO - volta.train_utils -   [NLVR2]: iter 7996 Ep: 2.96 loss 0.130 score 0.356 lr 4.73457e-06 
12/02/2021 16:29:58 - INFO - volta.train_utils -   [NLVR2]: iter 8036 Ep: 2.98 loss 0.124 score 0.366 lr 4.73046e-06 
12/02/2021 16:30:20 - INFO - volta.train_utils -   [NLVR2]: iter 8076 Ep: 2.99 loss 0.125 score 0.368 lr 4.72634e-06 
12/02/2021 16:31:17 - INFO - volta.train_utils -   Eval task TASK12 on iteration 8094 
12/02/2021 16:31:17 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.584 score 69.768 
12/02/2021 16:31:17 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  15%|        | 3/20 [1:16:01<7:10:34, 1519.66s/it]12/02/2021 16:32:02 - INFO - volta.train_utils -   [NLVR2]: iter 8134 Ep: 3.01 loss 0.130 score 0.375 lr 4.7213e-06 
12/02/2021 16:32:24 - INFO - volta.train_utils -   [NLVR2]: iter 8174 Ep: 3.03 loss 0.134 score 0.361 lr 4.71625e-06 
12/02/2021 16:32:45 - INFO - volta.train_utils -   [NLVR2]: iter 8214 Ep: 3.04 loss 0.129 score 0.355 lr 4.71214e-06 
12/02/2021 16:33:07 - INFO - volta.train_utils -   [NLVR2]: iter 8254 Ep: 3.06 loss 0.126 score 0.365 lr 4.70802e-06 
12/02/2021 16:33:29 - INFO - volta.train_utils -   [NLVR2]: iter 8294 Ep: 3.07 loss 0.125 score 0.371 lr 4.7039e-06 
12/02/2021 16:33:51 - INFO - volta.train_utils -   [NLVR2]: iter 8334 Ep: 3.09 loss 0.132 score 0.357 lr 4.69979e-06 
12/02/2021 16:34:12 - INFO - volta.train_utils -   [NLVR2]: iter 8374 Ep: 3.10 loss 0.132 score 0.363 lr 4.69567e-06 
12/02/2021 16:34:34 - INFO - volta.train_utils -   [NLVR2]: iter 8414 Ep: 3.12 loss 0.129 score 0.369 lr 4.69155e-06 
12/02/2021 16:34:56 - INFO - volta.train_utils -   [NLVR2]: iter 8454 Ep: 3.13 loss 0.129 score 0.358 lr 4.68744e-06 
12/02/2021 16:35:17 - INFO - volta.train_utils -   [NLVR2]: iter 8494 Ep: 3.15 loss 0.133 score 0.352 lr 4.68332e-06 
12/02/2021 16:35:39 - INFO - volta.train_utils -   [NLVR2]: iter 8534 Ep: 3.16 loss 0.135 score 0.354 lr 4.6792e-06 
12/02/2021 16:36:01 - INFO - volta.train_utils -   [NLVR2]: iter 8574 Ep: 3.18 loss 0.130 score 0.365 lr 4.67509e-06 
12/02/2021 16:36:23 - INFO - volta.train_utils -   [NLVR2]: iter 8614 Ep: 3.19 loss 0.128 score 0.359 lr 4.67097e-06 
12/02/2021 16:36:44 - INFO - volta.train_utils -   [NLVR2]: iter 8654 Ep: 3.21 loss 0.127 score 0.358 lr 4.66685e-06 
12/02/2021 16:37:06 - INFO - volta.train_utils -   [NLVR2]: iter 8694 Ep: 3.22 loss 0.131 score 0.361 lr 4.66274e-06 
12/02/2021 16:37:28 - INFO - volta.train_utils -   [NLVR2]: iter 8734 Ep: 3.24 loss 0.127 score 0.366 lr 4.65862e-06 
12/02/2021 16:37:50 - INFO - volta.train_utils -   [NLVR2]: iter 8774 Ep: 3.25 loss 0.126 score 0.370 lr 4.6545e-06 
12/02/2021 16:38:12 - INFO - volta.train_utils -   [NLVR2]: iter 8814 Ep: 3.27 loss 0.129 score 0.351 lr 4.65038e-06 
12/02/2021 16:38:33 - INFO - volta.train_utils -   [NLVR2]: iter 8854 Ep: 3.28 loss 0.129 score 0.360 lr 4.64627e-06 
12/02/2021 16:38:55 - INFO - volta.train_utils -   [NLVR2]: iter 8894 Ep: 3.30 loss 0.126 score 0.373 lr 4.64215e-06 
12/02/2021 16:39:17 - INFO - volta.train_utils -   [NLVR2]: iter 8934 Ep: 3.31 loss 0.120 score 0.369 lr 4.63803e-06 
12/02/2021 16:39:39 - INFO - volta.train_utils -   [NLVR2]: iter 8974 Ep: 3.32 loss 0.123 score 0.370 lr 4.63392e-06 
12/02/2021 16:40:00 - INFO - volta.train_utils -   [NLVR2]: iter 9014 Ep: 3.34 loss 0.129 score 0.366 lr 4.6298e-06 
12/02/2021 16:40:22 - INFO - volta.train_utils -   [NLVR2]: iter 9054 Ep: 3.35 loss 0.119 score 0.369 lr 4.62568e-06 
12/02/2021 16:40:44 - INFO - volta.train_utils -   [NLVR2]: iter 9094 Ep: 3.37 loss 0.125 score 0.370 lr 4.62157e-06 
12/02/2021 16:41:05 - INFO - volta.train_utils -   [NLVR2]: iter 9134 Ep: 3.38 loss 0.125 score 0.364 lr 4.61745e-06 
12/02/2021 16:41:27 - INFO - volta.train_utils -   [NLVR2]: iter 9174 Ep: 3.40 loss 0.127 score 0.373 lr 4.61333e-06 
12/02/2021 16:41:49 - INFO - volta.train_utils -   [NLVR2]: iter 9214 Ep: 3.41 loss 0.123 score 0.368 lr 4.60922e-06 
12/02/2021 16:42:10 - INFO - volta.train_utils -   [NLVR2]: iter 9254 Ep: 3.43 loss 0.120 score 0.372 lr 4.6051e-06 
12/02/2021 16:42:32 - INFO - volta.train_utils -   [NLVR2]: iter 9294 Ep: 3.44 loss 0.122 score 0.372 lr 4.60098e-06 
12/02/2021 16:42:54 - INFO - volta.train_utils -   [NLVR2]: iter 9334 Ep: 3.46 loss 0.125 score 0.371 lr 4.59687e-06 
12/02/2021 16:43:16 - INFO - volta.train_utils -   [NLVR2]: iter 9374 Ep: 3.47 loss 0.129 score 0.361 lr 4.59275e-06 
12/02/2021 16:43:37 - INFO - volta.train_utils -   [NLVR2]: iter 9414 Ep: 3.49 loss 0.121 score 0.361 lr 4.58863e-06 
12/02/2021 16:43:59 - INFO - volta.train_utils -   [NLVR2]: iter 9454 Ep: 3.50 loss 0.126 score 0.366 lr 4.58452e-06 
12/02/2021 16:44:21 - INFO - volta.train_utils -   [NLVR2]: iter 9494 Ep: 3.52 loss 0.123 score 0.373 lr 4.5804e-06 
12/02/2021 16:44:43 - INFO - volta.train_utils -   [NLVR2]: iter 9534 Ep: 3.53 loss 0.125 score 0.384 lr 4.57628e-06 
12/02/2021 16:45:05 - INFO - volta.train_utils -   [NLVR2]: iter 9574 Ep: 3.55 loss 0.133 score 0.364 lr 4.57217e-06 
12/02/2021 16:45:26 - INFO - volta.train_utils -   [NLVR2]: iter 9614 Ep: 3.56 loss 0.127 score 0.375 lr 4.56805e-06 
12/02/2021 16:45:48 - INFO - volta.train_utils -   [NLVR2]: iter 9654 Ep: 3.58 loss 0.122 score 0.374 lr 4.56393e-06 
12/02/2021 16:46:10 - INFO - volta.train_utils -   [NLVR2]: iter 9694 Ep: 3.59 loss 0.124 score 0.373 lr 4.55982e-06 
12/02/2021 16:46:32 - INFO - volta.train_utils -   [NLVR2]: iter 9734 Ep: 3.61 loss 0.124 score 0.385 lr 4.5557e-06 
12/02/2021 16:46:54 - INFO - volta.train_utils -   [NLVR2]: iter 9774 Ep: 3.62 loss 0.120 score 0.373 lr 4.55158e-06 
12/02/2021 16:47:15 - INFO - volta.train_utils -   [NLVR2]: iter 9814 Ep: 3.64 loss 0.120 score 0.383 lr 4.54747e-06 
12/02/2021 16:47:37 - INFO - volta.train_utils -   [NLVR2]: iter 9854 Ep: 3.65 loss 0.117 score 0.388 lr 4.54335e-06 
12/02/2021 16:47:59 - INFO - volta.train_utils -   [NLVR2]: iter 9894 Ep: 3.67 loss 0.116 score 0.375 lr 4.53923e-06 
12/02/2021 16:48:21 - INFO - volta.train_utils -   [NLVR2]: iter 9934 Ep: 3.68 loss 0.134 score 0.364 lr 4.53512e-06 
12/02/2021 16:48:43 - INFO - volta.train_utils -   [NLVR2]: iter 9974 Ep: 3.70 loss 0.118 score 0.373 lr 4.531e-06 
12/02/2021 16:49:05 - INFO - volta.train_utils -   [NLVR2]: iter 10014 Ep: 3.71 loss 0.112 score 0.378 lr 4.52688e-06 
12/02/2021 16:49:26 - INFO - volta.train_utils -   [NLVR2]: iter 10054 Ep: 3.73 loss 0.124 score 0.375 lr 4.52277e-06 
12/02/2021 16:49:48 - INFO - volta.train_utils -   [NLVR2]: iter 10094 Ep: 3.74 loss 0.133 score 0.367 lr 4.51865e-06 
12/02/2021 16:50:10 - INFO - volta.train_utils -   [NLVR2]: iter 10134 Ep: 3.75 loss 0.124 score 0.376 lr 4.51453e-06 
12/02/2021 16:50:32 - INFO - volta.train_utils -   [NLVR2]: iter 10174 Ep: 3.77 loss 0.123 score 0.370 lr 4.51042e-06 
12/02/2021 16:50:53 - INFO - volta.train_utils -   [NLVR2]: iter 10214 Ep: 3.78 loss 0.112 score 0.382 lr 4.5063e-06 
12/02/2021 16:51:15 - INFO - volta.train_utils -   [NLVR2]: iter 10254 Ep: 3.80 loss 0.121 score 0.383 lr 4.50218e-06 
12/02/2021 16:51:37 - INFO - volta.train_utils -   [NLVR2]: iter 10294 Ep: 3.81 loss 0.118 score 0.388 lr 4.49807e-06 
12/02/2021 16:51:59 - INFO - volta.train_utils -   [NLVR2]: iter 10334 Ep: 3.83 loss 0.120 score 0.379 lr 4.49395e-06 
12/02/2021 16:52:21 - INFO - volta.train_utils -   [NLVR2]: iter 10374 Ep: 3.84 loss 0.108 score 0.402 lr 4.48983e-06 
12/02/2021 16:52:42 - INFO - volta.train_utils -   [NLVR2]: iter 10414 Ep: 3.86 loss 0.122 score 0.373 lr 4.48571e-06 
12/02/2021 16:53:04 - INFO - volta.train_utils -   [NLVR2]: iter 10454 Ep: 3.87 loss 0.119 score 0.368 lr 4.4816e-06 
12/02/2021 16:53:26 - INFO - volta.train_utils -   [NLVR2]: iter 10494 Ep: 3.89 loss 0.120 score 0.384 lr 4.47748e-06 
12/02/2021 16:53:48 - INFO - volta.train_utils -   [NLVR2]: iter 10534 Ep: 3.90 loss 0.123 score 0.380 lr 4.47336e-06 
12/02/2021 16:54:10 - INFO - volta.train_utils -   [NLVR2]: iter 10574 Ep: 3.92 loss 0.120 score 0.383 lr 4.46925e-06 
12/02/2021 16:54:32 - INFO - volta.train_utils -   [NLVR2]: iter 10614 Ep: 3.93 loss 0.114 score 0.391 lr 4.46513e-06 
12/02/2021 16:54:53 - INFO - volta.train_utils -   [NLVR2]: iter 10654 Ep: 3.95 loss 0.116 score 0.386 lr 4.46101e-06 
12/02/2021 16:55:15 - INFO - volta.train_utils -   [NLVR2]: iter 10694 Ep: 3.96 loss 0.112 score 0.383 lr 4.4569e-06 
12/02/2021 16:55:37 - INFO - volta.train_utils -   [NLVR2]: iter 10734 Ep: 3.98 loss 0.111 score 0.381 lr 4.45278e-06 
12/02/2021 16:55:59 - INFO - volta.train_utils -   [NLVR2]: iter 10774 Ep: 3.99 loss 0.104 score 0.390 lr 4.44866e-06 
12/02/2021 16:56:56 - INFO - volta.train_utils -   Eval task TASK12 on iteration 10792 
12/02/2021 16:56:56 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.614 score 70.857 
12/02/2021 16:56:56 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  20%|        | 4/20 [1:41:35<6:46:23, 1523.99s/it]12/02/2021 16:57:36 - INFO - volta.train_utils -   [NLVR2]: iter 10832 Ep: 4.01 loss 0.122 score 0.391 lr 4.44362e-06 
12/02/2021 16:57:58 - INFO - volta.train_utils -   [NLVR2]: iter 10872 Ep: 4.03 loss 0.114 score 0.382 lr 4.43858e-06 
12/02/2021 16:58:19 - INFO - volta.train_utils -   [NLVR2]: iter 10912 Ep: 4.04 loss 0.124 score 0.383 lr 4.43446e-06 
12/02/2021 16:58:41 - INFO - volta.train_utils -   [NLVR2]: iter 10952 Ep: 4.06 loss 0.126 score 0.384 lr 4.43034e-06 
12/02/2021 16:59:03 - INFO - volta.train_utils -   [NLVR2]: iter 10992 Ep: 4.07 loss 0.116 score 0.383 lr 4.42623e-06 
12/02/2021 16:59:24 - INFO - volta.train_utils -   [NLVR2]: iter 11032 Ep: 4.09 loss 0.119 score 0.378 lr 4.42211e-06 
12/02/2021 16:59:46 - INFO - volta.train_utils -   [NLVR2]: iter 11072 Ep: 4.10 loss 0.122 score 0.374 lr 4.41799e-06 
12/02/2021 17:00:07 - INFO - volta.train_utils -   [NLVR2]: iter 11112 Ep: 4.12 loss 0.115 score 0.378 lr 4.41388e-06 
12/02/2021 17:00:29 - INFO - volta.train_utils -   [NLVR2]: iter 11152 Ep: 4.13 loss 0.116 score 0.376 lr 4.40976e-06 
12/02/2021 17:00:50 - INFO - volta.train_utils -   [NLVR2]: iter 11192 Ep: 4.15 loss 0.120 score 0.383 lr 4.40564e-06 
12/02/2021 17:01:12 - INFO - volta.train_utils -   [NLVR2]: iter 11232 Ep: 4.16 loss 0.111 score 0.382 lr 4.40153e-06 
12/02/2021 17:01:34 - INFO - volta.train_utils -   [NLVR2]: iter 11272 Ep: 4.18 loss 0.108 score 0.382 lr 4.39741e-06 
12/02/2021 17:01:56 - INFO - volta.train_utils -   [NLVR2]: iter 11312 Ep: 4.19 loss 0.112 score 0.389 lr 4.39329e-06 
12/02/2021 17:02:17 - INFO - volta.train_utils -   [NLVR2]: iter 11352 Ep: 4.21 loss 0.105 score 0.380 lr 4.38918e-06 
12/02/2021 17:02:39 - INFO - volta.train_utils -   [NLVR2]: iter 11392 Ep: 4.22 loss 0.111 score 0.382 lr 4.38506e-06 
12/02/2021 17:03:00 - INFO - volta.train_utils -   [NLVR2]: iter 11432 Ep: 4.24 loss 0.120 score 0.378 lr 4.38094e-06 
12/02/2021 17:03:22 - INFO - volta.train_utils -   [NLVR2]: iter 11472 Ep: 4.25 loss 0.116 score 0.387 lr 4.37683e-06 
12/02/2021 17:03:44 - INFO - volta.train_utils -   [NLVR2]: iter 11512 Ep: 4.27 loss 0.117 score 0.389 lr 4.37271e-06 
12/02/2021 17:04:05 - INFO - volta.train_utils -   [NLVR2]: iter 11552 Ep: 4.28 loss 0.108 score 0.384 lr 4.36859e-06 
12/02/2021 17:04:27 - INFO - volta.train_utils -   [NLVR2]: iter 11592 Ep: 4.29 loss 0.111 score 0.390 lr 4.36448e-06 
12/02/2021 17:04:49 - INFO - volta.train_utils -   [NLVR2]: iter 11632 Ep: 4.31 loss 0.104 score 0.400 lr 4.36036e-06 
12/02/2021 17:05:10 - INFO - volta.train_utils -   [NLVR2]: iter 11672 Ep: 4.32 loss 0.113 score 0.380 lr 4.35624e-06 
12/02/2021 17:05:32 - INFO - volta.train_utils -   [NLVR2]: iter 11712 Ep: 4.34 loss 0.114 score 0.384 lr 4.35213e-06 
12/02/2021 17:05:53 - INFO - volta.train_utils -   [NLVR2]: iter 11752 Ep: 4.35 loss 0.115 score 0.391 lr 4.34801e-06 
12/02/2021 17:06:15 - INFO - volta.train_utils -   [NLVR2]: iter 11792 Ep: 4.37 loss 0.109 score 0.383 lr 4.34389e-06 
12/02/2021 17:06:37 - INFO - volta.train_utils -   [NLVR2]: iter 11832 Ep: 4.38 loss 0.112 score 0.394 lr 4.33978e-06 
12/02/2021 17:06:58 - INFO - volta.train_utils -   [NLVR2]: iter 11872 Ep: 4.40 loss 0.109 score 0.388 lr 4.33566e-06 
12/02/2021 17:07:20 - INFO - volta.train_utils -   [NLVR2]: iter 11912 Ep: 4.41 loss 0.111 score 0.377 lr 4.33154e-06 
12/02/2021 17:07:42 - INFO - volta.train_utils -   [NLVR2]: iter 11952 Ep: 4.43 loss 0.115 score 0.385 lr 4.32743e-06 
12/02/2021 17:08:03 - INFO - volta.train_utils -   [NLVR2]: iter 11992 Ep: 4.44 loss 0.106 score 0.396 lr 4.32331e-06 
12/02/2021 17:08:25 - INFO - volta.train_utils -   [NLVR2]: iter 12032 Ep: 4.46 loss 0.102 score 0.389 lr 4.31919e-06 
12/02/2021 17:08:47 - INFO - volta.train_utils -   [NLVR2]: iter 12072 Ep: 4.47 loss 0.111 score 0.386 lr 4.31508e-06 
12/02/2021 17:09:08 - INFO - volta.train_utils -   [NLVR2]: iter 12112 Ep: 4.49 loss 0.113 score 0.381 lr 4.31096e-06 
12/02/2021 17:09:30 - INFO - volta.train_utils -   [NLVR2]: iter 12152 Ep: 4.50 loss 0.104 score 0.401 lr 4.30684e-06 
12/02/2021 17:09:52 - INFO - volta.train_utils -   [NLVR2]: iter 12192 Ep: 4.52 loss 0.107 score 0.397 lr 4.30273e-06 
12/02/2021 17:10:14 - INFO - volta.train_utils -   [NLVR2]: iter 12232 Ep: 4.53 loss 0.110 score 0.393 lr 4.29861e-06 
12/02/2021 17:10:35 - INFO - volta.train_utils -   [NLVR2]: iter 12272 Ep: 4.55 loss 0.099 score 0.394 lr 4.29449e-06 
12/02/2021 17:10:57 - INFO - volta.train_utils -   [NLVR2]: iter 12312 Ep: 4.56 loss 0.109 score 0.390 lr 4.29038e-06 
12/02/2021 17:11:19 - INFO - volta.train_utils -   [NLVR2]: iter 12352 Ep: 4.58 loss 0.111 score 0.385 lr 4.28626e-06 
12/02/2021 17:11:41 - INFO - volta.train_utils -   [NLVR2]: iter 12392 Ep: 4.59 loss 0.115 score 0.389 lr 4.28214e-06 
12/02/2021 17:12:02 - INFO - volta.train_utils -   [NLVR2]: iter 12432 Ep: 4.61 loss 0.108 score 0.398 lr 4.27802e-06 
12/02/2021 17:12:24 - INFO - volta.train_utils -   [NLVR2]: iter 12472 Ep: 4.62 loss 0.105 score 0.395 lr 4.27391e-06 
12/02/2021 17:12:46 - INFO - volta.train_utils -   [NLVR2]: iter 12512 Ep: 4.64 loss 0.107 score 0.391 lr 4.26979e-06 
12/02/2021 17:13:08 - INFO - volta.train_utils -   [NLVR2]: iter 12552 Ep: 4.65 loss 0.106 score 0.389 lr 4.26567e-06 
12/02/2021 17:13:29 - INFO - volta.train_utils -   [NLVR2]: iter 12592 Ep: 4.67 loss 0.106 score 0.393 lr 4.26156e-06 
12/02/2021 17:13:51 - INFO - volta.train_utils -   [NLVR2]: iter 12632 Ep: 4.68 loss 0.118 score 0.380 lr 4.25744e-06 
12/02/2021 17:14:12 - INFO - volta.train_utils -   [NLVR2]: iter 12672 Ep: 4.70 loss 0.107 score 0.392 lr 4.25332e-06 
12/02/2021 17:14:34 - INFO - volta.train_utils -   [NLVR2]: iter 12712 Ep: 4.71 loss 0.101 score 0.401 lr 4.24921e-06 
12/02/2021 17:14:56 - INFO - volta.train_utils -   [NLVR2]: iter 12752 Ep: 4.72 loss 0.101 score 0.402 lr 4.24509e-06 
12/02/2021 17:15:18 - INFO - volta.train_utils -   [NLVR2]: iter 12792 Ep: 4.74 loss 0.109 score 0.391 lr 4.24097e-06 
12/02/2021 17:15:39 - INFO - volta.train_utils -   [NLVR2]: iter 12832 Ep: 4.75 loss 0.112 score 0.389 lr 4.23686e-06 
12/02/2021 17:16:01 - INFO - volta.train_utils -   [NLVR2]: iter 12872 Ep: 4.77 loss 0.096 score 0.399 lr 4.23274e-06 
12/02/2021 17:16:22 - INFO - volta.train_utils -   [NLVR2]: iter 12912 Ep: 4.78 loss 0.109 score 0.385 lr 4.22862e-06 
12/02/2021 17:16:44 - INFO - volta.train_utils -   [NLVR2]: iter 12952 Ep: 4.80 loss 0.105 score 0.397 lr 4.22451e-06 
12/02/2021 17:17:05 - INFO - volta.train_utils -   [NLVR2]: iter 12992 Ep: 4.81 loss 0.101 score 0.396 lr 4.22039e-06 
12/02/2021 17:17:27 - INFO - volta.train_utils -   [NLVR2]: iter 13032 Ep: 4.83 loss 0.106 score 0.395 lr 4.21627e-06 
12/02/2021 17:17:48 - INFO - volta.train_utils -   [NLVR2]: iter 13072 Ep: 4.84 loss 0.104 score 0.395 lr 4.21216e-06 
12/02/2021 17:18:10 - INFO - volta.train_utils -   [NLVR2]: iter 13112 Ep: 4.86 loss 0.103 score 0.404 lr 4.20804e-06 
12/02/2021 17:18:32 - INFO - volta.train_utils -   [NLVR2]: iter 13152 Ep: 4.87 loss 0.100 score 0.398 lr 4.20392e-06 
12/02/2021 17:18:53 - INFO - volta.train_utils -   [NLVR2]: iter 13192 Ep: 4.89 loss 0.106 score 0.403 lr 4.19981e-06 
12/02/2021 17:19:15 - INFO - volta.train_utils -   [NLVR2]: iter 13232 Ep: 4.90 loss 0.103 score 0.391 lr 4.19569e-06 
12/02/2021 17:19:36 - INFO - volta.train_utils -   [NLVR2]: iter 13272 Ep: 4.92 loss 0.095 score 0.405 lr 4.19157e-06 
12/02/2021 17:19:58 - INFO - volta.train_utils -   [NLVR2]: iter 13312 Ep: 4.93 loss 0.101 score 0.403 lr 4.18746e-06 
12/02/2021 17:20:19 - INFO - volta.train_utils -   [NLVR2]: iter 13352 Ep: 4.95 loss 0.103 score 0.401 lr 4.18334e-06 
12/02/2021 17:20:41 - INFO - volta.train_utils -   [NLVR2]: iter 13392 Ep: 4.96 loss 0.099 score 0.400 lr 4.17922e-06 
12/02/2021 17:21:02 - INFO - volta.train_utils -   [NLVR2]: iter 13432 Ep: 4.98 loss 0.102 score 0.396 lr 4.17511e-06 
12/02/2021 17:21:24 - INFO - volta.train_utils -   [NLVR2]: iter 13472 Ep: 4.99 loss 0.100 score 0.400 lr 4.17099e-06 
12/02/2021 17:22:20 - INFO - volta.train_utils -   Eval task TASK12 on iteration 13490 
12/02/2021 17:22:20 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.651 score 71.373 
12/02/2021 17:22:20 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  25%|       | 5/20 [2:07:00<6:21:05, 1524.35s/it]12/02/2021 17:23:01 - INFO - volta.train_utils -   [NLVR2]: iter 13530 Ep: 5.01 loss 0.109 score 0.398 lr 4.16595e-06 
12/02/2021 17:23:23 - INFO - volta.train_utils -   [NLVR2]: iter 13570 Ep: 5.03 loss 0.100 score 0.401 lr 4.1609e-06 
12/02/2021 17:23:44 - INFO - volta.train_utils -   [NLVR2]: iter 13610 Ep: 5.04 loss 0.088 score 0.406 lr 4.15679e-06 
12/02/2021 17:24:06 - INFO - volta.train_utils -   [NLVR2]: iter 13650 Ep: 5.06 loss 0.116 score 0.393 lr 4.15267e-06 
12/02/2021 17:24:27 - INFO - volta.train_utils -   [NLVR2]: iter 13690 Ep: 5.07 loss 0.099 score 0.406 lr 4.14855e-06 
12/02/2021 17:24:49 - INFO - volta.train_utils -   [NLVR2]: iter 13730 Ep: 5.09 loss 0.100 score 0.402 lr 4.14444e-06 
12/02/2021 17:25:10 - INFO - volta.train_utils -   [NLVR2]: iter 13770 Ep: 5.10 loss 0.113 score 0.389 lr 4.14032e-06 
12/02/2021 17:25:32 - INFO - volta.train_utils -   [NLVR2]: iter 13810 Ep: 5.12 loss 0.106 score 0.400 lr 4.1362e-06 
12/02/2021 17:25:53 - INFO - volta.train_utils -   [NLVR2]: iter 13850 Ep: 5.13 loss 0.109 score 0.394 lr 4.13209e-06 
12/02/2021 17:26:15 - INFO - volta.train_utils -   [NLVR2]: iter 13890 Ep: 5.15 loss 0.104 score 0.402 lr 4.12797e-06 
12/02/2021 17:26:37 - INFO - volta.train_utils -   [NLVR2]: iter 13930 Ep: 5.16 loss 0.091 score 0.410 lr 4.12385e-06 
12/02/2021 17:26:58 - INFO - volta.train_utils -   [NLVR2]: iter 13970 Ep: 5.18 loss 0.100 score 0.398 lr 4.11974e-06 
12/02/2021 17:27:20 - INFO - volta.train_utils -   [NLVR2]: iter 14010 Ep: 5.19 loss 0.094 score 0.401 lr 4.11562e-06 
12/02/2021 17:27:41 - INFO - volta.train_utils -   [NLVR2]: iter 14050 Ep: 5.21 loss 0.106 score 0.397 lr 4.1115e-06 
12/02/2021 17:28:03 - INFO - volta.train_utils -   [NLVR2]: iter 14090 Ep: 5.22 loss 0.097 score 0.407 lr 4.10739e-06 
12/02/2021 17:28:25 - INFO - volta.train_utils -   [NLVR2]: iter 14130 Ep: 5.24 loss 0.100 score 0.400 lr 4.10327e-06 
12/02/2021 17:28:46 - INFO - volta.train_utils -   [NLVR2]: iter 14170 Ep: 5.25 loss 0.114 score 0.400 lr 4.09915e-06 
12/02/2021 17:29:08 - INFO - volta.train_utils -   [NLVR2]: iter 14210 Ep: 5.26 loss 0.099 score 0.399 lr 4.09504e-06 
12/02/2021 17:29:30 - INFO - volta.train_utils -   [NLVR2]: iter 14250 Ep: 5.28 loss 0.111 score 0.391 lr 4.09092e-06 
12/02/2021 17:29:51 - INFO - volta.train_utils -   [NLVR2]: iter 14290 Ep: 5.29 loss 0.102 score 0.399 lr 4.0868e-06 
12/02/2021 17:30:13 - INFO - volta.train_utils -   [NLVR2]: iter 14330 Ep: 5.31 loss 0.099 score 0.400 lr 4.08268e-06 
12/02/2021 17:30:34 - INFO - volta.train_utils -   [NLVR2]: iter 14370 Ep: 5.32 loss 0.104 score 0.391 lr 4.07857e-06 
12/02/2021 17:30:56 - INFO - volta.train_utils -   [NLVR2]: iter 14410 Ep: 5.34 loss 0.106 score 0.398 lr 4.07445e-06 
12/02/2021 17:31:18 - INFO - volta.train_utils -   [NLVR2]: iter 14450 Ep: 5.35 loss 0.099 score 0.407 lr 4.07033e-06 
12/02/2021 17:31:39 - INFO - volta.train_utils -   [NLVR2]: iter 14490 Ep: 5.37 loss 0.095 score 0.402 lr 4.06622e-06 
12/02/2021 17:32:01 - INFO - volta.train_utils -   [NLVR2]: iter 14530 Ep: 5.38 loss 0.095 score 0.403 lr 4.0621e-06 
12/02/2021 17:32:22 - INFO - volta.train_utils -   [NLVR2]: iter 14570 Ep: 5.40 loss 0.095 score 0.400 lr 4.05798e-06 
12/02/2021 17:32:44 - INFO - volta.train_utils -   [NLVR2]: iter 14610 Ep: 5.41 loss 0.097 score 0.400 lr 4.05387e-06 
12/02/2021 17:33:06 - INFO - volta.train_utils -   [NLVR2]: iter 14650 Ep: 5.43 loss 0.097 score 0.405 lr 4.04975e-06 
12/02/2021 17:33:28 - INFO - volta.train_utils -   [NLVR2]: iter 14690 Ep: 5.44 loss 0.105 score 0.393 lr 4.04563e-06 
12/02/2021 17:33:49 - INFO - volta.train_utils -   [NLVR2]: iter 14730 Ep: 5.46 loss 0.104 score 0.404 lr 4.04152e-06 
12/02/2021 17:34:11 - INFO - volta.train_utils -   [NLVR2]: iter 14770 Ep: 5.47 loss 0.095 score 0.402 lr 4.0374e-06 
12/02/2021 17:34:33 - INFO - volta.train_utils -   [NLVR2]: iter 14810 Ep: 5.49 loss 0.095 score 0.402 lr 4.03328e-06 
12/02/2021 17:34:54 - INFO - volta.train_utils -   [NLVR2]: iter 14850 Ep: 5.50 loss 0.096 score 0.403 lr 4.02917e-06 
12/02/2021 17:35:16 - INFO - volta.train_utils -   [NLVR2]: iter 14890 Ep: 5.52 loss 0.097 score 0.397 lr 4.02505e-06 
12/02/2021 17:35:38 - INFO - volta.train_utils -   [NLVR2]: iter 14930 Ep: 5.53 loss 0.101 score 0.405 lr 4.02093e-06 
12/02/2021 17:35:59 - INFO - volta.train_utils -   [NLVR2]: iter 14970 Ep: 5.55 loss 0.094 score 0.412 lr 4.01682e-06 
12/02/2021 17:36:21 - INFO - volta.train_utils -   [NLVR2]: iter 15010 Ep: 5.56 loss 0.098 score 0.410 lr 4.0127e-06 
12/02/2021 17:36:42 - INFO - volta.train_utils -   [NLVR2]: iter 15050 Ep: 5.58 loss 0.091 score 0.415 lr 4.00858e-06 
12/02/2021 17:37:04 - INFO - volta.train_utils -   [NLVR2]: iter 15090 Ep: 5.59 loss 0.106 score 0.407 lr 4.00447e-06 
12/02/2021 17:37:26 - INFO - volta.train_utils -   [NLVR2]: iter 15130 Ep: 5.61 loss 0.090 score 0.413 lr 4.00035e-06 
12/02/2021 17:37:48 - INFO - volta.train_utils -   [NLVR2]: iter 15170 Ep: 5.62 loss 0.092 score 0.414 lr 3.99623e-06 
12/02/2021 17:38:09 - INFO - volta.train_utils -   [NLVR2]: iter 15210 Ep: 5.64 loss 0.097 score 0.403 lr 3.99212e-06 
12/02/2021 17:38:31 - INFO - volta.train_utils -   [NLVR2]: iter 15250 Ep: 5.65 loss 0.098 score 0.405 lr 3.988e-06 
12/02/2021 17:38:53 - INFO - volta.train_utils -   [NLVR2]: iter 15290 Ep: 5.67 loss 0.099 score 0.401 lr 3.98388e-06 
12/02/2021 17:39:14 - INFO - volta.train_utils -   [NLVR2]: iter 15330 Ep: 5.68 loss 0.091 score 0.412 lr 3.97977e-06 
12/02/2021 17:39:36 - INFO - volta.train_utils -   [NLVR2]: iter 15370 Ep: 5.69 loss 0.093 score 0.412 lr 3.97565e-06 
12/02/2021 17:39:57 - INFO - volta.train_utils -   [NLVR2]: iter 15410 Ep: 5.71 loss 0.091 score 0.410 lr 3.97153e-06 
12/02/2021 17:40:19 - INFO - volta.train_utils -   [NLVR2]: iter 15450 Ep: 5.72 loss 0.090 score 0.411 lr 3.96742e-06 
12/02/2021 17:40:40 - INFO - volta.train_utils -   [NLVR2]: iter 15490 Ep: 5.74 loss 0.092 score 0.402 lr 3.9633e-06 
12/02/2021 17:41:02 - INFO - volta.train_utils -   [NLVR2]: iter 15530 Ep: 5.75 loss 0.105 score 0.402 lr 3.95918e-06 
12/02/2021 17:41:23 - INFO - volta.train_utils -   [NLVR2]: iter 15570 Ep: 5.77 loss 0.108 score 0.395 lr 3.95507e-06 
12/02/2021 17:41:45 - INFO - volta.train_utils -   [NLVR2]: iter 15610 Ep: 5.78 loss 0.090 score 0.409 lr 3.95095e-06 
12/02/2021 17:42:07 - INFO - volta.train_utils -   [NLVR2]: iter 15650 Ep: 5.80 loss 0.101 score 0.409 lr 3.94683e-06 
12/02/2021 17:42:28 - INFO - volta.train_utils -   [NLVR2]: iter 15690 Ep: 5.81 loss 0.087 score 0.415 lr 3.94272e-06 
12/02/2021 17:42:50 - INFO - volta.train_utils -   [NLVR2]: iter 15730 Ep: 5.83 loss 0.103 score 0.401 lr 3.9386e-06 
12/02/2021 17:43:11 - INFO - volta.train_utils -   [NLVR2]: iter 15770 Ep: 5.84 loss 0.098 score 0.413 lr 3.93448e-06 
12/02/2021 17:43:33 - INFO - volta.train_utils -   [NLVR2]: iter 15810 Ep: 5.86 loss 0.091 score 0.412 lr 3.93037e-06 
12/02/2021 17:43:55 - INFO - volta.train_utils -   [NLVR2]: iter 15850 Ep: 5.87 loss 0.092 score 0.414 lr 3.92625e-06 
12/02/2021 17:44:16 - INFO - volta.train_utils -   [NLVR2]: iter 15890 Ep: 5.89 loss 0.089 score 0.403 lr 3.92213e-06 
12/02/2021 17:44:38 - INFO - volta.train_utils -   [NLVR2]: iter 15930 Ep: 5.90 loss 0.092 score 0.418 lr 3.91801e-06 
12/02/2021 17:44:59 - INFO - volta.train_utils -   [NLVR2]: iter 15970 Ep: 5.92 loss 0.091 score 0.407 lr 3.9139e-06 
12/02/2021 17:45:21 - INFO - volta.train_utils -   [NLVR2]: iter 16010 Ep: 5.93 loss 0.088 score 0.419 lr 3.90978e-06 
12/02/2021 17:45:43 - INFO - volta.train_utils -   [NLVR2]: iter 16050 Ep: 5.95 loss 0.091 score 0.409 lr 3.90566e-06 
12/02/2021 17:46:04 - INFO - volta.train_utils -   [NLVR2]: iter 16090 Ep: 5.96 loss 0.094 score 0.411 lr 3.90155e-06 
12/02/2021 17:46:26 - INFO - volta.train_utils -   [NLVR2]: iter 16130 Ep: 5.98 loss 0.100 score 0.417 lr 3.89743e-06 
12/02/2021 17:46:47 - INFO - volta.train_utils -   [NLVR2]: iter 16170 Ep: 5.99 loss 0.095 score 0.412 lr 3.89331e-06 
12/02/2021 17:47:45 - INFO - volta.train_utils -   Eval task TASK12 on iteration 16188 
12/02/2021 17:47:45 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.672 score 71.588 
12/02/2021 17:47:45 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  30%|       | 6/20 [2:32:25<5:55:44, 1524.60s/it]12/02/2021 17:48:27 - INFO - volta.train_utils -   [NLVR2]: iter 16228 Ep: 6.01 loss 0.096 score 0.426 lr 3.88827e-06 
12/02/2021 17:48:48 - INFO - volta.train_utils -   [NLVR2]: iter 16268 Ep: 6.03 loss 0.100 score 0.414 lr 3.88323e-06 
12/02/2021 17:49:10 - INFO - volta.train_utils -   [NLVR2]: iter 16308 Ep: 6.04 loss 0.089 score 0.414 lr 3.87911e-06 
12/02/2021 17:49:31 - INFO - volta.train_utils -   [NLVR2]: iter 16348 Ep: 6.06 loss 0.093 score 0.405 lr 3.87499e-06 
12/02/2021 17:49:52 - INFO - volta.train_utils -   [NLVR2]: iter 16388 Ep: 6.07 loss 0.099 score 0.412 lr 3.87088e-06 
12/02/2021 17:50:14 - INFO - volta.train_utils -   [NLVR2]: iter 16428 Ep: 6.09 loss 0.089 score 0.411 lr 3.86676e-06 
12/02/2021 17:50:35 - INFO - volta.train_utils -   [NLVR2]: iter 16468 Ep: 6.10 loss 0.095 score 0.412 lr 3.86264e-06 
12/02/2021 17:50:57 - INFO - volta.train_utils -   [NLVR2]: iter 16508 Ep: 6.12 loss 0.100 score 0.416 lr 3.85853e-06 
12/02/2021 17:51:18 - INFO - volta.train_utils -   [NLVR2]: iter 16548 Ep: 6.13 loss 0.093 score 0.403 lr 3.85441e-06 
12/02/2021 17:51:40 - INFO - volta.train_utils -   [NLVR2]: iter 16588 Ep: 6.15 loss 0.101 score 0.410 lr 3.85029e-06 
12/02/2021 17:52:01 - INFO - volta.train_utils -   [NLVR2]: iter 16628 Ep: 6.16 loss 0.094 score 0.405 lr 3.84618e-06 
12/02/2021 17:52:23 - INFO - volta.train_utils -   [NLVR2]: iter 16668 Ep: 6.18 loss 0.094 score 0.413 lr 3.84206e-06 
12/02/2021 17:52:45 - INFO - volta.train_utils -   [NLVR2]: iter 16708 Ep: 6.19 loss 0.090 score 0.416 lr 3.83794e-06 
12/02/2021 17:53:06 - INFO - volta.train_utils -   [NLVR2]: iter 16748 Ep: 6.21 loss 0.094 score 0.409 lr 3.83383e-06 
12/02/2021 17:53:28 - INFO - volta.train_utils -   [NLVR2]: iter 16788 Ep: 6.22 loss 0.094 score 0.404 lr 3.82971e-06 
12/02/2021 17:53:49 - INFO - volta.train_utils -   [NLVR2]: iter 16828 Ep: 6.23 loss 0.083 score 0.418 lr 3.82559e-06 
12/02/2021 17:54:11 - INFO - volta.train_utils -   [NLVR2]: iter 16868 Ep: 6.25 loss 0.092 score 0.414 lr 3.82148e-06 
12/02/2021 17:54:33 - INFO - volta.train_utils -   [NLVR2]: iter 16908 Ep: 6.26 loss 0.081 score 0.415 lr 3.81736e-06 
12/02/2021 17:54:54 - INFO - volta.train_utils -   [NLVR2]: iter 16948 Ep: 6.28 loss 0.090 score 0.421 lr 3.81324e-06 
12/02/2021 17:55:16 - INFO - volta.train_utils -   [NLVR2]: iter 16988 Ep: 6.29 loss 0.091 score 0.410 lr 3.80913e-06 
12/02/2021 17:55:37 - INFO - volta.train_utils -   [NLVR2]: iter 17028 Ep: 6.31 loss 0.091 score 0.410 lr 3.80501e-06 
12/02/2021 17:55:59 - INFO - volta.train_utils -   [NLVR2]: iter 17068 Ep: 6.32 loss 0.090 score 0.406 lr 3.80089e-06 
12/02/2021 17:56:21 - INFO - volta.train_utils -   [NLVR2]: iter 17108 Ep: 6.34 loss 0.079 score 0.423 lr 3.79678e-06 
12/02/2021 17:56:42 - INFO - volta.train_utils -   [NLVR2]: iter 17148 Ep: 6.35 loss 0.091 score 0.416 lr 3.79266e-06 
12/02/2021 17:57:04 - INFO - volta.train_utils -   [NLVR2]: iter 17188 Ep: 6.37 loss 0.090 score 0.411 lr 3.78854e-06 
12/02/2021 17:57:25 - INFO - volta.train_utils -   [NLVR2]: iter 17228 Ep: 6.38 loss 0.089 score 0.409 lr 3.78443e-06 
12/02/2021 17:57:47 - INFO - volta.train_utils -   [NLVR2]: iter 17268 Ep: 6.40 loss 0.082 score 0.415 lr 3.78031e-06 
12/02/2021 17:58:09 - INFO - volta.train_utils -   [NLVR2]: iter 17308 Ep: 6.41 loss 0.092 score 0.411 lr 3.77619e-06 
12/02/2021 17:58:30 - INFO - volta.train_utils -   [NLVR2]: iter 17348 Ep: 6.43 loss 0.080 score 0.420 lr 3.77208e-06 
12/02/2021 17:58:52 - INFO - volta.train_utils -   [NLVR2]: iter 17388 Ep: 6.44 loss 0.093 score 0.415 lr 3.76796e-06 
12/02/2021 17:59:13 - INFO - volta.train_utils -   [NLVR2]: iter 17428 Ep: 6.46 loss 0.088 score 0.414 lr 3.76384e-06 
12/02/2021 17:59:35 - INFO - volta.train_utils -   [NLVR2]: iter 17468 Ep: 6.47 loss 0.090 score 0.417 lr 3.75973e-06 
12/02/2021 17:59:57 - INFO - volta.train_utils -   [NLVR2]: iter 17508 Ep: 6.49 loss 0.085 score 0.422 lr 3.75561e-06 
12/02/2021 18:00:18 - INFO - volta.train_utils -   [NLVR2]: iter 17548 Ep: 6.50 loss 0.091 score 0.420 lr 3.75149e-06 
12/02/2021 18:00:39 - INFO - volta.train_utils -   [NLVR2]: iter 17588 Ep: 6.52 loss 0.086 score 0.417 lr 3.74738e-06 
12/02/2021 18:01:01 - INFO - volta.train_utils -   [NLVR2]: iter 17628 Ep: 6.53 loss 0.077 score 0.432 lr 3.74326e-06 
12/02/2021 18:01:23 - INFO - volta.train_utils -   [NLVR2]: iter 17668 Ep: 6.55 loss 0.087 score 0.421 lr 3.73914e-06 
12/02/2021 18:01:44 - INFO - volta.train_utils -   [NLVR2]: iter 17708 Ep: 6.56 loss 0.086 score 0.425 lr 3.73503e-06 
12/02/2021 18:02:06 - INFO - volta.train_utils -   [NLVR2]: iter 17748 Ep: 6.58 loss 0.084 score 0.422 lr 3.73091e-06 
12/02/2021 18:02:27 - INFO - volta.train_utils -   [NLVR2]: iter 17788 Ep: 6.59 loss 0.084 score 0.420 lr 3.72679e-06 
12/02/2021 18:02:49 - INFO - volta.train_utils -   [NLVR2]: iter 17828 Ep: 6.61 loss 0.086 score 0.418 lr 3.72268e-06 
12/02/2021 18:03:10 - INFO - volta.train_utils -   [NLVR2]: iter 17868 Ep: 6.62 loss 0.079 score 0.416 lr 3.71856e-06 
12/02/2021 18:03:32 - INFO - volta.train_utils -   [NLVR2]: iter 17908 Ep: 6.64 loss 0.084 score 0.414 lr 3.71444e-06 
12/02/2021 18:03:53 - INFO - volta.train_utils -   [NLVR2]: iter 17948 Ep: 6.65 loss 0.083 score 0.410 lr 3.71032e-06 
12/02/2021 18:04:15 - INFO - volta.train_utils -   [NLVR2]: iter 17988 Ep: 6.66 loss 0.084 score 0.420 lr 3.70621e-06 
12/02/2021 18:04:36 - INFO - volta.train_utils -   [NLVR2]: iter 18028 Ep: 6.68 loss 0.078 score 0.418 lr 3.70209e-06 
12/02/2021 18:04:58 - INFO - volta.train_utils -   [NLVR2]: iter 18068 Ep: 6.69 loss 0.088 score 0.419 lr 3.69797e-06 
12/02/2021 18:05:19 - INFO - volta.train_utils -   [NLVR2]: iter 18108 Ep: 6.71 loss 0.079 score 0.418 lr 3.69386e-06 
12/02/2021 18:05:41 - INFO - volta.train_utils -   [NLVR2]: iter 18148 Ep: 6.72 loss 0.082 score 0.421 lr 3.68974e-06 
12/02/2021 18:06:02 - INFO - volta.train_utils -   [NLVR2]: iter 18188 Ep: 6.74 loss 0.083 score 0.425 lr 3.68562e-06 
12/02/2021 18:06:24 - INFO - volta.train_utils -   [NLVR2]: iter 18228 Ep: 6.75 loss 0.084 score 0.420 lr 3.68151e-06 
12/02/2021 18:06:45 - INFO - volta.train_utils -   [NLVR2]: iter 18268 Ep: 6.77 loss 0.082 score 0.425 lr 3.67739e-06 
12/02/2021 18:07:07 - INFO - volta.train_utils -   [NLVR2]: iter 18308 Ep: 6.78 loss 0.081 score 0.419 lr 3.67327e-06 
12/02/2021 18:07:28 - INFO - volta.train_utils -   [NLVR2]: iter 18348 Ep: 6.80 loss 0.079 score 0.425 lr 3.66916e-06 
12/02/2021 18:07:50 - INFO - volta.train_utils -   [NLVR2]: iter 18388 Ep: 6.81 loss 0.085 score 0.418 lr 3.66504e-06 
12/02/2021 18:08:11 - INFO - volta.train_utils -   [NLVR2]: iter 18428 Ep: 6.83 loss 0.080 score 0.423 lr 3.66092e-06 
12/02/2021 18:08:32 - INFO - volta.train_utils -   [NLVR2]: iter 18468 Ep: 6.84 loss 0.093 score 0.417 lr 3.65681e-06 
12/02/2021 18:08:54 - INFO - volta.train_utils -   [NLVR2]: iter 18508 Ep: 6.86 loss 0.085 score 0.420 lr 3.65269e-06 
12/02/2021 18:09:16 - INFO - volta.train_utils -   [NLVR2]: iter 18548 Ep: 6.87 loss 0.088 score 0.428 lr 3.64857e-06 
12/02/2021 18:09:37 - INFO - volta.train_utils -   [NLVR2]: iter 18588 Ep: 6.89 loss 0.077 score 0.426 lr 3.64446e-06 
12/02/2021 18:09:59 - INFO - volta.train_utils -   [NLVR2]: iter 18628 Ep: 6.90 loss 0.091 score 0.405 lr 3.64034e-06 
12/02/2021 18:10:21 - INFO - volta.train_utils -   [NLVR2]: iter 18668 Ep: 6.92 loss 0.080 score 0.422 lr 3.63622e-06 
12/02/2021 18:10:42 - INFO - volta.train_utils -   [NLVR2]: iter 18708 Ep: 6.93 loss 0.077 score 0.420 lr 3.63211e-06 
12/02/2021 18:11:04 - INFO - volta.train_utils -   [NLVR2]: iter 18748 Ep: 6.95 loss 0.078 score 0.432 lr 3.62799e-06 
12/02/2021 18:11:25 - INFO - volta.train_utils -   [NLVR2]: iter 18788 Ep: 6.96 loss 0.076 score 0.430 lr 3.62387e-06 
12/02/2021 18:11:47 - INFO - volta.train_utils -   [NLVR2]: iter 18828 Ep: 6.98 loss 0.083 score 0.422 lr 3.61976e-06 
12/02/2021 18:12:08 - INFO - volta.train_utils -   [NLVR2]: iter 18868 Ep: 6.99 loss 0.085 score 0.418 lr 3.61564e-06 
12/02/2021 18:13:05 - INFO - volta.train_utils -   Eval task TASK12 on iteration 18886 
12/02/2021 18:13:05 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.734 score 71.488 
Epoch:  35%|      | 7/20 [2:57:25<5:28:43, 1517.23s/it]12/02/2021 18:13:27 - INFO - volta.train_utils -   [NLVR2]: iter 18926 Ep: 7.01 loss 0.074 score 0.438 lr 3.6106e-06 
12/02/2021 18:13:48 - INFO - volta.train_utils -   [NLVR2]: iter 18966 Ep: 7.03 loss 0.086 score 0.423 lr 3.60555e-06 
12/02/2021 18:14:10 - INFO - volta.train_utils -   [NLVR2]: iter 19006 Ep: 7.04 loss 0.085 score 0.411 lr 3.60144e-06 
12/02/2021 18:14:32 - INFO - volta.train_utils -   [NLVR2]: iter 19046 Ep: 7.06 loss 0.080 score 0.424 lr 3.59732e-06 
12/02/2021 18:14:53 - INFO - volta.train_utils -   [NLVR2]: iter 19086 Ep: 7.07 loss 0.078 score 0.424 lr 3.5932e-06 
12/02/2021 18:15:15 - INFO - volta.train_utils -   [NLVR2]: iter 19126 Ep: 7.09 loss 0.085 score 0.416 lr 3.58909e-06 
12/02/2021 18:15:36 - INFO - volta.train_utils -   [NLVR2]: iter 19166 Ep: 7.10 loss 0.088 score 0.418 lr 3.58497e-06 
12/02/2021 18:15:58 - INFO - volta.train_utils -   [NLVR2]: iter 19206 Ep: 7.12 loss 0.082 score 0.422 lr 3.58085e-06 
12/02/2021 18:16:19 - INFO - volta.train_utils -   [NLVR2]: iter 19246 Ep: 7.13 loss 0.081 score 0.415 lr 3.57674e-06 
12/02/2021 18:16:41 - INFO - volta.train_utils -   [NLVR2]: iter 19286 Ep: 7.15 loss 0.080 score 0.420 lr 3.57262e-06 
12/02/2021 18:17:02 - INFO - volta.train_utils -   [NLVR2]: iter 19326 Ep: 7.16 loss 0.075 score 0.425 lr 3.5685e-06 
12/02/2021 18:17:24 - INFO - volta.train_utils -   [NLVR2]: iter 19366 Ep: 7.18 loss 0.077 score 0.432 lr 3.56439e-06 
12/02/2021 18:17:45 - INFO - volta.train_utils -   [NLVR2]: iter 19406 Ep: 7.19 loss 0.078 score 0.425 lr 3.56027e-06 
12/02/2021 18:18:07 - INFO - volta.train_utils -   [NLVR2]: iter 19446 Ep: 7.20 loss 0.083 score 0.420 lr 3.55615e-06 
12/02/2021 18:18:28 - INFO - volta.train_utils -   [NLVR2]: iter 19486 Ep: 7.22 loss 0.075 score 0.429 lr 3.55204e-06 
12/02/2021 18:18:50 - INFO - volta.train_utils -   [NLVR2]: iter 19526 Ep: 7.23 loss 0.079 score 0.425 lr 3.54792e-06 
12/02/2021 18:19:11 - INFO - volta.train_utils -   [NLVR2]: iter 19566 Ep: 7.25 loss 0.085 score 0.418 lr 3.5438e-06 
12/02/2021 18:19:33 - INFO - volta.train_utils -   [NLVR2]: iter 19606 Ep: 7.26 loss 0.080 score 0.432 lr 3.53969e-06 
12/02/2021 18:19:54 - INFO - volta.train_utils -   [NLVR2]: iter 19646 Ep: 7.28 loss 0.073 score 0.431 lr 3.53557e-06 
12/02/2021 18:20:16 - INFO - volta.train_utils -   [NLVR2]: iter 19686 Ep: 7.29 loss 0.077 score 0.425 lr 3.53145e-06 
12/02/2021 18:20:37 - INFO - volta.train_utils -   [NLVR2]: iter 19726 Ep: 7.31 loss 0.088 score 0.421 lr 3.52734e-06 
12/02/2021 18:20:59 - INFO - volta.train_utils -   [NLVR2]: iter 19766 Ep: 7.32 loss 0.083 score 0.416 lr 3.52322e-06 
12/02/2021 18:21:20 - INFO - volta.train_utils -   [NLVR2]: iter 19806 Ep: 7.34 loss 0.078 score 0.434 lr 3.5191e-06 
12/02/2021 18:21:42 - INFO - volta.train_utils -   [NLVR2]: iter 19846 Ep: 7.35 loss 0.077 score 0.434 lr 3.51498e-06 
12/02/2021 18:22:03 - INFO - volta.train_utils -   [NLVR2]: iter 19886 Ep: 7.37 loss 0.085 score 0.427 lr 3.51087e-06 
12/02/2021 18:22:25 - INFO - volta.train_utils -   [NLVR2]: iter 19926 Ep: 7.38 loss 0.079 score 0.421 lr 3.50675e-06 
12/02/2021 18:22:46 - INFO - volta.train_utils -   [NLVR2]: iter 19966 Ep: 7.40 loss 0.077 score 0.416 lr 3.50263e-06 
12/02/2021 18:23:08 - INFO - volta.train_utils -   [NLVR2]: iter 20006 Ep: 7.41 loss 0.073 score 0.423 lr 3.49852e-06 
12/02/2021 18:23:30 - INFO - volta.train_utils -   [NLVR2]: iter 20046 Ep: 7.43 loss 0.073 score 0.426 lr 3.4944e-06 
12/02/2021 18:23:51 - INFO - volta.train_utils -   [NLVR2]: iter 20086 Ep: 7.44 loss 0.083 score 0.435 lr 3.49028e-06 
12/02/2021 18:24:13 - INFO - volta.train_utils -   [NLVR2]: iter 20126 Ep: 7.46 loss 0.068 score 0.432 lr 3.48617e-06 
12/02/2021 18:24:34 - INFO - volta.train_utils -   [NLVR2]: iter 20166 Ep: 7.47 loss 0.074 score 0.427 lr 3.48205e-06 
12/02/2021 18:24:56 - INFO - volta.train_utils -   [NLVR2]: iter 20206 Ep: 7.49 loss 0.075 score 0.425 lr 3.47793e-06 
12/02/2021 18:25:17 - INFO - volta.train_utils -   [NLVR2]: iter 20246 Ep: 7.50 loss 0.071 score 0.428 lr 3.47382e-06 
12/02/2021 18:25:39 - INFO - volta.train_utils -   [NLVR2]: iter 20286 Ep: 7.52 loss 0.084 score 0.430 lr 3.4697e-06 
12/02/2021 18:26:01 - INFO - volta.train_utils -   [NLVR2]: iter 20326 Ep: 7.53 loss 0.076 score 0.429 lr 3.46558e-06 
12/02/2021 18:26:22 - INFO - volta.train_utils -   [NLVR2]: iter 20366 Ep: 7.55 loss 0.076 score 0.434 lr 3.46147e-06 
12/02/2021 18:26:44 - INFO - volta.train_utils -   [NLVR2]: iter 20406 Ep: 7.56 loss 0.077 score 0.423 lr 3.45735e-06 
12/02/2021 18:27:05 - INFO - volta.train_utils -   [NLVR2]: iter 20446 Ep: 7.58 loss 0.081 score 0.424 lr 3.45323e-06 
12/02/2021 18:27:27 - INFO - volta.train_utils -   [NLVR2]: iter 20486 Ep: 7.59 loss 0.072 score 0.430 lr 3.44912e-06 
12/02/2021 18:27:48 - INFO - volta.train_utils -   [NLVR2]: iter 20526 Ep: 7.61 loss 0.076 score 0.424 lr 3.445e-06 
12/02/2021 18:28:10 - INFO - volta.train_utils -   [NLVR2]: iter 20566 Ep: 7.62 loss 0.073 score 0.431 lr 3.44088e-06 
12/02/2021 18:28:31 - INFO - volta.train_utils -   [NLVR2]: iter 20606 Ep: 7.63 loss 0.068 score 0.430 lr 3.43677e-06 
12/02/2021 18:28:53 - INFO - volta.train_utils -   [NLVR2]: iter 20646 Ep: 7.65 loss 0.073 score 0.435 lr 3.43265e-06 
12/02/2021 18:29:14 - INFO - volta.train_utils -   [NLVR2]: iter 20686 Ep: 7.66 loss 0.074 score 0.432 lr 3.42853e-06 
12/02/2021 18:29:36 - INFO - volta.train_utils -   [NLVR2]: iter 20726 Ep: 7.68 loss 0.080 score 0.423 lr 3.42442e-06 
12/02/2021 18:29:57 - INFO - volta.train_utils -   [NLVR2]: iter 20766 Ep: 7.69 loss 0.080 score 0.425 lr 3.4203e-06 
12/02/2021 18:30:19 - INFO - volta.train_utils -   [NLVR2]: iter 20806 Ep: 7.71 loss 0.076 score 0.428 lr 3.41618e-06 
12/02/2021 18:30:40 - INFO - volta.train_utils -   [NLVR2]: iter 20846 Ep: 7.72 loss 0.076 score 0.437 lr 3.41207e-06 
12/02/2021 18:31:02 - INFO - volta.train_utils -   [NLVR2]: iter 20886 Ep: 7.74 loss 0.070 score 0.423 lr 3.40795e-06 
12/02/2021 18:31:23 - INFO - volta.train_utils -   [NLVR2]: iter 20926 Ep: 7.75 loss 0.075 score 0.429 lr 3.40383e-06 
12/02/2021 18:31:45 - INFO - volta.train_utils -   [NLVR2]: iter 20966 Ep: 7.77 loss 0.067 score 0.432 lr 3.39972e-06 
12/02/2021 18:32:06 - INFO - volta.train_utils -   [NLVR2]: iter 21006 Ep: 7.78 loss 0.074 score 0.430 lr 3.3956e-06 
12/02/2021 18:32:28 - INFO - volta.train_utils -   [NLVR2]: iter 21046 Ep: 7.80 loss 0.077 score 0.426 lr 3.39148e-06 
12/02/2021 18:32:50 - INFO - volta.train_utils -   [NLVR2]: iter 21086 Ep: 7.81 loss 0.073 score 0.431 lr 3.38737e-06 
12/02/2021 18:33:11 - INFO - volta.train_utils -   [NLVR2]: iter 21126 Ep: 7.83 loss 0.068 score 0.436 lr 3.38325e-06 
12/02/2021 18:33:33 - INFO - volta.train_utils -   [NLVR2]: iter 21166 Ep: 7.84 loss 0.074 score 0.437 lr 3.37913e-06 
12/02/2021 18:33:54 - INFO - volta.train_utils -   [NLVR2]: iter 21206 Ep: 7.86 loss 0.080 score 0.426 lr 3.37502e-06 
12/02/2021 18:34:16 - INFO - volta.train_utils -   [NLVR2]: iter 21246 Ep: 7.87 loss 0.070 score 0.437 lr 3.3709e-06 
12/02/2021 18:34:37 - INFO - volta.train_utils -   [NLVR2]: iter 21286 Ep: 7.89 loss 0.075 score 0.437 lr 3.36678e-06 
12/02/2021 18:34:59 - INFO - volta.train_utils -   [NLVR2]: iter 21326 Ep: 7.90 loss 0.071 score 0.431 lr 3.36267e-06 
12/02/2021 18:35:20 - INFO - volta.train_utils -   [NLVR2]: iter 21366 Ep: 7.92 loss 0.074 score 0.434 lr 3.35855e-06 
12/02/2021 18:35:42 - INFO - volta.train_utils -   [NLVR2]: iter 21406 Ep: 7.93 loss 0.074 score 0.427 lr 3.35443e-06 
12/02/2021 18:36:03 - INFO - volta.train_utils -   [NLVR2]: iter 21446 Ep: 7.95 loss 0.069 score 0.429 lr 3.35031e-06 
12/02/2021 18:36:25 - INFO - volta.train_utils -   [NLVR2]: iter 21486 Ep: 7.96 loss 0.065 score 0.437 lr 3.3462e-06 
12/02/2021 18:36:46 - INFO - volta.train_utils -   [NLVR2]: iter 21526 Ep: 7.98 loss 0.068 score 0.429 lr 3.34208e-06 
12/02/2021 18:37:08 - INFO - volta.train_utils -   [NLVR2]: iter 21566 Ep: 7.99 loss 0.080 score 0.427 lr 3.33796e-06 
12/02/2021 18:38:04 - INFO - volta.train_utils -   Eval task TASK12 on iteration 21584 
12/02/2021 18:38:04 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.766 score 70.986 
Epoch:  40%|      | 8/20 [3:22:25<5:02:21, 1511.81s/it]12/02/2021 18:38:26 - INFO - volta.train_utils -   [NLVR2]: iter 21624 Ep: 8.01 loss 0.076 score 0.439 lr 3.33292e-06 
12/02/2021 18:38:48 - INFO - volta.train_utils -   [NLVR2]: iter 21664 Ep: 8.03 loss 0.074 score 0.431 lr 3.32788e-06 
12/02/2021 18:39:09 - INFO - volta.train_utils -   [NLVR2]: iter 21704 Ep: 8.04 loss 0.078 score 0.432 lr 3.32376e-06 
12/02/2021 18:39:31 - INFO - volta.train_utils -   [NLVR2]: iter 21744 Ep: 8.06 loss 0.071 score 0.435 lr 3.31965e-06 
12/02/2021 18:39:52 - INFO - volta.train_utils -   [NLVR2]: iter 21784 Ep: 8.07 loss 0.072 score 0.431 lr 3.31553e-06 
12/02/2021 18:40:14 - INFO - volta.train_utils -   [NLVR2]: iter 21824 Ep: 8.09 loss 0.068 score 0.424 lr 3.31141e-06 
12/02/2021 18:40:35 - INFO - volta.train_utils -   [NLVR2]: iter 21864 Ep: 8.10 loss 0.074 score 0.432 lr 3.30729e-06 
12/02/2021 18:40:57 - INFO - volta.train_utils -   [NLVR2]: iter 21904 Ep: 8.12 loss 0.083 score 0.430 lr 3.30318e-06 
12/02/2021 18:41:18 - INFO - volta.train_utils -   [NLVR2]: iter 21944 Ep: 8.13 loss 0.077 score 0.429 lr 3.29906e-06 
12/02/2021 18:41:40 - INFO - volta.train_utils -   [NLVR2]: iter 21984 Ep: 8.15 loss 0.069 score 0.429 lr 3.29494e-06 
12/02/2021 18:42:01 - INFO - volta.train_utils -   [NLVR2]: iter 22024 Ep: 8.16 loss 0.065 score 0.439 lr 3.29083e-06 
12/02/2021 18:42:23 - INFO - volta.train_utils -   [NLVR2]: iter 22064 Ep: 8.17 loss 0.070 score 0.436 lr 3.28671e-06 
12/02/2021 18:42:45 - INFO - volta.train_utils -   [NLVR2]: iter 22104 Ep: 8.19 loss 0.075 score 0.440 lr 3.28259e-06 
12/02/2021 18:43:06 - INFO - volta.train_utils -   [NLVR2]: iter 22144 Ep: 8.20 loss 0.077 score 0.432 lr 3.27848e-06 
12/02/2021 18:43:28 - INFO - volta.train_utils -   [NLVR2]: iter 22184 Ep: 8.22 loss 0.070 score 0.441 lr 3.27436e-06 
12/02/2021 18:43:49 - INFO - volta.train_utils -   [NLVR2]: iter 22224 Ep: 8.23 loss 0.067 score 0.432 lr 3.27024e-06 
12/02/2021 18:44:11 - INFO - volta.train_utils -   [NLVR2]: iter 22264 Ep: 8.25 loss 0.069 score 0.433 lr 3.26613e-06 
12/02/2021 18:44:32 - INFO - volta.train_utils -   [NLVR2]: iter 22304 Ep: 8.26 loss 0.072 score 0.434 lr 3.26201e-06 
12/02/2021 18:44:54 - INFO - volta.train_utils -   [NLVR2]: iter 22344 Ep: 8.28 loss 0.075 score 0.429 lr 3.25789e-06 
12/02/2021 18:45:15 - INFO - volta.train_utils -   [NLVR2]: iter 22384 Ep: 8.29 loss 0.070 score 0.439 lr 3.25378e-06 
12/02/2021 18:45:37 - INFO - volta.train_utils -   [NLVR2]: iter 22424 Ep: 8.31 loss 0.073 score 0.436 lr 3.24966e-06 
12/02/2021 18:45:58 - INFO - volta.train_utils -   [NLVR2]: iter 22464 Ep: 8.32 loss 0.069 score 0.433 lr 3.24554e-06 
12/02/2021 18:46:20 - INFO - volta.train_utils -   [NLVR2]: iter 22504 Ep: 8.34 loss 0.066 score 0.439 lr 3.24143e-06 
12/02/2021 18:46:41 - INFO - volta.train_utils -   [NLVR2]: iter 22544 Ep: 8.35 loss 0.067 score 0.432 lr 3.23731e-06 
12/02/2021 18:47:03 - INFO - volta.train_utils -   [NLVR2]: iter 22584 Ep: 8.37 loss 0.064 score 0.438 lr 3.23319e-06 
12/02/2021 18:47:24 - INFO - volta.train_utils -   [NLVR2]: iter 22624 Ep: 8.38 loss 0.067 score 0.437 lr 3.22908e-06 
12/02/2021 18:47:46 - INFO - volta.train_utils -   [NLVR2]: iter 22664 Ep: 8.40 loss 0.067 score 0.430 lr 3.22496e-06 
12/02/2021 18:48:08 - INFO - volta.train_utils -   [NLVR2]: iter 22704 Ep: 8.41 loss 0.071 score 0.438 lr 3.22084e-06 
12/02/2021 18:48:29 - INFO - volta.train_utils -   [NLVR2]: iter 22744 Ep: 8.43 loss 0.075 score 0.430 lr 3.21673e-06 
12/02/2021 18:48:51 - INFO - volta.train_utils -   [NLVR2]: iter 22784 Ep: 8.44 loss 0.063 score 0.436 lr 3.21261e-06 
12/02/2021 18:49:12 - INFO - volta.train_utils -   [NLVR2]: iter 22824 Ep: 8.46 loss 0.062 score 0.437 lr 3.20849e-06 
12/02/2021 18:49:34 - INFO - volta.train_utils -   [NLVR2]: iter 22864 Ep: 8.47 loss 0.068 score 0.434 lr 3.20438e-06 
12/02/2021 18:49:55 - INFO - volta.train_utils -   [NLVR2]: iter 22904 Ep: 8.49 loss 0.073 score 0.437 lr 3.20026e-06 
12/02/2021 18:50:17 - INFO - volta.train_utils -   [NLVR2]: iter 22944 Ep: 8.50 loss 0.078 score 0.431 lr 3.19614e-06 
12/02/2021 18:50:38 - INFO - volta.train_utils -   [NLVR2]: iter 22984 Ep: 8.52 loss 0.063 score 0.439 lr 3.19203e-06 
12/02/2021 18:51:00 - INFO - volta.train_utils -   [NLVR2]: iter 23024 Ep: 8.53 loss 0.074 score 0.432 lr 3.18791e-06 
12/02/2021 18:51:21 - INFO - volta.train_utils -   [NLVR2]: iter 23064 Ep: 8.55 loss 0.069 score 0.434 lr 3.18379e-06 
12/02/2021 18:51:43 - INFO - volta.train_utils -   [NLVR2]: iter 23104 Ep: 8.56 loss 0.067 score 0.443 lr 3.17968e-06 
12/02/2021 18:52:04 - INFO - volta.train_utils -   [NLVR2]: iter 23144 Ep: 8.58 loss 0.071 score 0.431 lr 3.17556e-06 
12/02/2021 18:52:26 - INFO - volta.train_utils -   [NLVR2]: iter 23184 Ep: 8.59 loss 0.067 score 0.439 lr 3.17144e-06 
12/02/2021 18:52:47 - INFO - volta.train_utils -   [NLVR2]: iter 23224 Ep: 8.60 loss 0.073 score 0.435 lr 3.16733e-06 
12/02/2021 18:53:09 - INFO - volta.train_utils -   [NLVR2]: iter 23264 Ep: 8.62 loss 0.073 score 0.435 lr 3.16321e-06 
12/02/2021 18:53:30 - INFO - volta.train_utils -   [NLVR2]: iter 23304 Ep: 8.63 loss 0.063 score 0.440 lr 3.15909e-06 
12/02/2021 18:53:52 - INFO - volta.train_utils -   [NLVR2]: iter 23344 Ep: 8.65 loss 0.083 score 0.431 lr 3.15498e-06 
12/02/2021 18:54:13 - INFO - volta.train_utils -   [NLVR2]: iter 23384 Ep: 8.66 loss 0.068 score 0.430 lr 3.15086e-06 
12/02/2021 18:54:35 - INFO - volta.train_utils -   [NLVR2]: iter 23424 Ep: 8.68 loss 0.075 score 0.432 lr 3.14674e-06 
12/02/2021 18:54:56 - INFO - volta.train_utils -   [NLVR2]: iter 23464 Ep: 8.69 loss 0.072 score 0.437 lr 3.14262e-06 
12/02/2021 18:55:18 - INFO - volta.train_utils -   [NLVR2]: iter 23504 Ep: 8.71 loss 0.067 score 0.432 lr 3.13851e-06 
12/02/2021 18:55:39 - INFO - volta.train_utils -   [NLVR2]: iter 23544 Ep: 8.72 loss 0.073 score 0.442 lr 3.13439e-06 
12/02/2021 18:56:01 - INFO - volta.train_utils -   [NLVR2]: iter 23584 Ep: 8.74 loss 0.062 score 0.438 lr 3.13027e-06 
12/02/2021 18:56:22 - INFO - volta.train_utils -   [NLVR2]: iter 23624 Ep: 8.75 loss 0.058 score 0.439 lr 3.12616e-06 
12/02/2021 18:56:44 - INFO - volta.train_utils -   [NLVR2]: iter 23664 Ep: 8.77 loss 0.065 score 0.441 lr 3.12204e-06 
12/02/2021 18:57:05 - INFO - volta.train_utils -   [NLVR2]: iter 23704 Ep: 8.78 loss 0.070 score 0.434 lr 3.11792e-06 
12/02/2021 18:57:27 - INFO - volta.train_utils -   [NLVR2]: iter 23744 Ep: 8.80 loss 0.074 score 0.436 lr 3.11381e-06 
12/02/2021 18:57:49 - INFO - volta.train_utils -   [NLVR2]: iter 23784 Ep: 8.81 loss 0.064 score 0.434 lr 3.10969e-06 
12/02/2021 18:58:10 - INFO - volta.train_utils -   [NLVR2]: iter 23824 Ep: 8.83 loss 0.063 score 0.444 lr 3.10557e-06 
12/02/2021 18:58:32 - INFO - volta.train_utils -   [NLVR2]: iter 23864 Ep: 8.84 loss 0.069 score 0.440 lr 3.10146e-06 
12/02/2021 18:58:53 - INFO - volta.train_utils -   [NLVR2]: iter 23904 Ep: 8.86 loss 0.060 score 0.440 lr 3.09734e-06 
12/02/2021 18:59:15 - INFO - volta.train_utils -   [NLVR2]: iter 23944 Ep: 8.87 loss 0.068 score 0.438 lr 3.09322e-06 
12/02/2021 18:59:37 - INFO - volta.train_utils -   [NLVR2]: iter 23984 Ep: 8.89 loss 0.070 score 0.438 lr 3.08911e-06 
12/02/2021 18:59:58 - INFO - volta.train_utils -   [NLVR2]: iter 24024 Ep: 8.90 loss 0.064 score 0.442 lr 3.08499e-06 
12/02/2021 19:00:20 - INFO - volta.train_utils -   [NLVR2]: iter 24064 Ep: 8.92 loss 0.074 score 0.438 lr 3.08087e-06 
12/02/2021 19:00:41 - INFO - volta.train_utils -   [NLVR2]: iter 24104 Ep: 8.93 loss 0.067 score 0.439 lr 3.07676e-06 
12/02/2021 19:01:03 - INFO - volta.train_utils -   [NLVR2]: iter 24144 Ep: 8.95 loss 0.063 score 0.441 lr 3.07264e-06 
12/02/2021 19:01:24 - INFO - volta.train_utils -   [NLVR2]: iter 24184 Ep: 8.96 loss 0.071 score 0.432 lr 3.06852e-06 
12/02/2021 19:01:46 - INFO - volta.train_utils -   [NLVR2]: iter 24224 Ep: 8.98 loss 0.066 score 0.441 lr 3.06441e-06 
12/02/2021 19:02:08 - INFO - volta.train_utils -   [NLVR2]: iter 24264 Ep: 8.99 loss 0.065 score 0.444 lr 3.06029e-06 
12/02/2021 19:03:03 - INFO - volta.train_utils -   Eval task TASK12 on iteration 24282 
12/02/2021 19:03:03 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.879 score 71.044 
Epoch:  45%|     | 9/20 [3:47:24<4:36:29, 1508.12s/it]12/02/2021 19:03:25 - INFO - volta.train_utils -   [NLVR2]: iter 24322 Ep: 9.01 loss 0.068 score 0.446 lr 3.05525e-06 
12/02/2021 19:03:47 - INFO - volta.train_utils -   [NLVR2]: iter 24362 Ep: 9.03 loss 0.065 score 0.438 lr 3.0502e-06 
12/02/2021 19:04:08 - INFO - volta.train_utils -   [NLVR2]: iter 24402 Ep: 9.04 loss 0.066 score 0.444 lr 3.04609e-06 
12/02/2021 19:04:30 - INFO - volta.train_utils -   [NLVR2]: iter 24442 Ep: 9.06 loss 0.061 score 0.445 lr 3.04197e-06 
12/02/2021 19:04:52 - INFO - volta.train_utils -   [NLVR2]: iter 24482 Ep: 9.07 loss 0.066 score 0.440 lr 3.03785e-06 
12/02/2021 19:05:13 - INFO - volta.train_utils -   [NLVR2]: iter 24522 Ep: 9.09 loss 0.061 score 0.442 lr 3.03374e-06 
12/02/2021 19:05:35 - INFO - volta.train_utils -   [NLVR2]: iter 24562 Ep: 9.10 loss 0.072 score 0.436 lr 3.02962e-06 
12/02/2021 19:05:56 - INFO - volta.train_utils -   [NLVR2]: iter 24602 Ep: 9.12 loss 0.061 score 0.442 lr 3.0255e-06 
12/02/2021 19:06:17 - INFO - volta.train_utils -   [NLVR2]: iter 24642 Ep: 9.13 loss 0.068 score 0.441 lr 3.02139e-06 
12/02/2021 19:06:39 - INFO - volta.train_utils -   [NLVR2]: iter 24682 Ep: 9.14 loss 0.064 score 0.444 lr 3.01727e-06 
12/02/2021 19:07:01 - INFO - volta.train_utils -   [NLVR2]: iter 24722 Ep: 9.16 loss 0.056 score 0.439 lr 3.01315e-06 
12/02/2021 19:07:22 - INFO - volta.train_utils -   [NLVR2]: iter 24762 Ep: 9.17 loss 0.068 score 0.446 lr 3.00904e-06 
12/02/2021 19:07:44 - INFO - volta.train_utils -   [NLVR2]: iter 24802 Ep: 9.19 loss 0.062 score 0.449 lr 3.00492e-06 
12/02/2021 19:08:05 - INFO - volta.train_utils -   [NLVR2]: iter 24842 Ep: 9.20 loss 0.062 score 0.439 lr 3.0008e-06 
12/02/2021 19:08:27 - INFO - volta.train_utils -   [NLVR2]: iter 24882 Ep: 9.22 loss 0.059 score 0.447 lr 2.99669e-06 
12/02/2021 19:08:48 - INFO - volta.train_utils -   [NLVR2]: iter 24922 Ep: 9.23 loss 0.060 score 0.446 lr 2.99257e-06 
12/02/2021 19:09:10 - INFO - volta.train_utils -   [NLVR2]: iter 24962 Ep: 9.25 loss 0.068 score 0.433 lr 2.98845e-06 
12/02/2021 19:09:31 - INFO - volta.train_utils -   [NLVR2]: iter 25002 Ep: 9.26 loss 0.068 score 0.445 lr 2.98434e-06 
12/02/2021 19:09:53 - INFO - volta.train_utils -   [NLVR2]: iter 25042 Ep: 9.28 loss 0.072 score 0.432 lr 2.98022e-06 
12/02/2021 19:10:14 - INFO - volta.train_utils -   [NLVR2]: iter 25082 Ep: 9.29 loss 0.060 score 0.439 lr 2.9761e-06 
12/02/2021 19:10:36 - INFO - volta.train_utils -   [NLVR2]: iter 25122 Ep: 9.31 loss 0.057 score 0.440 lr 2.97199e-06 
12/02/2021 19:10:57 - INFO - volta.train_utils -   [NLVR2]: iter 25162 Ep: 9.32 loss 0.069 score 0.445 lr 2.96787e-06 
12/02/2021 19:11:19 - INFO - volta.train_utils -   [NLVR2]: iter 25202 Ep: 9.34 loss 0.064 score 0.445 lr 2.96375e-06 
12/02/2021 19:11:40 - INFO - volta.train_utils -   [NLVR2]: iter 25242 Ep: 9.35 loss 0.061 score 0.440 lr 2.95964e-06 
12/02/2021 19:12:02 - INFO - volta.train_utils -   [NLVR2]: iter 25282 Ep: 9.37 loss 0.062 score 0.448 lr 2.95552e-06 
12/02/2021 19:12:23 - INFO - volta.train_utils -   [NLVR2]: iter 25322 Ep: 9.38 loss 0.064 score 0.442 lr 2.9514e-06 
12/02/2021 19:12:45 - INFO - volta.train_utils -   [NLVR2]: iter 25362 Ep: 9.40 loss 0.066 score 0.444 lr 2.94729e-06 
12/02/2021 19:13:06 - INFO - volta.train_utils -   [NLVR2]: iter 25402 Ep: 9.41 loss 0.059 score 0.445 lr 2.94317e-06 
12/02/2021 19:13:28 - INFO - volta.train_utils -   [NLVR2]: iter 25442 Ep: 9.43 loss 0.067 score 0.438 lr 2.93905e-06 
12/02/2021 19:13:49 - INFO - volta.train_utils -   [NLVR2]: iter 25482 Ep: 9.44 loss 0.061 score 0.445 lr 2.93493e-06 
12/02/2021 19:14:11 - INFO - volta.train_utils -   [NLVR2]: iter 25522 Ep: 9.46 loss 0.067 score 0.444 lr 2.93082e-06 
12/02/2021 19:14:32 - INFO - volta.train_utils -   [NLVR2]: iter 25562 Ep: 9.47 loss 0.062 score 0.445 lr 2.9267e-06 
12/02/2021 19:14:54 - INFO - volta.train_utils -   [NLVR2]: iter 25602 Ep: 9.49 loss 0.067 score 0.443 lr 2.92258e-06 
12/02/2021 19:15:15 - INFO - volta.train_utils -   [NLVR2]: iter 25642 Ep: 9.50 loss 0.066 score 0.443 lr 2.91847e-06 
12/02/2021 19:15:37 - INFO - volta.train_utils -   [NLVR2]: iter 25682 Ep: 9.52 loss 0.054 score 0.452 lr 2.91435e-06 
12/02/2021 19:15:58 - INFO - volta.train_utils -   [NLVR2]: iter 25722 Ep: 9.53 loss 0.056 score 0.451 lr 2.91023e-06 
12/02/2021 19:16:20 - INFO - volta.train_utils -   [NLVR2]: iter 25762 Ep: 9.55 loss 0.058 score 0.445 lr 2.90612e-06 
12/02/2021 19:16:41 - INFO - volta.train_utils -   [NLVR2]: iter 25802 Ep: 9.56 loss 0.055 score 0.441 lr 2.902e-06 
12/02/2021 19:17:03 - INFO - volta.train_utils -   [NLVR2]: iter 25842 Ep: 9.57 loss 0.069 score 0.443 lr 2.89788e-06 
12/02/2021 19:17:24 - INFO - volta.train_utils -   [NLVR2]: iter 25882 Ep: 9.59 loss 0.062 score 0.446 lr 2.89377e-06 
12/02/2021 19:17:46 - INFO - volta.train_utils -   [NLVR2]: iter 25922 Ep: 9.60 loss 0.057 score 0.449 lr 2.88965e-06 
12/02/2021 19:18:07 - INFO - volta.train_utils -   [NLVR2]: iter 25962 Ep: 9.62 loss 0.075 score 0.437 lr 2.88553e-06 
12/02/2021 19:18:29 - INFO - volta.train_utils -   [NLVR2]: iter 26002 Ep: 9.63 loss 0.062 score 0.445 lr 2.88142e-06 
12/02/2021 19:18:50 - INFO - volta.train_utils -   [NLVR2]: iter 26042 Ep: 9.65 loss 0.058 score 0.451 lr 2.8773e-06 
12/02/2021 19:19:12 - INFO - volta.train_utils -   [NLVR2]: iter 26082 Ep: 9.66 loss 0.058 score 0.449 lr 2.87318e-06 
12/02/2021 19:19:33 - INFO - volta.train_utils -   [NLVR2]: iter 26122 Ep: 9.68 loss 0.062 score 0.445 lr 2.86907e-06 
12/02/2021 19:19:55 - INFO - volta.train_utils -   [NLVR2]: iter 26162 Ep: 9.69 loss 0.061 score 0.448 lr 2.86495e-06 
12/02/2021 19:20:17 - INFO - volta.train_utils -   [NLVR2]: iter 26202 Ep: 9.71 loss 0.062 score 0.448 lr 2.86083e-06 
12/02/2021 19:20:38 - INFO - volta.train_utils -   [NLVR2]: iter 26242 Ep: 9.72 loss 0.059 score 0.438 lr 2.85672e-06 
12/02/2021 19:21:00 - INFO - volta.train_utils -   [NLVR2]: iter 26282 Ep: 9.74 loss 0.057 score 0.447 lr 2.8526e-06 
12/02/2021 19:21:21 - INFO - volta.train_utils -   [NLVR2]: iter 26322 Ep: 9.75 loss 0.053 score 0.448 lr 2.84848e-06 
12/02/2021 19:21:43 - INFO - volta.train_utils -   [NLVR2]: iter 26362 Ep: 9.77 loss 0.064 score 0.438 lr 2.84437e-06 
12/02/2021 19:22:04 - INFO - volta.train_utils -   [NLVR2]: iter 26402 Ep: 9.78 loss 0.063 score 0.445 lr 2.84025e-06 
12/02/2021 19:22:26 - INFO - volta.train_utils -   [NLVR2]: iter 26442 Ep: 9.80 loss 0.052 score 0.449 lr 2.83613e-06 
12/02/2021 19:22:47 - INFO - volta.train_utils -   [NLVR2]: iter 26482 Ep: 9.81 loss 0.068 score 0.439 lr 2.83202e-06 
12/02/2021 19:23:09 - INFO - volta.train_utils -   [NLVR2]: iter 26522 Ep: 9.83 loss 0.063 score 0.438 lr 2.8279e-06 
12/02/2021 19:23:30 - INFO - volta.train_utils -   [NLVR2]: iter 26562 Ep: 9.84 loss 0.065 score 0.452 lr 2.82378e-06 
12/02/2021 19:23:52 - INFO - volta.train_utils -   [NLVR2]: iter 26602 Ep: 9.86 loss 0.057 score 0.448 lr 2.81967e-06 
12/02/2021 19:24:13 - INFO - volta.train_utils -   [NLVR2]: iter 26642 Ep: 9.87 loss 0.057 score 0.452 lr 2.81555e-06 
12/02/2021 19:24:35 - INFO - volta.train_utils -   [NLVR2]: iter 26682 Ep: 9.89 loss 0.056 score 0.446 lr 2.81143e-06 
12/02/2021 19:24:56 - INFO - volta.train_utils -   [NLVR2]: iter 26722 Ep: 9.90 loss 0.053 score 0.444 lr 2.80732e-06 
12/02/2021 19:25:17 - INFO - volta.train_utils -   [NLVR2]: iter 26762 Ep: 9.92 loss 0.063 score 0.445 lr 2.8032e-06 
12/02/2021 19:25:39 - INFO - volta.train_utils -   [NLVR2]: iter 26802 Ep: 9.93 loss 0.061 score 0.450 lr 2.79908e-06 
12/02/2021 19:26:00 - INFO - volta.train_utils -   [NLVR2]: iter 26842 Ep: 9.95 loss 0.055 score 0.450 lr 2.79497e-06 
12/02/2021 19:26:22 - INFO - volta.train_utils -   [NLVR2]: iter 26882 Ep: 9.96 loss 0.057 score 0.449 lr 2.79085e-06 
12/02/2021 19:26:43 - INFO - volta.train_utils -   [NLVR2]: iter 26922 Ep: 9.97 loss 0.067 score 0.445 lr 2.78673e-06 
12/02/2021 19:27:05 - INFO - volta.train_utils -   [NLVR2]: iter 26962 Ep: 9.99 loss 0.048 score 0.451 lr 2.78261e-06 
12/02/2021 19:28:01 - INFO - volta.train_utils -   Eval task TASK12 on iteration 26980 
12/02/2021 19:28:01 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.940 score 71.044 
Epoch:  50%|     | 10/20 [4:12:22<4:10:50, 1505.05s/it]12/02/2021 19:28:23 - INFO - volta.train_utils -   [NLVR2]: iter 27020 Ep: 10.01 loss 0.061 score 0.456 lr 2.77757e-06 
12/02/2021 19:28:45 - INFO - volta.train_utils -   [NLVR2]: iter 27060 Ep: 10.03 loss 0.068 score 0.442 lr 2.77253e-06 
12/02/2021 19:29:06 - INFO - volta.train_utils -   [NLVR2]: iter 27100 Ep: 10.04 loss 0.062 score 0.441 lr 2.76841e-06 
12/02/2021 19:29:28 - INFO - volta.train_utils -   [NLVR2]: iter 27140 Ep: 10.06 loss 0.058 score 0.447 lr 2.7643e-06 
12/02/2021 19:29:49 - INFO - volta.train_utils -   [NLVR2]: iter 27180 Ep: 10.07 loss 0.057 score 0.445 lr 2.76018e-06 
12/02/2021 19:30:11 - INFO - volta.train_utils -   [NLVR2]: iter 27220 Ep: 10.09 loss 0.053 score 0.446 lr 2.75606e-06 
12/02/2021 19:30:32 - INFO - volta.train_utils -   [NLVR2]: iter 27260 Ep: 10.10 loss 0.051 score 0.450 lr 2.75195e-06 
12/02/2021 19:30:54 - INFO - volta.train_utils -   [NLVR2]: iter 27300 Ep: 10.11 loss 0.048 score 0.448 lr 2.74783e-06 
12/02/2021 19:31:15 - INFO - volta.train_utils -   [NLVR2]: iter 27340 Ep: 10.13 loss 0.057 score 0.448 lr 2.74371e-06 
12/02/2021 19:31:37 - INFO - volta.train_utils -   [NLVR2]: iter 27380 Ep: 10.14 loss 0.059 score 0.445 lr 2.73959e-06 
12/02/2021 19:31:58 - INFO - volta.train_utils -   [NLVR2]: iter 27420 Ep: 10.16 loss 0.057 score 0.449 lr 2.73548e-06 
12/02/2021 19:32:20 - INFO - volta.train_utils -   [NLVR2]: iter 27460 Ep: 10.17 loss 0.064 score 0.445 lr 2.73136e-06 
12/02/2021 19:32:41 - INFO - volta.train_utils -   [NLVR2]: iter 27500 Ep: 10.19 loss 0.063 score 0.444 lr 2.72724e-06 
12/02/2021 19:33:03 - INFO - volta.train_utils -   [NLVR2]: iter 27540 Ep: 10.20 loss 0.064 score 0.446 lr 2.72313e-06 
12/02/2021 19:33:24 - INFO - volta.train_utils -   [NLVR2]: iter 27580 Ep: 10.22 loss 0.055 score 0.450 lr 2.71901e-06 
12/02/2021 19:33:45 - INFO - volta.train_utils -   [NLVR2]: iter 27620 Ep: 10.23 loss 0.057 score 0.447 lr 2.71489e-06 
12/02/2021 19:34:07 - INFO - volta.train_utils -   [NLVR2]: iter 27660 Ep: 10.25 loss 0.055 score 0.452 lr 2.71078e-06 
12/02/2021 19:34:29 - INFO - volta.train_utils -   [NLVR2]: iter 27700 Ep: 10.26 loss 0.051 score 0.455 lr 2.70666e-06 
12/02/2021 19:34:50 - INFO - volta.train_utils -   [NLVR2]: iter 27740 Ep: 10.28 loss 0.053 score 0.449 lr 2.70254e-06 
12/02/2021 19:35:12 - INFO - volta.train_utils -   [NLVR2]: iter 27780 Ep: 10.29 loss 0.053 score 0.447 lr 2.69843e-06 
12/02/2021 19:35:33 - INFO - volta.train_utils -   [NLVR2]: iter 27820 Ep: 10.31 loss 0.054 score 0.450 lr 2.69431e-06 
12/02/2021 19:35:55 - INFO - volta.train_utils -   [NLVR2]: iter 27860 Ep: 10.32 loss 0.062 score 0.450 lr 2.69019e-06 
12/02/2021 19:36:17 - INFO - volta.train_utils -   [NLVR2]: iter 27900 Ep: 10.34 loss 0.060 score 0.452 lr 2.68608e-06 
12/02/2021 19:36:38 - INFO - volta.train_utils -   [NLVR2]: iter 27940 Ep: 10.35 loss 0.052 score 0.454 lr 2.68196e-06 
12/02/2021 19:37:00 - INFO - volta.train_utils -   [NLVR2]: iter 27980 Ep: 10.37 loss 0.066 score 0.447 lr 2.67784e-06 
12/02/2021 19:37:21 - INFO - volta.train_utils -   [NLVR2]: iter 28020 Ep: 10.38 loss 0.057 score 0.448 lr 2.67373e-06 
12/02/2021 19:37:43 - INFO - volta.train_utils -   [NLVR2]: iter 28060 Ep: 10.40 loss 0.048 score 0.450 lr 2.66961e-06 
12/02/2021 19:38:04 - INFO - volta.train_utils -   [NLVR2]: iter 28100 Ep: 10.41 loss 0.061 score 0.448 lr 2.66549e-06 
12/02/2021 19:38:26 - INFO - volta.train_utils -   [NLVR2]: iter 28140 Ep: 10.43 loss 0.057 score 0.453 lr 2.66138e-06 
12/02/2021 19:38:47 - INFO - volta.train_utils -   [NLVR2]: iter 28180 Ep: 10.44 loss 0.054 score 0.449 lr 2.65726e-06 
12/02/2021 19:39:09 - INFO - volta.train_utils -   [NLVR2]: iter 28220 Ep: 10.46 loss 0.060 score 0.441 lr 2.65314e-06 
12/02/2021 19:39:31 - INFO - volta.train_utils -   [NLVR2]: iter 28260 Ep: 10.47 loss 0.059 score 0.447 lr 2.64903e-06 
12/02/2021 19:39:52 - INFO - volta.train_utils -   [NLVR2]: iter 28300 Ep: 10.49 loss 0.063 score 0.449 lr 2.64491e-06 
12/02/2021 19:40:13 - INFO - volta.train_utils -   [NLVR2]: iter 28340 Ep: 10.50 loss 0.053 score 0.448 lr 2.64079e-06 
12/02/2021 19:40:35 - INFO - volta.train_utils -   [NLVR2]: iter 28380 Ep: 10.52 loss 0.051 score 0.454 lr 2.63668e-06 
12/02/2021 19:40:56 - INFO - volta.train_utils -   [NLVR2]: iter 28420 Ep: 10.53 loss 0.055 score 0.452 lr 2.63256e-06 
12/02/2021 19:41:18 - INFO - volta.train_utils -   [NLVR2]: iter 28460 Ep: 10.54 loss 0.054 score 0.451 lr 2.62844e-06 
12/02/2021 19:41:39 - INFO - volta.train_utils -   [NLVR2]: iter 28500 Ep: 10.56 loss 0.053 score 0.457 lr 2.62433e-06 
12/02/2021 19:42:01 - INFO - volta.train_utils -   [NLVR2]: iter 28540 Ep: 10.57 loss 0.051 score 0.454 lr 2.62021e-06 
12/02/2021 19:42:22 - INFO - volta.train_utils -   [NLVR2]: iter 28580 Ep: 10.59 loss 0.056 score 0.448 lr 2.61609e-06 
12/02/2021 19:42:44 - INFO - volta.train_utils -   [NLVR2]: iter 28620 Ep: 10.60 loss 0.051 score 0.452 lr 2.61198e-06 
12/02/2021 19:43:05 - INFO - volta.train_utils -   [NLVR2]: iter 28660 Ep: 10.62 loss 0.058 score 0.454 lr 2.60786e-06 
12/02/2021 19:43:27 - INFO - volta.train_utils -   [NLVR2]: iter 28700 Ep: 10.63 loss 0.058 score 0.448 lr 2.60374e-06 
12/02/2021 19:43:48 - INFO - volta.train_utils -   [NLVR2]: iter 28740 Ep: 10.65 loss 0.051 score 0.457 lr 2.59963e-06 
12/02/2021 19:44:10 - INFO - volta.train_utils -   [NLVR2]: iter 28780 Ep: 10.66 loss 0.047 score 0.454 lr 2.59551e-06 
12/02/2021 19:44:31 - INFO - volta.train_utils -   [NLVR2]: iter 28820 Ep: 10.68 loss 0.055 score 0.449 lr 2.59139e-06 
12/02/2021 19:44:53 - INFO - volta.train_utils -   [NLVR2]: iter 28860 Ep: 10.69 loss 0.053 score 0.451 lr 2.58728e-06 
12/02/2021 19:45:14 - INFO - volta.train_utils -   [NLVR2]: iter 28900 Ep: 10.71 loss 0.051 score 0.460 lr 2.58316e-06 
12/02/2021 19:45:36 - INFO - volta.train_utils -   [NLVR2]: iter 28940 Ep: 10.72 loss 0.061 score 0.443 lr 2.57904e-06 
12/02/2021 19:45:58 - INFO - volta.train_utils -   [NLVR2]: iter 28980 Ep: 10.74 loss 0.063 score 0.448 lr 2.57492e-06 
12/02/2021 19:46:19 - INFO - volta.train_utils -   [NLVR2]: iter 29020 Ep: 10.75 loss 0.059 score 0.448 lr 2.57081e-06 
12/02/2021 19:46:41 - INFO - volta.train_utils -   [NLVR2]: iter 29060 Ep: 10.77 loss 0.061 score 0.445 lr 2.56669e-06 
12/02/2021 19:47:02 - INFO - volta.train_utils -   [NLVR2]: iter 29100 Ep: 10.78 loss 0.052 score 0.457 lr 2.56257e-06 
12/02/2021 19:47:24 - INFO - volta.train_utils -   [NLVR2]: iter 29140 Ep: 10.80 loss 0.054 score 0.452 lr 2.55846e-06 
12/02/2021 19:47:45 - INFO - volta.train_utils -   [NLVR2]: iter 29180 Ep: 10.81 loss 0.046 score 0.455 lr 2.55434e-06 
12/02/2021 19:48:07 - INFO - volta.train_utils -   [NLVR2]: iter 29220 Ep: 10.83 loss 0.050 score 0.451 lr 2.55022e-06 
12/02/2021 19:48:28 - INFO - volta.train_utils -   [NLVR2]: iter 29260 Ep: 10.84 loss 0.062 score 0.449 lr 2.54611e-06 
12/02/2021 19:48:50 - INFO - volta.train_utils -   [NLVR2]: iter 29300 Ep: 10.86 loss 0.057 score 0.454 lr 2.54199e-06 
12/02/2021 19:49:12 - INFO - volta.train_utils -   [NLVR2]: iter 29340 Ep: 10.87 loss 0.053 score 0.450 lr 2.53787e-06 
12/02/2021 19:49:33 - INFO - volta.train_utils -   [NLVR2]: iter 29380 Ep: 10.89 loss 0.049 score 0.459 lr 2.53376e-06 
12/02/2021 19:49:55 - INFO - volta.train_utils -   [NLVR2]: iter 29420 Ep: 10.90 loss 0.049 score 0.455 lr 2.52964e-06 
12/02/2021 19:50:16 - INFO - volta.train_utils -   [NLVR2]: iter 29460 Ep: 10.92 loss 0.054 score 0.457 lr 2.52552e-06 
12/02/2021 19:50:38 - INFO - volta.train_utils -   [NLVR2]: iter 29500 Ep: 10.93 loss 0.053 score 0.453 lr 2.52141e-06 
12/02/2021 19:50:59 - INFO - volta.train_utils -   [NLVR2]: iter 29540 Ep: 10.94 loss 0.056 score 0.454 lr 2.51729e-06 
12/02/2021 19:51:21 - INFO - volta.train_utils -   [NLVR2]: iter 29580 Ep: 10.96 loss 0.043 score 0.459 lr 2.51317e-06 
12/02/2021 19:51:42 - INFO - volta.train_utils -   [NLVR2]: iter 29620 Ep: 10.97 loss 0.046 score 0.457 lr 2.50906e-06 
12/02/2021 19:52:04 - INFO - volta.train_utils -   [NLVR2]: iter 29660 Ep: 10.99 loss 0.061 score 0.452 lr 2.50494e-06 
12/02/2021 19:53:00 - INFO - volta.train_utils -   Eval task TASK12 on iteration 29678 
12/02/2021 19:53:00 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.993 score 71.388 
Epoch:  55%|    | 11/20 [4:37:21<3:45:29, 1503.25s/it]12/02/2021 19:53:23 - INFO - volta.train_utils -   [NLVR2]: iter 29718 Ep: 11.01 loss 0.045 score 0.465 lr 2.4999e-06 
12/02/2021 19:53:44 - INFO - volta.train_utils -   [NLVR2]: iter 29758 Ep: 11.03 loss 0.060 score 0.446 lr 2.49485e-06 
12/02/2021 19:54:05 - INFO - volta.train_utils -   [NLVR2]: iter 29798 Ep: 11.04 loss 0.053 score 0.451 lr 2.49074e-06 
12/02/2021 19:54:27 - INFO - volta.train_utils -   [NLVR2]: iter 29838 Ep: 11.06 loss 0.050 score 0.459 lr 2.48662e-06 
12/02/2021 19:54:49 - INFO - volta.train_utils -   [NLVR2]: iter 29878 Ep: 11.07 loss 0.048 score 0.458 lr 2.4825e-06 
12/02/2021 19:55:10 - INFO - volta.train_utils -   [NLVR2]: iter 29918 Ep: 11.08 loss 0.047 score 0.455 lr 2.47839e-06 
12/02/2021 19:55:31 - INFO - volta.train_utils -   [NLVR2]: iter 29958 Ep: 11.10 loss 0.049 score 0.451 lr 2.47427e-06 
12/02/2021 19:55:53 - INFO - volta.train_utils -   [NLVR2]: iter 29998 Ep: 11.11 loss 0.055 score 0.455 lr 2.47015e-06 
12/02/2021 19:56:14 - INFO - volta.train_utils -   [NLVR2]: iter 30038 Ep: 11.13 loss 0.050 score 0.455 lr 2.46604e-06 
12/02/2021 19:56:36 - INFO - volta.train_utils -   [NLVR2]: iter 30078 Ep: 11.14 loss 0.050 score 0.455 lr 2.46192e-06 
12/02/2021 19:56:58 - INFO - volta.train_utils -   [NLVR2]: iter 30118 Ep: 11.16 loss 0.051 score 0.452 lr 2.4578e-06 
12/02/2021 19:57:19 - INFO - volta.train_utils -   [NLVR2]: iter 30158 Ep: 11.17 loss 0.059 score 0.454 lr 2.45369e-06 
12/02/2021 19:57:40 - INFO - volta.train_utils -   [NLVR2]: iter 30198 Ep: 11.19 loss 0.054 score 0.451 lr 2.44957e-06 
12/02/2021 19:58:02 - INFO - volta.train_utils -   [NLVR2]: iter 30238 Ep: 11.20 loss 0.049 score 0.457 lr 2.44545e-06 
12/02/2021 19:58:23 - INFO - volta.train_utils -   [NLVR2]: iter 30278 Ep: 11.22 loss 0.050 score 0.451 lr 2.44134e-06 
12/02/2021 19:58:45 - INFO - volta.train_utils -   [NLVR2]: iter 30318 Ep: 11.23 loss 0.048 score 0.458 lr 2.43722e-06 
12/02/2021 19:59:06 - INFO - volta.train_utils -   [NLVR2]: iter 30358 Ep: 11.25 loss 0.048 score 0.456 lr 2.4331e-06 
12/02/2021 19:59:28 - INFO - volta.train_utils -   [NLVR2]: iter 30398 Ep: 11.26 loss 0.047 score 0.457 lr 2.42899e-06 
12/02/2021 19:59:49 - INFO - volta.train_utils -   [NLVR2]: iter 30438 Ep: 11.28 loss 0.062 score 0.448 lr 2.42487e-06 
12/02/2021 20:00:11 - INFO - volta.train_utils -   [NLVR2]: iter 30478 Ep: 11.29 loss 0.049 score 0.449 lr 2.42075e-06 
12/02/2021 20:00:32 - INFO - volta.train_utils -   [NLVR2]: iter 30518 Ep: 11.31 loss 0.054 score 0.455 lr 2.41664e-06 
12/02/2021 20:00:54 - INFO - volta.train_utils -   [NLVR2]: iter 30558 Ep: 11.32 loss 0.058 score 0.448 lr 2.41252e-06 
12/02/2021 20:01:15 - INFO - volta.train_utils -   [NLVR2]: iter 30598 Ep: 11.34 loss 0.052 score 0.452 lr 2.4084e-06 
12/02/2021 20:01:37 - INFO - volta.train_utils -   [NLVR2]: iter 30638 Ep: 11.35 loss 0.054 score 0.456 lr 2.40429e-06 
12/02/2021 20:01:58 - INFO - volta.train_utils -   [NLVR2]: iter 30678 Ep: 11.37 loss 0.045 score 0.457 lr 2.40017e-06 
12/02/2021 20:02:19 - INFO - volta.train_utils -   [NLVR2]: iter 30718 Ep: 11.38 loss 0.045 score 0.465 lr 2.39605e-06 
12/02/2021 20:02:41 - INFO - volta.train_utils -   [NLVR2]: iter 30758 Ep: 11.40 loss 0.054 score 0.447 lr 2.39194e-06 
12/02/2021 20:03:02 - INFO - volta.train_utils -   [NLVR2]: iter 30798 Ep: 11.41 loss 0.052 score 0.450 lr 2.38782e-06 
12/02/2021 20:03:24 - INFO - volta.train_utils -   [NLVR2]: iter 30838 Ep: 11.43 loss 0.047 score 0.457 lr 2.3837e-06 
12/02/2021 20:03:46 - INFO - volta.train_utils -   [NLVR2]: iter 30878 Ep: 11.44 loss 0.053 score 0.454 lr 2.37959e-06 
12/02/2021 20:04:07 - INFO - volta.train_utils -   [NLVR2]: iter 30918 Ep: 11.46 loss 0.050 score 0.456 lr 2.37547e-06 
12/02/2021 20:04:29 - INFO - volta.train_utils -   [NLVR2]: iter 30958 Ep: 11.47 loss 0.045 score 0.464 lr 2.37135e-06 
12/02/2021 20:04:50 - INFO - volta.train_utils -   [NLVR2]: iter 30998 Ep: 11.48 loss 0.045 score 0.463 lr 2.36723e-06 
12/02/2021 20:05:12 - INFO - volta.train_utils -   [NLVR2]: iter 31038 Ep: 11.50 loss 0.057 score 0.456 lr 2.36312e-06 
12/02/2021 20:05:33 - INFO - volta.train_utils -   [NLVR2]: iter 31078 Ep: 11.51 loss 0.051 score 0.452 lr 2.359e-06 
12/02/2021 20:05:55 - INFO - volta.train_utils -   [NLVR2]: iter 31118 Ep: 11.53 loss 0.048 score 0.449 lr 2.35488e-06 
12/02/2021 20:06:17 - INFO - volta.train_utils -   [NLVR2]: iter 31158 Ep: 11.54 loss 0.054 score 0.458 lr 2.35077e-06 
12/02/2021 20:06:38 - INFO - volta.train_utils -   [NLVR2]: iter 31198 Ep: 11.56 loss 0.053 score 0.462 lr 2.34665e-06 
12/02/2021 20:07:00 - INFO - volta.train_utils -   [NLVR2]: iter 31238 Ep: 11.57 loss 0.045 score 0.457 lr 2.34253e-06 
12/02/2021 20:07:21 - INFO - volta.train_utils -   [NLVR2]: iter 31278 Ep: 11.59 loss 0.049 score 0.454 lr 2.33842e-06 
12/02/2021 20:07:43 - INFO - volta.train_utils -   [NLVR2]: iter 31318 Ep: 11.60 loss 0.054 score 0.460 lr 2.3343e-06 
12/02/2021 20:08:04 - INFO - volta.train_utils -   [NLVR2]: iter 31358 Ep: 11.62 loss 0.047 score 0.452 lr 2.33018e-06 
12/02/2021 20:08:26 - INFO - volta.train_utils -   [NLVR2]: iter 31398 Ep: 11.63 loss 0.049 score 0.456 lr 2.32607e-06 
12/02/2021 20:08:48 - INFO - volta.train_utils -   [NLVR2]: iter 31438 Ep: 11.65 loss 0.052 score 0.456 lr 2.32195e-06 
12/02/2021 20:09:09 - INFO - volta.train_utils -   [NLVR2]: iter 31478 Ep: 11.66 loss 0.046 score 0.467 lr 2.31783e-06 
12/02/2021 20:09:31 - INFO - volta.train_utils -   [NLVR2]: iter 31518 Ep: 11.68 loss 0.055 score 0.456 lr 2.31372e-06 
12/02/2021 20:09:52 - INFO - volta.train_utils -   [NLVR2]: iter 31558 Ep: 11.69 loss 0.042 score 0.457 lr 2.3096e-06 
12/02/2021 20:10:14 - INFO - volta.train_utils -   [NLVR2]: iter 31598 Ep: 11.71 loss 0.055 score 0.455 lr 2.30548e-06 
12/02/2021 20:10:35 - INFO - volta.train_utils -   [NLVR2]: iter 31638 Ep: 11.72 loss 0.046 score 0.457 lr 2.30137e-06 
12/02/2021 20:10:56 - INFO - volta.train_utils -   [NLVR2]: iter 31678 Ep: 11.74 loss 0.044 score 0.457 lr 2.29725e-06 
12/02/2021 20:11:18 - INFO - volta.train_utils -   [NLVR2]: iter 31718 Ep: 11.75 loss 0.040 score 0.461 lr 2.29313e-06 
12/02/2021 20:11:39 - INFO - volta.train_utils -   [NLVR2]: iter 31758 Ep: 11.77 loss 0.060 score 0.456 lr 2.28902e-06 
12/02/2021 20:12:01 - INFO - volta.train_utils -   [NLVR2]: iter 31798 Ep: 11.78 loss 0.045 score 0.463 lr 2.2849e-06 
12/02/2021 20:12:22 - INFO - volta.train_utils -   [NLVR2]: iter 31838 Ep: 11.80 loss 0.045 score 0.457 lr 2.28078e-06 
12/02/2021 20:12:44 - INFO - volta.train_utils -   [NLVR2]: iter 31878 Ep: 11.81 loss 0.049 score 0.457 lr 2.27667e-06 
12/02/2021 20:13:06 - INFO - volta.train_utils -   [NLVR2]: iter 31918 Ep: 11.83 loss 0.040 score 0.461 lr 2.27255e-06 
12/02/2021 20:13:27 - INFO - volta.train_utils -   [NLVR2]: iter 31958 Ep: 11.84 loss 0.046 score 0.464 lr 2.26843e-06 
12/02/2021 20:13:49 - INFO - volta.train_utils -   [NLVR2]: iter 31998 Ep: 11.86 loss 0.048 score 0.462 lr 2.26432e-06 
12/02/2021 20:14:10 - INFO - volta.train_utils -   [NLVR2]: iter 32038 Ep: 11.87 loss 0.049 score 0.456 lr 2.2602e-06 
12/02/2021 20:14:32 - INFO - volta.train_utils -   [NLVR2]: iter 32078 Ep: 11.89 loss 0.050 score 0.458 lr 2.25608e-06 
12/02/2021 20:14:53 - INFO - volta.train_utils -   [NLVR2]: iter 32118 Ep: 11.90 loss 0.058 score 0.456 lr 2.25197e-06 
12/02/2021 20:15:15 - INFO - volta.train_utils -   [NLVR2]: iter 32158 Ep: 11.91 loss 0.049 score 0.460 lr 2.24785e-06 
12/02/2021 20:15:36 - INFO - volta.train_utils -   [NLVR2]: iter 32198 Ep: 11.93 loss 0.045 score 0.463 lr 2.24373e-06 
12/02/2021 20:15:58 - INFO - volta.train_utils -   [NLVR2]: iter 32238 Ep: 11.94 loss 0.047 score 0.459 lr 2.23962e-06 
12/02/2021 20:16:19 - INFO - volta.train_utils -   [NLVR2]: iter 32278 Ep: 11.96 loss 0.051 score 0.464 lr 2.2355e-06 
12/02/2021 20:16:41 - INFO - volta.train_utils -   [NLVR2]: iter 32318 Ep: 11.97 loss 0.048 score 0.461 lr 2.23138e-06 
12/02/2021 20:17:02 - INFO - volta.train_utils -   [NLVR2]: iter 32358 Ep: 11.99 loss 0.056 score 0.455 lr 2.22727e-06 
12/02/2021 20:17:59 - INFO - volta.train_utils -   Eval task TASK12 on iteration 32376 
12/02/2021 20:17:59 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.034 score 71.373 
Epoch:  60%|    | 12/20 [5:02:19<3:20:14, 1501.78s/it]12/02/2021 20:18:21 - INFO - volta.train_utils -   [NLVR2]: iter 32416 Ep: 12.01 loss 0.047 score 0.466 lr 2.22222e-06 
12/02/2021 20:18:42 - INFO - volta.train_utils -   [NLVR2]: iter 32456 Ep: 12.03 loss 0.048 score 0.451 lr 2.21718e-06 
12/02/2021 20:19:04 - INFO - volta.train_utils -   [NLVR2]: iter 32496 Ep: 12.04 loss 0.049 score 0.460 lr 2.21306e-06 
12/02/2021 20:19:25 - INFO - volta.train_utils -   [NLVR2]: iter 32536 Ep: 12.05 loss 0.043 score 0.456 lr 2.20895e-06 
12/02/2021 20:19:47 - INFO - volta.train_utils -   [NLVR2]: iter 32576 Ep: 12.07 loss 0.046 score 0.463 lr 2.20483e-06 
12/02/2021 20:20:08 - INFO - volta.train_utils -   [NLVR2]: iter 32616 Ep: 12.08 loss 0.042 score 0.464 lr 2.20071e-06 
12/02/2021 20:20:30 - INFO - volta.train_utils -   [NLVR2]: iter 32656 Ep: 12.10 loss 0.050 score 0.459 lr 2.1966e-06 
12/02/2021 20:20:52 - INFO - volta.train_utils -   [NLVR2]: iter 32696 Ep: 12.11 loss 0.046 score 0.461 lr 2.19248e-06 
12/02/2021 20:21:13 - INFO - volta.train_utils -   [NLVR2]: iter 32736 Ep: 12.13 loss 0.054 score 0.450 lr 2.18836e-06 
12/02/2021 20:21:35 - INFO - volta.train_utils -   [NLVR2]: iter 32776 Ep: 12.14 loss 0.043 score 0.466 lr 2.18425e-06 
12/02/2021 20:21:56 - INFO - volta.train_utils -   [NLVR2]: iter 32816 Ep: 12.16 loss 0.047 score 0.461 lr 2.18013e-06 
12/02/2021 20:22:18 - INFO - volta.train_utils -   [NLVR2]: iter 32856 Ep: 12.17 loss 0.042 score 0.459 lr 2.17601e-06 
12/02/2021 20:22:39 - INFO - volta.train_utils -   [NLVR2]: iter 32896 Ep: 12.19 loss 0.060 score 0.457 lr 2.17189e-06 
12/02/2021 20:23:01 - INFO - volta.train_utils -   [NLVR2]: iter 32936 Ep: 12.20 loss 0.045 score 0.454 lr 2.16778e-06 
12/02/2021 20:23:22 - INFO - volta.train_utils -   [NLVR2]: iter 32976 Ep: 12.22 loss 0.052 score 0.461 lr 2.16366e-06 
12/02/2021 20:23:44 - INFO - volta.train_utils -   [NLVR2]: iter 33016 Ep: 12.23 loss 0.053 score 0.457 lr 2.15954e-06 
12/02/2021 20:24:05 - INFO - volta.train_utils -   [NLVR2]: iter 33056 Ep: 12.25 loss 0.045 score 0.463 lr 2.15543e-06 
12/02/2021 20:24:27 - INFO - volta.train_utils -   [NLVR2]: iter 33096 Ep: 12.26 loss 0.050 score 0.461 lr 2.15131e-06 
12/02/2021 20:24:49 - INFO - volta.train_utils -   [NLVR2]: iter 33136 Ep: 12.28 loss 0.046 score 0.461 lr 2.14719e-06 
12/02/2021 20:25:10 - INFO - volta.train_utils -   [NLVR2]: iter 33176 Ep: 12.29 loss 0.050 score 0.454 lr 2.14308e-06 
12/02/2021 20:25:32 - INFO - volta.train_utils -   [NLVR2]: iter 33216 Ep: 12.31 loss 0.044 score 0.457 lr 2.13896e-06 
12/02/2021 20:25:54 - INFO - volta.train_utils -   [NLVR2]: iter 33256 Ep: 12.32 loss 0.044 score 0.469 lr 2.13484e-06 
12/02/2021 20:26:15 - INFO - volta.train_utils -   [NLVR2]: iter 33296 Ep: 12.34 loss 0.046 score 0.459 lr 2.13073e-06 
12/02/2021 20:26:37 - INFO - volta.train_utils -   [NLVR2]: iter 33336 Ep: 12.35 loss 0.052 score 0.456 lr 2.12661e-06 
12/02/2021 20:26:58 - INFO - volta.train_utils -   [NLVR2]: iter 33376 Ep: 12.37 loss 0.052 score 0.459 lr 2.12249e-06 
12/02/2021 20:27:20 - INFO - volta.train_utils -   [NLVR2]: iter 33416 Ep: 12.38 loss 0.050 score 0.461 lr 2.11838e-06 
12/02/2021 20:27:41 - INFO - volta.train_utils -   [NLVR2]: iter 33456 Ep: 12.40 loss 0.044 score 0.461 lr 2.11426e-06 
12/02/2021 20:28:03 - INFO - volta.train_utils -   [NLVR2]: iter 33496 Ep: 12.41 loss 0.048 score 0.456 lr 2.11014e-06 
12/02/2021 20:28:25 - INFO - volta.train_utils -   [NLVR2]: iter 33536 Ep: 12.43 loss 0.046 score 0.464 lr 2.10603e-06 
12/02/2021 20:28:46 - INFO - volta.train_utils -   [NLVR2]: iter 33576 Ep: 12.44 loss 0.045 score 0.457 lr 2.10191e-06 
12/02/2021 20:29:08 - INFO - volta.train_utils -   [NLVR2]: iter 33616 Ep: 12.45 loss 0.051 score 0.456 lr 2.09779e-06 
12/02/2021 20:29:29 - INFO - volta.train_utils -   [NLVR2]: iter 33656 Ep: 12.47 loss 0.052 score 0.454 lr 2.09368e-06 
12/02/2021 20:29:50 - INFO - volta.train_utils -   [NLVR2]: iter 33696 Ep: 12.48 loss 0.040 score 0.463 lr 2.08956e-06 
12/02/2021 20:30:12 - INFO - volta.train_utils -   [NLVR2]: iter 33736 Ep: 12.50 loss 0.047 score 0.460 lr 2.08544e-06 
12/02/2021 20:30:34 - INFO - volta.train_utils -   [NLVR2]: iter 33776 Ep: 12.51 loss 0.041 score 0.467 lr 2.08133e-06 
12/02/2021 20:30:55 - INFO - volta.train_utils -   [NLVR2]: iter 33816 Ep: 12.53 loss 0.042 score 0.462 lr 2.07721e-06 
12/02/2021 20:31:17 - INFO - volta.train_utils -   [NLVR2]: iter 33856 Ep: 12.54 loss 0.044 score 0.460 lr 2.07309e-06 
12/02/2021 20:31:38 - INFO - volta.train_utils -   [NLVR2]: iter 33896 Ep: 12.56 loss 0.043 score 0.459 lr 2.06898e-06 
12/02/2021 20:32:00 - INFO - volta.train_utils -   [NLVR2]: iter 33936 Ep: 12.57 loss 0.039 score 0.463 lr 2.06486e-06 
12/02/2021 20:32:21 - INFO - volta.train_utils -   [NLVR2]: iter 33976 Ep: 12.59 loss 0.054 score 0.460 lr 2.06074e-06 
12/02/2021 20:32:43 - INFO - volta.train_utils -   [NLVR2]: iter 34016 Ep: 12.60 loss 0.041 score 0.466 lr 2.05663e-06 
12/02/2021 20:33:04 - INFO - volta.train_utils -   [NLVR2]: iter 34056 Ep: 12.62 loss 0.046 score 0.457 lr 2.05251e-06 
12/02/2021 20:33:26 - INFO - volta.train_utils -   [NLVR2]: iter 34096 Ep: 12.63 loss 0.043 score 0.463 lr 2.04839e-06 
12/02/2021 20:33:47 - INFO - volta.train_utils -   [NLVR2]: iter 34136 Ep: 12.65 loss 0.037 score 0.468 lr 2.04428e-06 
12/02/2021 20:34:09 - INFO - volta.train_utils -   [NLVR2]: iter 34176 Ep: 12.66 loss 0.034 score 0.467 lr 2.04016e-06 
12/02/2021 20:34:30 - INFO - volta.train_utils -   [NLVR2]: iter 34216 Ep: 12.68 loss 0.046 score 0.464 lr 2.03604e-06 
12/02/2021 20:34:52 - INFO - volta.train_utils -   [NLVR2]: iter 34256 Ep: 12.69 loss 0.038 score 0.464 lr 2.03193e-06 
12/02/2021 20:35:13 - INFO - volta.train_utils -   [NLVR2]: iter 34296 Ep: 12.71 loss 0.045 score 0.463 lr 2.02781e-06 
12/02/2021 20:35:35 - INFO - volta.train_utils -   [NLVR2]: iter 34336 Ep: 12.72 loss 0.048 score 0.465 lr 2.02369e-06 
12/02/2021 20:35:56 - INFO - volta.train_utils -   [NLVR2]: iter 34376 Ep: 12.74 loss 0.040 score 0.465 lr 2.01958e-06 
12/02/2021 20:36:18 - INFO - volta.train_utils -   [NLVR2]: iter 34416 Ep: 12.75 loss 0.045 score 0.459 lr 2.01546e-06 
12/02/2021 20:36:39 - INFO - volta.train_utils -   [NLVR2]: iter 34456 Ep: 12.77 loss 0.050 score 0.457 lr 2.01134e-06 
12/02/2021 20:37:01 - INFO - volta.train_utils -   [NLVR2]: iter 34496 Ep: 12.78 loss 0.040 score 0.459 lr 2.00722e-06 
12/02/2021 20:37:22 - INFO - volta.train_utils -   [NLVR2]: iter 34536 Ep: 12.80 loss 0.045 score 0.463 lr 2.00311e-06 
12/02/2021 20:37:44 - INFO - volta.train_utils -   [NLVR2]: iter 34576 Ep: 12.81 loss 0.044 score 0.465 lr 1.99899e-06 
12/02/2021 20:38:05 - INFO - volta.train_utils -   [NLVR2]: iter 34616 Ep: 12.83 loss 0.041 score 0.470 lr 1.99487e-06 
12/02/2021 20:38:27 - INFO - volta.train_utils -   [NLVR2]: iter 34656 Ep: 12.84 loss 0.047 score 0.461 lr 1.99076e-06 
12/02/2021 20:38:48 - INFO - volta.train_utils -   [NLVR2]: iter 34696 Ep: 12.86 loss 0.041 score 0.473 lr 1.98664e-06 
12/02/2021 20:39:10 - INFO - volta.train_utils -   [NLVR2]: iter 34736 Ep: 12.87 loss 0.045 score 0.466 lr 1.98252e-06 
12/02/2021 20:39:31 - INFO - volta.train_utils -   [NLVR2]: iter 34776 Ep: 12.88 loss 0.040 score 0.463 lr 1.97841e-06 
12/02/2021 20:39:53 - INFO - volta.train_utils -   [NLVR2]: iter 34816 Ep: 12.90 loss 0.042 score 0.467 lr 1.97429e-06 
12/02/2021 20:40:14 - INFO - volta.train_utils -   [NLVR2]: iter 34856 Ep: 12.91 loss 0.039 score 0.464 lr 1.97017e-06 
12/02/2021 20:40:36 - INFO - volta.train_utils -   [NLVR2]: iter 34896 Ep: 12.93 loss 0.038 score 0.460 lr 1.96606e-06 
12/02/2021 20:40:57 - INFO - volta.train_utils -   [NLVR2]: iter 34936 Ep: 12.94 loss 0.043 score 0.464 lr 1.96194e-06 
12/02/2021 20:41:19 - INFO - volta.train_utils -   [NLVR2]: iter 34976 Ep: 12.96 loss 0.049 score 0.461 lr 1.95782e-06 
12/02/2021 20:41:40 - INFO - volta.train_utils -   [NLVR2]: iter 35016 Ep: 12.97 loss 0.039 score 0.463 lr 1.95371e-06 
12/02/2021 20:42:02 - INFO - volta.train_utils -   [NLVR2]: iter 35056 Ep: 12.99 loss 0.049 score 0.462 lr 1.94959e-06 
12/02/2021 20:42:59 - INFO - volta.train_utils -   Eval task TASK12 on iteration 35074 
12/02/2021 20:42:59 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.065 score 71.144 
Epoch:  65%|   | 13/20 [5:27:19<2:55:08, 1501.21s/it]12/02/2021 20:43:21 - INFO - volta.train_utils -   [NLVR2]: iter 35114 Ep: 13.01 loss 0.038 score 0.473 lr 1.94455e-06 
12/02/2021 20:43:42 - INFO - volta.train_utils -   [NLVR2]: iter 35154 Ep: 13.02 loss 0.046 score 0.465 lr 1.9395e-06 
12/02/2021 20:44:04 - INFO - volta.train_utils -   [NLVR2]: iter 35194 Ep: 13.04 loss 0.042 score 0.460 lr 1.93539e-06 
12/02/2021 20:44:25 - INFO - volta.train_utils -   [NLVR2]: iter 35234 Ep: 13.05 loss 0.038 score 0.468 lr 1.93127e-06 
12/02/2021 20:44:47 - INFO - volta.train_utils -   [NLVR2]: iter 35274 Ep: 13.07 loss 0.042 score 0.463 lr 1.92715e-06 
12/02/2021 20:45:09 - INFO - volta.train_utils -   [NLVR2]: iter 35314 Ep: 13.08 loss 0.040 score 0.466 lr 1.92304e-06 
12/02/2021 20:45:30 - INFO - volta.train_utils -   [NLVR2]: iter 35354 Ep: 13.10 loss 0.041 score 0.463 lr 1.91892e-06 
12/02/2021 20:45:52 - INFO - volta.train_utils -   [NLVR2]: iter 35394 Ep: 13.11 loss 0.047 score 0.465 lr 1.9148e-06 
12/02/2021 20:46:13 - INFO - volta.train_utils -   [NLVR2]: iter 35434 Ep: 13.13 loss 0.039 score 0.468 lr 1.91069e-06 
12/02/2021 20:46:34 - INFO - volta.train_utils -   [NLVR2]: iter 35474 Ep: 13.14 loss 0.039 score 0.468 lr 1.90657e-06 
12/02/2021 20:46:56 - INFO - volta.train_utils -   [NLVR2]: iter 35514 Ep: 13.16 loss 0.039 score 0.468 lr 1.90245e-06 
12/02/2021 20:47:18 - INFO - volta.train_utils -   [NLVR2]: iter 35554 Ep: 13.17 loss 0.041 score 0.466 lr 1.89834e-06 
12/02/2021 20:47:39 - INFO - volta.train_utils -   [NLVR2]: iter 35594 Ep: 13.19 loss 0.038 score 0.462 lr 1.89422e-06 
12/02/2021 20:48:01 - INFO - volta.train_utils -   [NLVR2]: iter 35634 Ep: 13.20 loss 0.039 score 0.466 lr 1.8901e-06 
12/02/2021 20:48:22 - INFO - volta.train_utils -   [NLVR2]: iter 35674 Ep: 13.22 loss 0.045 score 0.466 lr 1.88599e-06 
12/02/2021 20:48:44 - INFO - volta.train_utils -   [NLVR2]: iter 35714 Ep: 13.23 loss 0.040 score 0.463 lr 1.88187e-06 
12/02/2021 20:49:06 - INFO - volta.train_utils -   [NLVR2]: iter 35754 Ep: 13.25 loss 0.043 score 0.464 lr 1.87775e-06 
12/02/2021 20:49:27 - INFO - volta.train_utils -   [NLVR2]: iter 35794 Ep: 13.26 loss 0.040 score 0.469 lr 1.87364e-06 
12/02/2021 20:49:49 - INFO - volta.train_utils -   [NLVR2]: iter 35834 Ep: 13.28 loss 0.039 score 0.463 lr 1.86952e-06 
12/02/2021 20:50:10 - INFO - volta.train_utils -   [NLVR2]: iter 35874 Ep: 13.29 loss 0.040 score 0.464 lr 1.8654e-06 
12/02/2021 20:50:32 - INFO - volta.train_utils -   [NLVR2]: iter 35914 Ep: 13.31 loss 0.035 score 0.469 lr 1.86129e-06 
12/02/2021 20:50:53 - INFO - volta.train_utils -   [NLVR2]: iter 35954 Ep: 13.32 loss 0.035 score 0.471 lr 1.85717e-06 
12/02/2021 20:51:15 - INFO - volta.train_utils -   [NLVR2]: iter 35994 Ep: 13.34 loss 0.038 score 0.467 lr 1.85305e-06 
12/02/2021 20:51:36 - INFO - volta.train_utils -   [NLVR2]: iter 36034 Ep: 13.35 loss 0.047 score 0.461 lr 1.84894e-06 
12/02/2021 20:51:58 - INFO - volta.train_utils -   [NLVR2]: iter 36074 Ep: 13.37 loss 0.042 score 0.470 lr 1.84482e-06 
12/02/2021 20:52:19 - INFO - volta.train_utils -   [NLVR2]: iter 36114 Ep: 13.38 loss 0.041 score 0.468 lr 1.8407e-06 
12/02/2021 20:52:41 - INFO - volta.train_utils -   [NLVR2]: iter 36154 Ep: 13.40 loss 0.043 score 0.461 lr 1.83659e-06 
12/02/2021 20:53:02 - INFO - volta.train_utils -   [NLVR2]: iter 36194 Ep: 13.41 loss 0.040 score 0.461 lr 1.83247e-06 
12/02/2021 20:53:23 - INFO - volta.train_utils -   [NLVR2]: iter 36234 Ep: 13.42 loss 0.045 score 0.466 lr 1.82835e-06 
12/02/2021 20:53:45 - INFO - volta.train_utils -   [NLVR2]: iter 36274 Ep: 13.44 loss 0.052 score 0.456 lr 1.82424e-06 
12/02/2021 20:54:07 - INFO - volta.train_utils -   [NLVR2]: iter 36314 Ep: 13.45 loss 0.035 score 0.472 lr 1.82012e-06 
12/02/2021 20:54:28 - INFO - volta.train_utils -   [NLVR2]: iter 36354 Ep: 13.47 loss 0.036 score 0.468 lr 1.816e-06 
12/02/2021 20:54:49 - INFO - volta.train_utils -   [NLVR2]: iter 36394 Ep: 13.48 loss 0.045 score 0.463 lr 1.81189e-06 
12/02/2021 20:55:11 - INFO - volta.train_utils -   [NLVR2]: iter 36434 Ep: 13.50 loss 0.040 score 0.466 lr 1.80777e-06 
12/02/2021 20:55:33 - INFO - volta.train_utils -   [NLVR2]: iter 36474 Ep: 13.51 loss 0.038 score 0.466 lr 1.80365e-06 
12/02/2021 20:55:54 - INFO - volta.train_utils -   [NLVR2]: iter 36514 Ep: 13.53 loss 0.032 score 0.469 lr 1.79953e-06 
12/02/2021 20:56:16 - INFO - volta.train_utils -   [NLVR2]: iter 36554 Ep: 13.54 loss 0.034 score 0.466 lr 1.79542e-06 
12/02/2021 20:56:37 - INFO - volta.train_utils -   [NLVR2]: iter 36594 Ep: 13.56 loss 0.033 score 0.473 lr 1.7913e-06 
12/02/2021 20:56:59 - INFO - volta.train_utils -   [NLVR2]: iter 36634 Ep: 13.57 loss 0.030 score 0.471 lr 1.78718e-06 
12/02/2021 20:57:20 - INFO - volta.train_utils -   [NLVR2]: iter 36674 Ep: 13.59 loss 0.041 score 0.469 lr 1.78307e-06 
12/02/2021 20:57:42 - INFO - volta.train_utils -   [NLVR2]: iter 36714 Ep: 13.60 loss 0.037 score 0.466 lr 1.77895e-06 
12/02/2021 20:58:03 - INFO - volta.train_utils -   [NLVR2]: iter 36754 Ep: 13.62 loss 0.036 score 0.464 lr 1.77483e-06 
12/02/2021 20:58:25 - INFO - volta.train_utils -   [NLVR2]: iter 36794 Ep: 13.63 loss 0.043 score 0.468 lr 1.77072e-06 
12/02/2021 20:58:46 - INFO - volta.train_utils -   [NLVR2]: iter 36834 Ep: 13.65 loss 0.039 score 0.467 lr 1.7666e-06 
12/02/2021 20:59:07 - INFO - volta.train_utils -   [NLVR2]: iter 36874 Ep: 13.66 loss 0.043 score 0.461 lr 1.76248e-06 
12/02/2021 20:59:29 - INFO - volta.train_utils -   [NLVR2]: iter 36914 Ep: 13.68 loss 0.037 score 0.470 lr 1.75837e-06 
12/02/2021 20:59:51 - INFO - volta.train_utils -   [NLVR2]: iter 36954 Ep: 13.69 loss 0.038 score 0.471 lr 1.75425e-06 
12/02/2021 21:00:12 - INFO - volta.train_utils -   [NLVR2]: iter 36994 Ep: 13.71 loss 0.039 score 0.462 lr 1.75013e-06 
12/02/2021 21:00:33 - INFO - volta.train_utils -   [NLVR2]: iter 37034 Ep: 13.72 loss 0.030 score 0.472 lr 1.74602e-06 
12/02/2021 21:00:55 - INFO - volta.train_utils -   [NLVR2]: iter 37074 Ep: 13.74 loss 0.044 score 0.462 lr 1.7419e-06 
12/02/2021 21:01:16 - INFO - volta.train_utils -   [NLVR2]: iter 37114 Ep: 13.75 loss 0.040 score 0.465 lr 1.73778e-06 
12/02/2021 21:01:38 - INFO - volta.train_utils -   [NLVR2]: iter 37154 Ep: 13.77 loss 0.042 score 0.468 lr 1.73367e-06 
12/02/2021 21:02:00 - INFO - volta.train_utils -   [NLVR2]: iter 37194 Ep: 13.78 loss 0.044 score 0.464 lr 1.72955e-06 
12/02/2021 21:02:21 - INFO - volta.train_utils -   [NLVR2]: iter 37234 Ep: 13.80 loss 0.031 score 0.469 lr 1.72543e-06 
12/02/2021 21:02:43 - INFO - volta.train_utils -   [NLVR2]: iter 37274 Ep: 13.81 loss 0.037 score 0.466 lr 1.72132e-06 
12/02/2021 21:03:04 - INFO - volta.train_utils -   [NLVR2]: iter 37314 Ep: 13.83 loss 0.039 score 0.463 lr 1.7172e-06 
12/02/2021 21:03:26 - INFO - volta.train_utils -   [NLVR2]: iter 37354 Ep: 13.84 loss 0.041 score 0.464 lr 1.71308e-06 
12/02/2021 21:03:47 - INFO - volta.train_utils -   [NLVR2]: iter 37394 Ep: 13.85 loss 0.046 score 0.466 lr 1.70897e-06 
12/02/2021 21:04:09 - INFO - volta.train_utils -   [NLVR2]: iter 37434 Ep: 13.87 loss 0.037 score 0.467 lr 1.70485e-06 
12/02/2021 21:04:30 - INFO - volta.train_utils -   [NLVR2]: iter 37474 Ep: 13.88 loss 0.040 score 0.466 lr 1.70073e-06 
12/02/2021 21:04:52 - INFO - volta.train_utils -   [NLVR2]: iter 37514 Ep: 13.90 loss 0.033 score 0.470 lr 1.69662e-06 
12/02/2021 21:05:13 - INFO - volta.train_utils -   [NLVR2]: iter 37554 Ep: 13.91 loss 0.034 score 0.470 lr 1.6925e-06 
12/02/2021 21:05:35 - INFO - volta.train_utils -   [NLVR2]: iter 37594 Ep: 13.93 loss 0.030 score 0.475 lr 1.68838e-06 
12/02/2021 21:05:56 - INFO - volta.train_utils -   [NLVR2]: iter 37634 Ep: 13.94 loss 0.041 score 0.465 lr 1.68427e-06 
12/02/2021 21:06:18 - INFO - volta.train_utils -   [NLVR2]: iter 37674 Ep: 13.96 loss 0.041 score 0.471 lr 1.68015e-06 
12/02/2021 21:06:39 - INFO - volta.train_utils -   [NLVR2]: iter 37714 Ep: 13.97 loss 0.033 score 0.471 lr 1.67603e-06 
12/02/2021 21:07:01 - INFO - volta.train_utils -   [NLVR2]: iter 37754 Ep: 13.99 loss 0.043 score 0.470 lr 1.67192e-06 
12/02/2021 21:07:57 - INFO - volta.train_utils -   Eval task TASK12 on iteration 37772 
12/02/2021 21:07:57 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.148 score 70.943 
Epoch:  70%|   | 14/20 [5:52:18<2:30:01, 1500.30s/it]12/02/2021 21:08:19 - INFO - volta.train_utils -   [NLVR2]: iter 37812 Ep: 14.01 loss 0.045 score 0.475 lr 1.66687e-06 
12/02/2021 21:08:40 - INFO - volta.train_utils -   [NLVR2]: iter 37852 Ep: 14.02 loss 0.038 score 0.470 lr 1.66183e-06 
12/02/2021 21:09:02 - INFO - volta.train_utils -   [NLVR2]: iter 37892 Ep: 14.04 loss 0.038 score 0.474 lr 1.65771e-06 
12/02/2021 21:09:23 - INFO - volta.train_utils -   [NLVR2]: iter 37932 Ep: 14.05 loss 0.036 score 0.464 lr 1.6536e-06 
12/02/2021 21:09:45 - INFO - volta.train_utils -   [NLVR2]: iter 37972 Ep: 14.07 loss 0.038 score 0.465 lr 1.64948e-06 
12/02/2021 21:10:06 - INFO - volta.train_utils -   [NLVR2]: iter 38012 Ep: 14.08 loss 0.037 score 0.474 lr 1.64536e-06 
12/02/2021 21:10:28 - INFO - volta.train_utils -   [NLVR2]: iter 38052 Ep: 14.10 loss 0.039 score 0.465 lr 1.64125e-06 
12/02/2021 21:10:49 - INFO - volta.train_utils -   [NLVR2]: iter 38092 Ep: 14.11 loss 0.036 score 0.468 lr 1.63713e-06 
12/02/2021 21:11:11 - INFO - volta.train_utils -   [NLVR2]: iter 38132 Ep: 14.13 loss 0.037 score 0.464 lr 1.63301e-06 
12/02/2021 21:11:32 - INFO - volta.train_utils -   [NLVR2]: iter 38172 Ep: 14.14 loss 0.032 score 0.473 lr 1.6289e-06 
12/02/2021 21:11:54 - INFO - volta.train_utils -   [NLVR2]: iter 38212 Ep: 14.16 loss 0.036 score 0.470 lr 1.62478e-06 
12/02/2021 21:12:15 - INFO - volta.train_utils -   [NLVR2]: iter 38252 Ep: 14.17 loss 0.037 score 0.466 lr 1.62066e-06 
12/02/2021 21:12:37 - INFO - volta.train_utils -   [NLVR2]: iter 38292 Ep: 14.19 loss 0.034 score 0.473 lr 1.61655e-06 
12/02/2021 21:12:58 - INFO - volta.train_utils -   [NLVR2]: iter 38332 Ep: 14.20 loss 0.042 score 0.465 lr 1.61243e-06 
12/02/2021 21:13:20 - INFO - volta.train_utils -   [NLVR2]: iter 38372 Ep: 14.22 loss 0.039 score 0.470 lr 1.60831e-06 
12/02/2021 21:13:41 - INFO - volta.train_utils -   [NLVR2]: iter 38412 Ep: 14.23 loss 0.044 score 0.470 lr 1.60419e-06 
12/02/2021 21:14:03 - INFO - volta.train_utils -   [NLVR2]: iter 38452 Ep: 14.25 loss 0.033 score 0.471 lr 1.60008e-06 
12/02/2021 21:14:24 - INFO - volta.train_utils -   [NLVR2]: iter 38492 Ep: 14.26 loss 0.034 score 0.467 lr 1.59596e-06 
12/02/2021 21:14:46 - INFO - volta.train_utils -   [NLVR2]: iter 38532 Ep: 14.28 loss 0.041 score 0.466 lr 1.59184e-06 
12/02/2021 21:15:07 - INFO - volta.train_utils -   [NLVR2]: iter 38572 Ep: 14.29 loss 0.040 score 0.461 lr 1.58773e-06 
12/02/2021 21:15:29 - INFO - volta.train_utils -   [NLVR2]: iter 38612 Ep: 14.31 loss 0.045 score 0.465 lr 1.58361e-06 
12/02/2021 21:15:50 - INFO - volta.train_utils -   [NLVR2]: iter 38652 Ep: 14.32 loss 0.040 score 0.469 lr 1.57949e-06 
12/02/2021 21:16:12 - INFO - volta.train_utils -   [NLVR2]: iter 38692 Ep: 14.34 loss 0.039 score 0.466 lr 1.57538e-06 
12/02/2021 21:16:33 - INFO - volta.train_utils -   [NLVR2]: iter 38732 Ep: 14.35 loss 0.045 score 0.464 lr 1.57126e-06 
12/02/2021 21:16:55 - INFO - volta.train_utils -   [NLVR2]: iter 38772 Ep: 14.37 loss 0.034 score 0.468 lr 1.56714e-06 
12/02/2021 21:17:16 - INFO - volta.train_utils -   [NLVR2]: iter 38812 Ep: 14.38 loss 0.041 score 0.466 lr 1.56303e-06 
12/02/2021 21:17:38 - INFO - volta.train_utils -   [NLVR2]: iter 38852 Ep: 14.39 loss 0.039 score 0.466 lr 1.55891e-06 
12/02/2021 21:17:59 - INFO - volta.train_utils -   [NLVR2]: iter 38892 Ep: 14.41 loss 0.032 score 0.470 lr 1.55479e-06 
12/02/2021 21:18:20 - INFO - volta.train_utils -   [NLVR2]: iter 38932 Ep: 14.42 loss 0.037 score 0.472 lr 1.55068e-06 
12/02/2021 21:18:42 - INFO - volta.train_utils -   [NLVR2]: iter 38972 Ep: 14.44 loss 0.045 score 0.465 lr 1.54656e-06 
12/02/2021 21:19:03 - INFO - volta.train_utils -   [NLVR2]: iter 39012 Ep: 14.45 loss 0.042 score 0.470 lr 1.54244e-06 
12/02/2021 21:19:25 - INFO - volta.train_utils -   [NLVR2]: iter 39052 Ep: 14.47 loss 0.040 score 0.470 lr 1.53833e-06 
12/02/2021 21:19:46 - INFO - volta.train_utils -   [NLVR2]: iter 39092 Ep: 14.48 loss 0.050 score 0.466 lr 1.53421e-06 
12/02/2021 21:20:08 - INFO - volta.train_utils -   [NLVR2]: iter 39132 Ep: 14.50 loss 0.048 score 0.461 lr 1.53009e-06 
12/02/2021 21:20:30 - INFO - volta.train_utils -   [NLVR2]: iter 39172 Ep: 14.51 loss 0.034 score 0.472 lr 1.52598e-06 
12/02/2021 21:20:51 - INFO - volta.train_utils -   [NLVR2]: iter 39212 Ep: 14.53 loss 0.034 score 0.468 lr 1.52186e-06 
12/02/2021 21:21:13 - INFO - volta.train_utils -   [NLVR2]: iter 39252 Ep: 14.54 loss 0.039 score 0.474 lr 1.51774e-06 
12/02/2021 21:21:34 - INFO - volta.train_utils -   [NLVR2]: iter 39292 Ep: 14.56 loss 0.030 score 0.472 lr 1.51363e-06 
12/02/2021 21:21:56 - INFO - volta.train_utils -   [NLVR2]: iter 39332 Ep: 14.57 loss 0.044 score 0.466 lr 1.50951e-06 
12/02/2021 21:22:17 - INFO - volta.train_utils -   [NLVR2]: iter 39372 Ep: 14.59 loss 0.039 score 0.469 lr 1.50539e-06 
12/02/2021 21:22:39 - INFO - volta.train_utils -   [NLVR2]: iter 39412 Ep: 14.60 loss 0.037 score 0.468 lr 1.50128e-06 
12/02/2021 21:23:01 - INFO - volta.train_utils -   [NLVR2]: iter 39452 Ep: 14.62 loss 0.043 score 0.464 lr 1.49716e-06 
12/02/2021 21:23:22 - INFO - volta.train_utils -   [NLVR2]: iter 39492 Ep: 14.63 loss 0.029 score 0.474 lr 1.49304e-06 
12/02/2021 21:23:44 - INFO - volta.train_utils -   [NLVR2]: iter 39532 Ep: 14.65 loss 0.037 score 0.467 lr 1.48893e-06 
12/02/2021 21:24:05 - INFO - volta.train_utils -   [NLVR2]: iter 39572 Ep: 14.66 loss 0.034 score 0.467 lr 1.48481e-06 
12/02/2021 21:24:27 - INFO - volta.train_utils -   [NLVR2]: iter 39612 Ep: 14.68 loss 0.042 score 0.468 lr 1.48069e-06 
12/02/2021 21:24:48 - INFO - volta.train_utils -   [NLVR2]: iter 39652 Ep: 14.69 loss 0.038 score 0.469 lr 1.47658e-06 
12/02/2021 21:25:10 - INFO - volta.train_utils -   [NLVR2]: iter 39692 Ep: 14.71 loss 0.037 score 0.470 lr 1.47246e-06 
12/02/2021 21:25:31 - INFO - volta.train_utils -   [NLVR2]: iter 39732 Ep: 14.72 loss 0.041 score 0.462 lr 1.46834e-06 
12/02/2021 21:25:53 - INFO - volta.train_utils -   [NLVR2]: iter 39772 Ep: 14.74 loss 0.036 score 0.473 lr 1.46423e-06 
12/02/2021 21:26:15 - INFO - volta.train_utils -   [NLVR2]: iter 39812 Ep: 14.75 loss 0.036 score 0.471 lr 1.46011e-06 
12/02/2021 21:26:36 - INFO - volta.train_utils -   [NLVR2]: iter 39852 Ep: 14.77 loss 0.039 score 0.468 lr 1.45599e-06 
12/02/2021 21:26:58 - INFO - volta.train_utils -   [NLVR2]: iter 39892 Ep: 14.78 loss 0.034 score 0.475 lr 1.45188e-06 
12/02/2021 21:27:19 - INFO - volta.train_utils -   [NLVR2]: iter 39932 Ep: 14.80 loss 0.033 score 0.468 lr 1.44776e-06 
12/02/2021 21:27:41 - INFO - volta.train_utils -   [NLVR2]: iter 39972 Ep: 14.81 loss 0.042 score 0.468 lr 1.44364e-06 
12/02/2021 21:28:02 - INFO - volta.train_utils -   [NLVR2]: iter 40012 Ep: 14.82 loss 0.032 score 0.468 lr 1.43952e-06 
12/02/2021 21:28:24 - INFO - volta.train_utils -   [NLVR2]: iter 40052 Ep: 14.84 loss 0.041 score 0.468 lr 1.43541e-06 
12/02/2021 21:28:45 - INFO - volta.train_utils -   [NLVR2]: iter 40092 Ep: 14.85 loss 0.039 score 0.468 lr 1.43129e-06 
12/02/2021 21:29:07 - INFO - volta.train_utils -   [NLVR2]: iter 40132 Ep: 14.87 loss 0.032 score 0.472 lr 1.42717e-06 
12/02/2021 21:29:28 - INFO - volta.train_utils -   [NLVR2]: iter 40172 Ep: 14.88 loss 0.034 score 0.468 lr 1.42306e-06 
12/02/2021 21:29:50 - INFO - volta.train_utils -   [NLVR2]: iter 40212 Ep: 14.90 loss 0.044 score 0.470 lr 1.41894e-06 
12/02/2021 21:30:11 - INFO - volta.train_utils -   [NLVR2]: iter 40252 Ep: 14.91 loss 0.033 score 0.471 lr 1.41482e-06 
12/02/2021 21:30:33 - INFO - volta.train_utils -   [NLVR2]: iter 40292 Ep: 14.93 loss 0.032 score 0.473 lr 1.41071e-06 
12/02/2021 21:30:54 - INFO - volta.train_utils -   [NLVR2]: iter 40332 Ep: 14.94 loss 0.033 score 0.476 lr 1.40659e-06 
12/02/2021 21:31:15 - INFO - volta.train_utils -   [NLVR2]: iter 40372 Ep: 14.96 loss 0.036 score 0.468 lr 1.40247e-06 
12/02/2021 21:31:37 - INFO - volta.train_utils -   [NLVR2]: iter 40412 Ep: 14.97 loss 0.038 score 0.466 lr 1.39836e-06 
12/02/2021 21:31:58 - INFO - volta.train_utils -   [NLVR2]: iter 40452 Ep: 14.99 loss 0.038 score 0.470 lr 1.39424e-06 
12/02/2021 21:32:56 - INFO - volta.train_utils -   Eval task TASK12 on iteration 40470 
12/02/2021 21:32:56 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.192 score 70.786 
Epoch:  75%|  | 15/20 [6:17:17<2:04:59, 1500.00s/it]12/02/2021 21:33:18 - INFO - volta.train_utils -   [NLVR2]: iter 40510 Ep: 15.01 loss 0.033 score 0.482 lr 1.3892e-06 
12/02/2021 21:33:40 - INFO - volta.train_utils -   [NLVR2]: iter 40550 Ep: 15.02 loss 0.037 score 0.465 lr 1.38415e-06 
12/02/2021 21:34:01 - INFO - volta.train_utils -   [NLVR2]: iter 40590 Ep: 15.04 loss 0.031 score 0.476 lr 1.38004e-06 
12/02/2021 21:34:23 - INFO - volta.train_utils -   [NLVR2]: iter 40630 Ep: 15.05 loss 0.037 score 0.473 lr 1.37592e-06 
12/02/2021 21:34:44 - INFO - volta.train_utils -   [NLVR2]: iter 40670 Ep: 15.07 loss 0.030 score 0.477 lr 1.3718e-06 
12/02/2021 21:35:06 - INFO - volta.train_utils -   [NLVR2]: iter 40710 Ep: 15.08 loss 0.029 score 0.474 lr 1.36769e-06 
12/02/2021 21:35:27 - INFO - volta.train_utils -   [NLVR2]: iter 40750 Ep: 15.10 loss 0.038 score 0.466 lr 1.36357e-06 
12/02/2021 21:35:49 - INFO - volta.train_utils -   [NLVR2]: iter 40790 Ep: 15.11 loss 0.035 score 0.470 lr 1.35945e-06 
12/02/2021 21:36:10 - INFO - volta.train_utils -   [NLVR2]: iter 40830 Ep: 15.13 loss 0.026 score 0.475 lr 1.35534e-06 
12/02/2021 21:36:32 - INFO - volta.train_utils -   [NLVR2]: iter 40870 Ep: 15.14 loss 0.037 score 0.470 lr 1.35122e-06 
12/02/2021 21:36:53 - INFO - volta.train_utils -   [NLVR2]: iter 40910 Ep: 15.16 loss 0.032 score 0.473 lr 1.3471e-06 
12/02/2021 21:37:15 - INFO - volta.train_utils -   [NLVR2]: iter 40950 Ep: 15.17 loss 0.032 score 0.466 lr 1.34299e-06 
12/02/2021 21:37:36 - INFO - volta.train_utils -   [NLVR2]: iter 40990 Ep: 15.19 loss 0.029 score 0.473 lr 1.33887e-06 
12/02/2021 21:37:58 - INFO - volta.train_utils -   [NLVR2]: iter 41030 Ep: 15.20 loss 0.039 score 0.472 lr 1.33475e-06 
12/02/2021 21:38:19 - INFO - volta.train_utils -   [NLVR2]: iter 41070 Ep: 15.22 loss 0.031 score 0.472 lr 1.33064e-06 
12/02/2021 21:38:41 - INFO - volta.train_utils -   [NLVR2]: iter 41110 Ep: 15.23 loss 0.028 score 0.468 lr 1.32652e-06 
12/02/2021 21:39:03 - INFO - volta.train_utils -   [NLVR2]: iter 41150 Ep: 15.25 loss 0.040 score 0.470 lr 1.3224e-06 
12/02/2021 21:39:24 - INFO - volta.train_utils -   [NLVR2]: iter 41190 Ep: 15.26 loss 0.029 score 0.473 lr 1.31829e-06 
12/02/2021 21:39:46 - INFO - volta.train_utils -   [NLVR2]: iter 41230 Ep: 15.28 loss 0.029 score 0.474 lr 1.31417e-06 
12/02/2021 21:40:07 - INFO - volta.train_utils -   [NLVR2]: iter 41270 Ep: 15.29 loss 0.029 score 0.474 lr 1.31005e-06 
12/02/2021 21:40:29 - INFO - volta.train_utils -   [NLVR2]: iter 41310 Ep: 15.31 loss 0.029 score 0.474 lr 1.30594e-06 
12/02/2021 21:40:50 - INFO - volta.train_utils -   [NLVR2]: iter 41350 Ep: 15.32 loss 0.027 score 0.470 lr 1.30182e-06 
12/02/2021 21:41:12 - INFO - volta.train_utils -   [NLVR2]: iter 41390 Ep: 15.34 loss 0.038 score 0.470 lr 1.2977e-06 
12/02/2021 21:41:34 - INFO - volta.train_utils -   [NLVR2]: iter 41430 Ep: 15.35 loss 0.037 score 0.466 lr 1.29359e-06 
12/02/2021 21:41:55 - INFO - volta.train_utils -   [NLVR2]: iter 41470 Ep: 15.36 loss 0.034 score 0.470 lr 1.28947e-06 
12/02/2021 21:42:17 - INFO - volta.train_utils -   [NLVR2]: iter 41510 Ep: 15.38 loss 0.029 score 0.470 lr 1.28535e-06 
12/02/2021 21:42:38 - INFO - volta.train_utils -   [NLVR2]: iter 41550 Ep: 15.39 loss 0.041 score 0.471 lr 1.28124e-06 
12/02/2021 21:43:00 - INFO - volta.train_utils -   [NLVR2]: iter 41590 Ep: 15.41 loss 0.036 score 0.470 lr 1.27712e-06 
12/02/2021 21:43:21 - INFO - volta.train_utils -   [NLVR2]: iter 41630 Ep: 15.42 loss 0.029 score 0.477 lr 1.273e-06 
12/02/2021 21:43:43 - INFO - volta.train_utils -   [NLVR2]: iter 41670 Ep: 15.44 loss 0.028 score 0.473 lr 1.26889e-06 
12/02/2021 21:44:04 - INFO - volta.train_utils -   [NLVR2]: iter 41710 Ep: 15.45 loss 0.034 score 0.472 lr 1.26477e-06 
12/02/2021 21:44:26 - INFO - volta.train_utils -   [NLVR2]: iter 41750 Ep: 15.47 loss 0.040 score 0.467 lr 1.26065e-06 
12/02/2021 21:44:47 - INFO - volta.train_utils -   [NLVR2]: iter 41790 Ep: 15.48 loss 0.034 score 0.473 lr 1.25654e-06 
12/02/2021 21:45:09 - INFO - volta.train_utils -   [NLVR2]: iter 41830 Ep: 15.50 loss 0.028 score 0.477 lr 1.25242e-06 
12/02/2021 21:45:30 - INFO - volta.train_utils -   [NLVR2]: iter 41870 Ep: 15.51 loss 0.040 score 0.470 lr 1.2483e-06 
12/02/2021 21:45:52 - INFO - volta.train_utils -   [NLVR2]: iter 41910 Ep: 15.53 loss 0.033 score 0.477 lr 1.24419e-06 
12/02/2021 21:46:13 - INFO - volta.train_utils -   [NLVR2]: iter 41950 Ep: 15.54 loss 0.026 score 0.472 lr 1.24007e-06 
12/02/2021 21:46:35 - INFO - volta.train_utils -   [NLVR2]: iter 41990 Ep: 15.56 loss 0.032 score 0.472 lr 1.23595e-06 
12/02/2021 21:46:56 - INFO - volta.train_utils -   [NLVR2]: iter 42030 Ep: 15.57 loss 0.030 score 0.471 lr 1.23183e-06 
12/02/2021 21:47:18 - INFO - volta.train_utils -   [NLVR2]: iter 42070 Ep: 15.59 loss 0.036 score 0.470 lr 1.22772e-06 
12/02/2021 21:47:39 - INFO - volta.train_utils -   [NLVR2]: iter 42110 Ep: 15.60 loss 0.028 score 0.475 lr 1.2236e-06 
12/02/2021 21:48:01 - INFO - volta.train_utils -   [NLVR2]: iter 42150 Ep: 15.62 loss 0.034 score 0.468 lr 1.21948e-06 
12/02/2021 21:48:22 - INFO - volta.train_utils -   [NLVR2]: iter 42190 Ep: 15.63 loss 0.046 score 0.470 lr 1.21537e-06 
12/02/2021 21:48:44 - INFO - volta.train_utils -   [NLVR2]: iter 42230 Ep: 15.65 loss 0.025 score 0.480 lr 1.21125e-06 
12/02/2021 21:49:05 - INFO - volta.train_utils -   [NLVR2]: iter 42270 Ep: 15.66 loss 0.029 score 0.474 lr 1.20713e-06 
12/02/2021 21:49:27 - INFO - volta.train_utils -   [NLVR2]: iter 42310 Ep: 15.68 loss 0.032 score 0.475 lr 1.20302e-06 
12/02/2021 21:49:48 - INFO - volta.train_utils -   [NLVR2]: iter 42350 Ep: 15.69 loss 0.037 score 0.468 lr 1.1989e-06 
12/02/2021 21:50:10 - INFO - volta.train_utils -   [NLVR2]: iter 42390 Ep: 15.71 loss 0.031 score 0.471 lr 1.19478e-06 
12/02/2021 21:50:31 - INFO - volta.train_utils -   [NLVR2]: iter 42430 Ep: 15.72 loss 0.033 score 0.470 lr 1.19067e-06 
12/02/2021 21:50:53 - INFO - volta.train_utils -   [NLVR2]: iter 42470 Ep: 15.74 loss 0.033 score 0.471 lr 1.18655e-06 
12/02/2021 21:51:15 - INFO - volta.train_utils -   [NLVR2]: iter 42510 Ep: 15.75 loss 0.032 score 0.471 lr 1.18243e-06 
12/02/2021 21:51:36 - INFO - volta.train_utils -   [NLVR2]: iter 42550 Ep: 15.77 loss 0.033 score 0.475 lr 1.17832e-06 
12/02/2021 21:51:58 - INFO - volta.train_utils -   [NLVR2]: iter 42590 Ep: 15.78 loss 0.027 score 0.474 lr 1.1742e-06 
12/02/2021 21:52:19 - INFO - volta.train_utils -   [NLVR2]: iter 42630 Ep: 15.79 loss 0.033 score 0.477 lr 1.17008e-06 
12/02/2021 21:52:41 - INFO - volta.train_utils -   [NLVR2]: iter 42670 Ep: 15.81 loss 0.033 score 0.471 lr 1.16597e-06 
12/02/2021 21:53:02 - INFO - volta.train_utils -   [NLVR2]: iter 42710 Ep: 15.82 loss 0.031 score 0.474 lr 1.16185e-06 
12/02/2021 21:53:24 - INFO - volta.train_utils -   [NLVR2]: iter 42750 Ep: 15.84 loss 0.031 score 0.471 lr 1.15773e-06 
12/02/2021 21:53:45 - INFO - volta.train_utils -   [NLVR2]: iter 42790 Ep: 15.85 loss 0.031 score 0.469 lr 1.15362e-06 
12/02/2021 21:54:07 - INFO - volta.train_utils -   [NLVR2]: iter 42830 Ep: 15.87 loss 0.032 score 0.474 lr 1.1495e-06 
12/02/2021 21:54:29 - INFO - volta.train_utils -   [NLVR2]: iter 42870 Ep: 15.88 loss 0.030 score 0.473 lr 1.14538e-06 
12/02/2021 21:54:50 - INFO - volta.train_utils -   [NLVR2]: iter 42910 Ep: 15.90 loss 0.027 score 0.477 lr 1.14127e-06 
12/02/2021 21:55:12 - INFO - volta.train_utils -   [NLVR2]: iter 42950 Ep: 15.91 loss 0.035 score 0.470 lr 1.13715e-06 
12/02/2021 21:55:33 - INFO - volta.train_utils -   [NLVR2]: iter 42990 Ep: 15.93 loss 0.034 score 0.473 lr 1.13303e-06 
12/02/2021 21:55:55 - INFO - volta.train_utils -   [NLVR2]: iter 43030 Ep: 15.94 loss 0.030 score 0.475 lr 1.12892e-06 
12/02/2021 21:56:16 - INFO - volta.train_utils -   [NLVR2]: iter 43070 Ep: 15.96 loss 0.029 score 0.477 lr 1.1248e-06 
12/02/2021 21:56:38 - INFO - volta.train_utils -   [NLVR2]: iter 43110 Ep: 15.97 loss 0.030 score 0.470 lr 1.12068e-06 
12/02/2021 21:56:59 - INFO - volta.train_utils -   [NLVR2]: iter 43150 Ep: 15.99 loss 0.031 score 0.477 lr 1.11657e-06 
12/02/2021 21:57:56 - INFO - volta.train_utils -   Eval task TASK12 on iteration 43168 
12/02/2021 21:57:56 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.235 score 71.402 
Epoch:  80%|  | 16/20 [6:42:17<1:39:59, 1499.99s/it]12/02/2021 21:58:18 - INFO - volta.train_utils -   [NLVR2]: iter 43208 Ep: 16.01 loss 0.036 score 0.481 lr 1.11152e-06 
12/02/2021 21:58:40 - INFO - volta.train_utils -   [NLVR2]: iter 43248 Ep: 16.02 loss 0.031 score 0.473 lr 1.10648e-06 
12/02/2021 21:59:01 - INFO - volta.train_utils -   [NLVR2]: iter 43288 Ep: 16.04 loss 0.036 score 0.472 lr 1.10236e-06 
12/02/2021 21:59:23 - INFO - volta.train_utils -   [NLVR2]: iter 43328 Ep: 16.05 loss 0.030 score 0.470 lr 1.09825e-06 
12/02/2021 21:59:44 - INFO - volta.train_utils -   [NLVR2]: iter 43368 Ep: 16.07 loss 0.031 score 0.474 lr 1.09413e-06 
12/02/2021 22:00:05 - INFO - volta.train_utils -   [NLVR2]: iter 43408 Ep: 16.08 loss 0.030 score 0.471 lr 1.09001e-06 
12/02/2021 22:00:27 - INFO - volta.train_utils -   [NLVR2]: iter 43448 Ep: 16.10 loss 0.028 score 0.477 lr 1.0859e-06 
12/02/2021 22:00:48 - INFO - volta.train_utils -   [NLVR2]: iter 43488 Ep: 16.11 loss 0.031 score 0.470 lr 1.08178e-06 
12/02/2021 22:01:10 - INFO - volta.train_utils -   [NLVR2]: iter 43528 Ep: 16.13 loss 0.030 score 0.479 lr 1.07766e-06 
12/02/2021 22:01:31 - INFO - volta.train_utils -   [NLVR2]: iter 43568 Ep: 16.14 loss 0.033 score 0.471 lr 1.07355e-06 
12/02/2021 22:01:53 - INFO - volta.train_utils -   [NLVR2]: iter 43608 Ep: 16.16 loss 0.028 score 0.475 lr 1.06943e-06 
12/02/2021 22:02:15 - INFO - volta.train_utils -   [NLVR2]: iter 43648 Ep: 16.17 loss 0.036 score 0.471 lr 1.06531e-06 
12/02/2021 22:02:36 - INFO - volta.train_utils -   [NLVR2]: iter 43688 Ep: 16.19 loss 0.029 score 0.478 lr 1.0612e-06 
12/02/2021 22:02:58 - INFO - volta.train_utils -   [NLVR2]: iter 43728 Ep: 16.20 loss 0.031 score 0.469 lr 1.05708e-06 
12/02/2021 22:03:19 - INFO - volta.train_utils -   [NLVR2]: iter 43768 Ep: 16.22 loss 0.034 score 0.474 lr 1.05296e-06 
12/02/2021 22:03:41 - INFO - volta.train_utils -   [NLVR2]: iter 43808 Ep: 16.23 loss 0.035 score 0.471 lr 1.04885e-06 
12/02/2021 22:04:02 - INFO - volta.train_utils -   [NLVR2]: iter 43848 Ep: 16.25 loss 0.032 score 0.473 lr 1.04473e-06 
12/02/2021 22:04:24 - INFO - volta.train_utils -   [NLVR2]: iter 43888 Ep: 16.26 loss 0.028 score 0.477 lr 1.04061e-06 
12/02/2021 22:04:45 - INFO - volta.train_utils -   [NLVR2]: iter 43928 Ep: 16.28 loss 0.026 score 0.479 lr 1.03649e-06 
12/02/2021 22:05:07 - INFO - volta.train_utils -   [NLVR2]: iter 43968 Ep: 16.29 loss 0.035 score 0.472 lr 1.03238e-06 
12/02/2021 22:05:28 - INFO - volta.train_utils -   [NLVR2]: iter 44008 Ep: 16.31 loss 0.028 score 0.476 lr 1.02826e-06 
12/02/2021 22:05:50 - INFO - volta.train_utils -   [NLVR2]: iter 44048 Ep: 16.32 loss 0.037 score 0.471 lr 1.02414e-06 
12/02/2021 22:06:11 - INFO - volta.train_utils -   [NLVR2]: iter 44088 Ep: 16.33 loss 0.032 score 0.477 lr 1.02003e-06 
12/02/2021 22:06:33 - INFO - volta.train_utils -   [NLVR2]: iter 44128 Ep: 16.35 loss 0.032 score 0.472 lr 1.01591e-06 
12/02/2021 22:06:54 - INFO - volta.train_utils -   [NLVR2]: iter 44168 Ep: 16.36 loss 0.033 score 0.476 lr 1.01179e-06 
12/02/2021 22:07:16 - INFO - volta.train_utils -   [NLVR2]: iter 44208 Ep: 16.38 loss 0.024 score 0.472 lr 1.00768e-06 
12/02/2021 22:07:38 - INFO - volta.train_utils -   [NLVR2]: iter 44248 Ep: 16.39 loss 0.032 score 0.473 lr 1.00356e-06 
12/02/2021 22:07:59 - INFO - volta.train_utils -   [NLVR2]: iter 44288 Ep: 16.41 loss 0.038 score 0.474 lr 9.99444e-07 
12/02/2021 22:08:20 - INFO - volta.train_utils -   [NLVR2]: iter 44328 Ep: 16.42 loss 0.031 score 0.473 lr 9.95327e-07 
12/02/2021 22:08:42 - INFO - volta.train_utils -   [NLVR2]: iter 44368 Ep: 16.44 loss 0.038 score 0.468 lr 9.91211e-07 
12/02/2021 22:09:04 - INFO - volta.train_utils -   [NLVR2]: iter 44408 Ep: 16.45 loss 0.032 score 0.475 lr 9.87094e-07 
12/02/2021 22:09:25 - INFO - volta.train_utils -   [NLVR2]: iter 44448 Ep: 16.47 loss 0.035 score 0.479 lr 9.82977e-07 
12/02/2021 22:09:47 - INFO - volta.train_utils -   [NLVR2]: iter 44488 Ep: 16.48 loss 0.032 score 0.476 lr 9.7886e-07 
12/02/2021 22:10:08 - INFO - volta.train_utils -   [NLVR2]: iter 44528 Ep: 16.50 loss 0.030 score 0.475 lr 9.74744e-07 
12/02/2021 22:10:30 - INFO - volta.train_utils -   [NLVR2]: iter 44568 Ep: 16.51 loss 0.032 score 0.475 lr 9.70627e-07 
12/02/2021 22:10:51 - INFO - volta.train_utils -   [NLVR2]: iter 44608 Ep: 16.53 loss 0.030 score 0.476 lr 9.6651e-07 
12/02/2021 22:11:13 - INFO - volta.train_utils -   [NLVR2]: iter 44648 Ep: 16.54 loss 0.035 score 0.473 lr 9.62393e-07 
12/02/2021 22:11:34 - INFO - volta.train_utils -   [NLVR2]: iter 44688 Ep: 16.56 loss 0.037 score 0.472 lr 9.58277e-07 
12/02/2021 22:11:56 - INFO - volta.train_utils -   [NLVR2]: iter 44728 Ep: 16.57 loss 0.028 score 0.477 lr 9.5416e-07 
12/02/2021 22:12:17 - INFO - volta.train_utils -   [NLVR2]: iter 44768 Ep: 16.59 loss 0.029 score 0.475 lr 9.50043e-07 
12/02/2021 22:12:39 - INFO - volta.train_utils -   [NLVR2]: iter 44808 Ep: 16.60 loss 0.030 score 0.476 lr 9.45926e-07 
12/02/2021 22:13:00 - INFO - volta.train_utils -   [NLVR2]: iter 44848 Ep: 16.62 loss 0.030 score 0.475 lr 9.4181e-07 
12/02/2021 22:13:22 - INFO - volta.train_utils -   [NLVR2]: iter 44888 Ep: 16.63 loss 0.025 score 0.481 lr 9.37693e-07 
12/02/2021 22:13:43 - INFO - volta.train_utils -   [NLVR2]: iter 44928 Ep: 16.65 loss 0.033 score 0.477 lr 9.33576e-07 
12/02/2021 22:14:05 - INFO - volta.train_utils -   [NLVR2]: iter 44968 Ep: 16.66 loss 0.023 score 0.479 lr 9.29459e-07 
12/02/2021 22:14:26 - INFO - volta.train_utils -   [NLVR2]: iter 45008 Ep: 16.68 loss 0.046 score 0.464 lr 9.25343e-07 
12/02/2021 22:14:48 - INFO - volta.train_utils -   [NLVR2]: iter 45048 Ep: 16.69 loss 0.030 score 0.471 lr 9.21226e-07 
12/02/2021 22:15:09 - INFO - volta.train_utils -   [NLVR2]: iter 45088 Ep: 16.71 loss 0.029 score 0.476 lr 9.17109e-07 
12/02/2021 22:15:31 - INFO - volta.train_utils -   [NLVR2]: iter 45128 Ep: 16.72 loss 0.021 score 0.483 lr 9.12992e-07 
12/02/2021 22:15:52 - INFO - volta.train_utils -   [NLVR2]: iter 45168 Ep: 16.74 loss 0.032 score 0.475 lr 9.08876e-07 
12/02/2021 22:16:14 - INFO - volta.train_utils -   [NLVR2]: iter 45208 Ep: 16.75 loss 0.044 score 0.469 lr 9.04759e-07 
12/02/2021 22:16:35 - INFO - volta.train_utils -   [NLVR2]: iter 45248 Ep: 16.76 loss 0.027 score 0.479 lr 9.00642e-07 
12/02/2021 22:16:57 - INFO - volta.train_utils -   [NLVR2]: iter 45288 Ep: 16.78 loss 0.033 score 0.475 lr 8.96525e-07 
12/02/2021 22:17:18 - INFO - volta.train_utils -   [NLVR2]: iter 45328 Ep: 16.79 loss 0.026 score 0.478 lr 8.92409e-07 
12/02/2021 22:17:40 - INFO - volta.train_utils -   [NLVR2]: iter 45368 Ep: 16.81 loss 0.028 score 0.473 lr 8.88292e-07 
12/02/2021 22:18:01 - INFO - volta.train_utils -   [NLVR2]: iter 45408 Ep: 16.82 loss 0.027 score 0.476 lr 8.84175e-07 
12/02/2021 22:18:23 - INFO - volta.train_utils -   [NLVR2]: iter 45448 Ep: 16.84 loss 0.023 score 0.479 lr 8.80058e-07 
12/02/2021 22:18:44 - INFO - volta.train_utils -   [NLVR2]: iter 45488 Ep: 16.85 loss 0.029 score 0.477 lr 8.75942e-07 
12/02/2021 22:19:06 - INFO - volta.train_utils -   [NLVR2]: iter 45528 Ep: 16.87 loss 0.028 score 0.475 lr 8.71825e-07 
12/02/2021 22:19:27 - INFO - volta.train_utils -   [NLVR2]: iter 45568 Ep: 16.88 loss 0.031 score 0.476 lr 8.67708e-07 
12/02/2021 22:19:49 - INFO - volta.train_utils -   [NLVR2]: iter 45608 Ep: 16.90 loss 0.027 score 0.477 lr 8.63591e-07 
12/02/2021 22:20:10 - INFO - volta.train_utils -   [NLVR2]: iter 45648 Ep: 16.91 loss 0.035 score 0.472 lr 8.59475e-07 
12/02/2021 22:20:32 - INFO - volta.train_utils -   [NLVR2]: iter 45688 Ep: 16.93 loss 0.029 score 0.471 lr 8.55358e-07 
12/02/2021 22:20:53 - INFO - volta.train_utils -   [NLVR2]: iter 45728 Ep: 16.94 loss 0.035 score 0.476 lr 8.51241e-07 
12/02/2021 22:21:15 - INFO - volta.train_utils -   [NLVR2]: iter 45768 Ep: 16.96 loss 0.033 score 0.471 lr 8.47124e-07 
12/02/2021 22:21:36 - INFO - volta.train_utils -   [NLVR2]: iter 45808 Ep: 16.97 loss 0.028 score 0.475 lr 8.43008e-07 
12/02/2021 22:21:58 - INFO - volta.train_utils -   [NLVR2]: iter 45848 Ep: 16.99 loss 0.029 score 0.477 lr 8.38891e-07 
12/02/2021 22:22:54 - INFO - volta.train_utils -   Eval task TASK12 on iteration 45866 
12/02/2021 22:22:54 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.271 score 71.388 
Epoch:  85%| | 17/20 [7:07:15<1:14:58, 1499.41s/it]12/02/2021 22:23:16 - INFO - volta.train_utils -   [NLVR2]: iter 45906 Ep: 17.01 loss 0.027 score 0.486 lr 8.33848e-07 
12/02/2021 22:23:38 - INFO - volta.train_utils -   [NLVR2]: iter 45946 Ep: 17.02 loss 0.029 score 0.477 lr 8.28805e-07 
12/02/2021 22:23:59 - INFO - volta.train_utils -   [NLVR2]: iter 45986 Ep: 17.04 loss 0.028 score 0.477 lr 8.24688e-07 
12/02/2021 22:24:21 - INFO - volta.train_utils -   [NLVR2]: iter 46026 Ep: 17.05 loss 0.027 score 0.477 lr 8.20571e-07 
12/02/2021 22:24:42 - INFO - volta.train_utils -   [NLVR2]: iter 46066 Ep: 17.07 loss 0.035 score 0.469 lr 8.16455e-07 
12/02/2021 22:25:03 - INFO - volta.train_utils -   [NLVR2]: iter 46106 Ep: 17.08 loss 0.027 score 0.475 lr 8.12338e-07 
12/02/2021 22:25:25 - INFO - volta.train_utils -   [NLVR2]: iter 46146 Ep: 17.10 loss 0.030 score 0.474 lr 8.08221e-07 
12/02/2021 22:25:47 - INFO - volta.train_utils -   [NLVR2]: iter 46186 Ep: 17.11 loss 0.027 score 0.475 lr 8.04104e-07 
12/02/2021 22:26:08 - INFO - volta.train_utils -   [NLVR2]: iter 46226 Ep: 17.13 loss 0.026 score 0.475 lr 7.99988e-07 
12/02/2021 22:26:30 - INFO - volta.train_utils -   [NLVR2]: iter 46266 Ep: 17.14 loss 0.028 score 0.470 lr 7.95871e-07 
12/02/2021 22:26:51 - INFO - volta.train_utils -   [NLVR2]: iter 46306 Ep: 17.16 loss 0.024 score 0.483 lr 7.91754e-07 
12/02/2021 22:27:13 - INFO - volta.train_utils -   [NLVR2]: iter 46346 Ep: 17.17 loss 0.028 score 0.475 lr 7.87637e-07 
12/02/2021 22:27:34 - INFO - volta.train_utils -   [NLVR2]: iter 46386 Ep: 17.19 loss 0.030 score 0.474 lr 7.83521e-07 
12/02/2021 22:27:56 - INFO - volta.train_utils -   [NLVR2]: iter 46426 Ep: 17.20 loss 0.026 score 0.480 lr 7.79404e-07 
12/02/2021 22:28:17 - INFO - volta.train_utils -   [NLVR2]: iter 46466 Ep: 17.22 loss 0.024 score 0.479 lr 7.75287e-07 
12/02/2021 22:28:38 - INFO - volta.train_utils -   [NLVR2]: iter 46506 Ep: 17.23 loss 0.027 score 0.477 lr 7.7117e-07 
12/02/2021 22:29:00 - INFO - volta.train_utils -   [NLVR2]: iter 46546 Ep: 17.25 loss 0.033 score 0.475 lr 7.67054e-07 
12/02/2021 22:29:22 - INFO - volta.train_utils -   [NLVR2]: iter 46586 Ep: 17.26 loss 0.035 score 0.472 lr 7.62937e-07 
12/02/2021 22:29:43 - INFO - volta.train_utils -   [NLVR2]: iter 46626 Ep: 17.28 loss 0.026 score 0.476 lr 7.5882e-07 
12/02/2021 22:30:05 - INFO - volta.train_utils -   [NLVR2]: iter 46666 Ep: 17.29 loss 0.031 score 0.479 lr 7.54703e-07 
12/02/2021 22:30:26 - INFO - volta.train_utils -   [NLVR2]: iter 46706 Ep: 17.30 loss 0.028 score 0.476 lr 7.50587e-07 
12/02/2021 22:30:48 - INFO - volta.train_utils -   [NLVR2]: iter 46746 Ep: 17.32 loss 0.030 score 0.475 lr 7.4647e-07 
12/02/2021 22:31:09 - INFO - volta.train_utils -   [NLVR2]: iter 46786 Ep: 17.33 loss 0.025 score 0.478 lr 7.42353e-07 
12/02/2021 22:31:31 - INFO - volta.train_utils -   [NLVR2]: iter 46826 Ep: 17.35 loss 0.022 score 0.481 lr 7.38236e-07 
12/02/2021 22:31:52 - INFO - volta.train_utils -   [NLVR2]: iter 46866 Ep: 17.36 loss 0.028 score 0.477 lr 7.3412e-07 
12/02/2021 22:32:14 - INFO - volta.train_utils -   [NLVR2]: iter 46906 Ep: 17.38 loss 0.031 score 0.472 lr 7.30003e-07 
12/02/2021 22:32:35 - INFO - volta.train_utils -   [NLVR2]: iter 46946 Ep: 17.39 loss 0.030 score 0.473 lr 7.25886e-07 
12/02/2021 22:32:57 - INFO - volta.train_utils -   [NLVR2]: iter 46986 Ep: 17.41 loss 0.032 score 0.475 lr 7.21769e-07 
12/02/2021 22:33:18 - INFO - volta.train_utils -   [NLVR2]: iter 47026 Ep: 17.42 loss 0.026 score 0.479 lr 7.17653e-07 
12/02/2021 22:33:40 - INFO - volta.train_utils -   [NLVR2]: iter 47066 Ep: 17.44 loss 0.036 score 0.473 lr 7.13536e-07 
12/02/2021 22:34:01 - INFO - volta.train_utils -   [NLVR2]: iter 47106 Ep: 17.45 loss 0.031 score 0.478 lr 7.09419e-07 
12/02/2021 22:34:23 - INFO - volta.train_utils -   [NLVR2]: iter 47146 Ep: 17.47 loss 0.028 score 0.473 lr 7.05302e-07 
12/02/2021 22:34:44 - INFO - volta.train_utils -   [NLVR2]: iter 47186 Ep: 17.48 loss 0.029 score 0.473 lr 7.01186e-07 
12/02/2021 22:35:06 - INFO - volta.train_utils -   [NLVR2]: iter 47226 Ep: 17.50 loss 0.027 score 0.475 lr 6.97069e-07 
12/02/2021 22:35:27 - INFO - volta.train_utils -   [NLVR2]: iter 47266 Ep: 17.51 loss 0.028 score 0.474 lr 6.92952e-07 
12/02/2021 22:35:49 - INFO - volta.train_utils -   [NLVR2]: iter 47306 Ep: 17.53 loss 0.032 score 0.480 lr 6.88835e-07 
12/02/2021 22:36:10 - INFO - volta.train_utils -   [NLVR2]: iter 47346 Ep: 17.54 loss 0.022 score 0.484 lr 6.84719e-07 
12/02/2021 22:36:32 - INFO - volta.train_utils -   [NLVR2]: iter 47386 Ep: 17.56 loss 0.030 score 0.475 lr 6.80602e-07 
12/02/2021 22:36:53 - INFO - volta.train_utils -   [NLVR2]: iter 47426 Ep: 17.57 loss 0.025 score 0.475 lr 6.76485e-07 
12/02/2021 22:37:15 - INFO - volta.train_utils -   [NLVR2]: iter 47466 Ep: 17.59 loss 0.028 score 0.477 lr 6.72368e-07 
12/02/2021 22:37:36 - INFO - volta.train_utils -   [NLVR2]: iter 47506 Ep: 17.60 loss 0.029 score 0.480 lr 6.68252e-07 
12/02/2021 22:37:58 - INFO - volta.train_utils -   [NLVR2]: iter 47546 Ep: 17.62 loss 0.028 score 0.477 lr 6.64135e-07 
12/02/2021 22:38:19 - INFO - volta.train_utils -   [NLVR2]: iter 47586 Ep: 17.63 loss 0.031 score 0.473 lr 6.60018e-07 
12/02/2021 22:38:41 - INFO - volta.train_utils -   [NLVR2]: iter 47626 Ep: 17.65 loss 0.022 score 0.479 lr 6.55901e-07 
12/02/2021 22:39:02 - INFO - volta.train_utils -   [NLVR2]: iter 47666 Ep: 17.66 loss 0.030 score 0.474 lr 6.51785e-07 
12/02/2021 22:39:24 - INFO - volta.train_utils -   [NLVR2]: iter 47706 Ep: 17.68 loss 0.031 score 0.477 lr 6.47668e-07 
12/02/2021 22:39:45 - INFO - volta.train_utils -   [NLVR2]: iter 47746 Ep: 17.69 loss 0.028 score 0.479 lr 6.43551e-07 
12/02/2021 22:40:07 - INFO - volta.train_utils -   [NLVR2]: iter 47786 Ep: 17.71 loss 0.023 score 0.478 lr 6.39434e-07 
12/02/2021 22:40:28 - INFO - volta.train_utils -   [NLVR2]: iter 47826 Ep: 17.72 loss 0.027 score 0.481 lr 6.35318e-07 
12/02/2021 22:40:50 - INFO - volta.train_utils -   [NLVR2]: iter 47866 Ep: 17.73 loss 0.031 score 0.479 lr 6.31201e-07 
12/02/2021 22:41:11 - INFO - volta.train_utils -   [NLVR2]: iter 47906 Ep: 17.75 loss 0.024 score 0.479 lr 6.27084e-07 
12/02/2021 22:41:33 - INFO - volta.train_utils -   [NLVR2]: iter 47946 Ep: 17.76 loss 0.033 score 0.477 lr 6.22967e-07 
12/02/2021 22:41:54 - INFO - volta.train_utils -   [NLVR2]: iter 47986 Ep: 17.78 loss 0.032 score 0.476 lr 6.18851e-07 
12/02/2021 22:42:16 - INFO - volta.train_utils -   [NLVR2]: iter 48026 Ep: 17.79 loss 0.027 score 0.480 lr 6.14734e-07 
12/02/2021 22:42:37 - INFO - volta.train_utils -   [NLVR2]: iter 48066 Ep: 17.81 loss 0.026 score 0.478 lr 6.10617e-07 
12/02/2021 22:42:59 - INFO - volta.train_utils -   [NLVR2]: iter 48106 Ep: 17.82 loss 0.024 score 0.481 lr 6.065e-07 
12/02/2021 22:43:20 - INFO - volta.train_utils -   [NLVR2]: iter 48146 Ep: 17.84 loss 0.034 score 0.470 lr 6.02384e-07 
12/02/2021 22:43:42 - INFO - volta.train_utils -   [NLVR2]: iter 48186 Ep: 17.85 loss 0.028 score 0.477 lr 5.98267e-07 
12/02/2021 22:44:03 - INFO - volta.train_utils -   [NLVR2]: iter 48226 Ep: 17.87 loss 0.023 score 0.485 lr 5.9415e-07 
12/02/2021 22:44:25 - INFO - volta.train_utils -   [NLVR2]: iter 48266 Ep: 17.88 loss 0.025 score 0.482 lr 5.90033e-07 
12/02/2021 22:44:46 - INFO - volta.train_utils -   [NLVR2]: iter 48306 Ep: 17.90 loss 0.025 score 0.480 lr 5.85917e-07 
12/02/2021 22:45:08 - INFO - volta.train_utils -   [NLVR2]: iter 48346 Ep: 17.91 loss 0.025 score 0.482 lr 5.818e-07 
12/02/2021 22:45:29 - INFO - volta.train_utils -   [NLVR2]: iter 48386 Ep: 17.93 loss 0.027 score 0.477 lr 5.77683e-07 
12/02/2021 22:45:51 - INFO - volta.train_utils -   [NLVR2]: iter 48426 Ep: 17.94 loss 0.034 score 0.477 lr 5.73566e-07 
12/02/2021 22:46:12 - INFO - volta.train_utils -   [NLVR2]: iter 48466 Ep: 17.96 loss 0.032 score 0.476 lr 5.6945e-07 
12/02/2021 22:46:34 - INFO - volta.train_utils -   [NLVR2]: iter 48506 Ep: 17.97 loss 0.022 score 0.486 lr 5.65333e-07 
12/02/2021 22:46:55 - INFO - volta.train_utils -   [NLVR2]: iter 48546 Ep: 17.99 loss 0.035 score 0.475 lr 5.61216e-07 
12/02/2021 22:47:51 - INFO - volta.train_utils -   Eval task TASK12 on iteration 48564 
12/02/2021 22:47:51 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.333 score 70.929 
Epoch:  90%| | 18/20 [7:32:12<49:57, 1498.66s/it]  12/02/2021 22:48:13 - INFO - volta.train_utils -   [NLVR2]: iter 48604 Ep: 18.01 loss 0.027 score 0.488 lr 5.56173e-07 
12/02/2021 22:48:34 - INFO - volta.train_utils -   [NLVR2]: iter 48644 Ep: 18.02 loss 0.030 score 0.479 lr 5.5113e-07 
12/02/2021 22:48:56 - INFO - volta.train_utils -   [NLVR2]: iter 48684 Ep: 18.04 loss 0.024 score 0.477 lr 5.47013e-07 
12/02/2021 22:49:17 - INFO - volta.train_utils -   [NLVR2]: iter 48724 Ep: 18.05 loss 0.022 score 0.479 lr 5.42897e-07 
12/02/2021 22:49:39 - INFO - volta.train_utils -   [NLVR2]: iter 48764 Ep: 18.07 loss 0.029 score 0.479 lr 5.3878e-07 
12/02/2021 22:50:00 - INFO - volta.train_utils -   [NLVR2]: iter 48804 Ep: 18.08 loss 0.026 score 0.479 lr 5.34663e-07 
12/02/2021 22:50:22 - INFO - volta.train_utils -   [NLVR2]: iter 48844 Ep: 18.10 loss 0.027 score 0.479 lr 5.30546e-07 
12/02/2021 22:50:43 - INFO - volta.train_utils -   [NLVR2]: iter 48884 Ep: 18.11 loss 0.023 score 0.477 lr 5.2643e-07 
12/02/2021 22:51:05 - INFO - volta.train_utils -   [NLVR2]: iter 48924 Ep: 18.13 loss 0.023 score 0.481 lr 5.22313e-07 
12/02/2021 22:51:26 - INFO - volta.train_utils -   [NLVR2]: iter 48964 Ep: 18.14 loss 0.031 score 0.479 lr 5.18196e-07 
12/02/2021 22:51:47 - INFO - volta.train_utils -   [NLVR2]: iter 49004 Ep: 18.16 loss 0.026 score 0.476 lr 5.14079e-07 
12/02/2021 22:52:09 - INFO - volta.train_utils -   [NLVR2]: iter 49044 Ep: 18.17 loss 0.024 score 0.479 lr 5.09963e-07 
12/02/2021 22:52:30 - INFO - volta.train_utils -   [NLVR2]: iter 49084 Ep: 18.19 loss 0.030 score 0.476 lr 5.05846e-07 
12/02/2021 22:52:52 - INFO - volta.train_utils -   [NLVR2]: iter 49124 Ep: 18.20 loss 0.031 score 0.475 lr 5.01729e-07 
12/02/2021 22:53:13 - INFO - volta.train_utils -   [NLVR2]: iter 49164 Ep: 18.22 loss 0.025 score 0.479 lr 4.97612e-07 
12/02/2021 22:53:34 - INFO - volta.train_utils -   [NLVR2]: iter 49204 Ep: 18.23 loss 0.026 score 0.478 lr 4.93496e-07 
12/02/2021 22:53:56 - INFO - volta.train_utils -   [NLVR2]: iter 49244 Ep: 18.25 loss 0.031 score 0.479 lr 4.89379e-07 
12/02/2021 22:54:18 - INFO - volta.train_utils -   [NLVR2]: iter 49284 Ep: 18.26 loss 0.028 score 0.475 lr 4.85262e-07 
12/02/2021 22:54:39 - INFO - volta.train_utils -   [NLVR2]: iter 49324 Ep: 18.27 loss 0.026 score 0.479 lr 4.81145e-07 
12/02/2021 22:55:00 - INFO - volta.train_utils -   [NLVR2]: iter 49364 Ep: 18.29 loss 0.022 score 0.482 lr 4.77029e-07 
12/02/2021 22:55:22 - INFO - volta.train_utils -   [NLVR2]: iter 49404 Ep: 18.30 loss 0.025 score 0.478 lr 4.72912e-07 
12/02/2021 22:55:44 - INFO - volta.train_utils -   [NLVR2]: iter 49444 Ep: 18.32 loss 0.025 score 0.476 lr 4.68795e-07 
12/02/2021 22:56:05 - INFO - volta.train_utils -   [NLVR2]: iter 49484 Ep: 18.33 loss 0.022 score 0.483 lr 4.64678e-07 
12/02/2021 22:56:27 - INFO - volta.train_utils -   [NLVR2]: iter 49524 Ep: 18.35 loss 0.027 score 0.479 lr 4.60562e-07 
12/02/2021 22:56:48 - INFO - volta.train_utils -   [NLVR2]: iter 49564 Ep: 18.36 loss 0.028 score 0.475 lr 4.56445e-07 
12/02/2021 22:57:09 - INFO - volta.train_utils -   [NLVR2]: iter 49604 Ep: 18.38 loss 0.022 score 0.479 lr 4.52328e-07 
12/02/2021 22:57:31 - INFO - volta.train_utils -   [NLVR2]: iter 49644 Ep: 18.39 loss 0.028 score 0.477 lr 4.48211e-07 
12/02/2021 22:57:53 - INFO - volta.train_utils -   [NLVR2]: iter 49684 Ep: 18.41 loss 0.027 score 0.475 lr 4.44095e-07 
12/02/2021 22:58:14 - INFO - volta.train_utils -   [NLVR2]: iter 49724 Ep: 18.42 loss 0.023 score 0.480 lr 4.39978e-07 
12/02/2021 22:58:36 - INFO - volta.train_utils -   [NLVR2]: iter 49764 Ep: 18.44 loss 0.022 score 0.483 lr 4.35861e-07 
12/02/2021 22:58:57 - INFO - volta.train_utils -   [NLVR2]: iter 49804 Ep: 18.45 loss 0.029 score 0.477 lr 4.31744e-07 
12/02/2021 22:59:19 - INFO - volta.train_utils -   [NLVR2]: iter 49844 Ep: 18.47 loss 0.024 score 0.481 lr 4.27628e-07 
12/02/2021 22:59:40 - INFO - volta.train_utils -   [NLVR2]: iter 49884 Ep: 18.48 loss 0.034 score 0.475 lr 4.23511e-07 
12/02/2021 23:00:01 - INFO - volta.train_utils -   [NLVR2]: iter 49924 Ep: 18.50 loss 0.030 score 0.477 lr 4.19394e-07 
12/02/2021 23:00:23 - INFO - volta.train_utils -   [NLVR2]: iter 49964 Ep: 18.51 loss 0.031 score 0.478 lr 4.15277e-07 
12/02/2021 23:00:44 - INFO - volta.train_utils -   [NLVR2]: iter 50004 Ep: 18.53 loss 0.024 score 0.480 lr 4.11161e-07 
12/02/2021 23:01:05 - INFO - volta.train_utils -   [NLVR2]: iter 50044 Ep: 18.54 loss 0.029 score 0.477 lr 4.07044e-07 
12/02/2021 23:01:27 - INFO - volta.train_utils -   [NLVR2]: iter 50084 Ep: 18.56 loss 0.021 score 0.483 lr 4.02927e-07 
12/02/2021 23:01:48 - INFO - volta.train_utils -   [NLVR2]: iter 50124 Ep: 18.57 loss 0.028 score 0.479 lr 3.9881e-07 
12/02/2021 23:02:10 - INFO - volta.train_utils -   [NLVR2]: iter 50164 Ep: 18.59 loss 0.023 score 0.480 lr 3.94694e-07 
12/02/2021 23:02:31 - INFO - volta.train_utils -   [NLVR2]: iter 50204 Ep: 18.60 loss 0.028 score 0.480 lr 3.90577e-07 
12/02/2021 23:02:53 - INFO - volta.train_utils -   [NLVR2]: iter 50244 Ep: 18.62 loss 0.029 score 0.479 lr 3.8646e-07 
12/02/2021 23:03:14 - INFO - volta.train_utils -   [NLVR2]: iter 50284 Ep: 18.63 loss 0.023 score 0.480 lr 3.82343e-07 
12/02/2021 23:03:36 - INFO - volta.train_utils -   [NLVR2]: iter 50324 Ep: 18.65 loss 0.025 score 0.477 lr 3.78227e-07 
12/02/2021 23:03:57 - INFO - volta.train_utils -   [NLVR2]: iter 50364 Ep: 18.66 loss 0.025 score 0.481 lr 3.7411e-07 
12/02/2021 23:04:19 - INFO - volta.train_utils -   [NLVR2]: iter 50404 Ep: 18.68 loss 0.018 score 0.485 lr 3.69993e-07 
12/02/2021 23:04:40 - INFO - volta.train_utils -   [NLVR2]: iter 50444 Ep: 18.69 loss 0.031 score 0.475 lr 3.65876e-07 
12/02/2021 23:05:01 - INFO - volta.train_utils -   [NLVR2]: iter 50484 Ep: 18.70 loss 0.024 score 0.475 lr 3.61759e-07 
12/02/2021 23:05:23 - INFO - volta.train_utils -   [NLVR2]: iter 50524 Ep: 18.72 loss 0.031 score 0.475 lr 3.57643e-07 
12/02/2021 23:05:44 - INFO - volta.train_utils -   [NLVR2]: iter 50564 Ep: 18.73 loss 0.024 score 0.478 lr 3.53526e-07 
12/02/2021 23:06:06 - INFO - volta.train_utils -   [NLVR2]: iter 50604 Ep: 18.75 loss 0.026 score 0.475 lr 3.49409e-07 
12/02/2021 23:06:27 - INFO - volta.train_utils -   [NLVR2]: iter 50644 Ep: 18.76 loss 0.024 score 0.480 lr 3.45292e-07 
12/02/2021 23:06:48 - INFO - volta.train_utils -   [NLVR2]: iter 50684 Ep: 18.78 loss 0.026 score 0.479 lr 3.41176e-07 
12/02/2021 23:07:10 - INFO - volta.train_utils -   [NLVR2]: iter 50724 Ep: 18.79 loss 0.020 score 0.480 lr 3.37059e-07 
12/02/2021 23:07:31 - INFO - volta.train_utils -   [NLVR2]: iter 50764 Ep: 18.81 loss 0.038 score 0.478 lr 3.32942e-07 
12/02/2021 23:07:53 - INFO - volta.train_utils -   [NLVR2]: iter 50804 Ep: 18.82 loss 0.027 score 0.480 lr 3.28825e-07 
12/02/2021 23:08:14 - INFO - volta.train_utils -   [NLVR2]: iter 50844 Ep: 18.84 loss 0.029 score 0.480 lr 3.24709e-07 
12/02/2021 23:08:35 - INFO - volta.train_utils -   [NLVR2]: iter 50884 Ep: 18.85 loss 0.033 score 0.479 lr 3.20592e-07 
12/02/2021 23:08:57 - INFO - volta.train_utils -   [NLVR2]: iter 50924 Ep: 18.87 loss 0.019 score 0.482 lr 3.16475e-07 
12/02/2021 23:09:18 - INFO - volta.train_utils -   [NLVR2]: iter 50964 Ep: 18.88 loss 0.025 score 0.480 lr 3.12358e-07 
12/02/2021 23:09:40 - INFO - volta.train_utils -   [NLVR2]: iter 51004 Ep: 18.90 loss 0.031 score 0.476 lr 3.08242e-07 
12/02/2021 23:10:01 - INFO - volta.train_utils -   [NLVR2]: iter 51044 Ep: 18.91 loss 0.028 score 0.481 lr 3.04125e-07 
12/02/2021 23:10:23 - INFO - volta.train_utils -   [NLVR2]: iter 51084 Ep: 18.93 loss 0.028 score 0.479 lr 3.00008e-07 
12/02/2021 23:10:44 - INFO - volta.train_utils -   [NLVR2]: iter 51124 Ep: 18.94 loss 0.027 score 0.480 lr 2.95891e-07 
12/02/2021 23:11:05 - INFO - volta.train_utils -   [NLVR2]: iter 51164 Ep: 18.96 loss 0.024 score 0.478 lr 2.91775e-07 
12/02/2021 23:11:27 - INFO - volta.train_utils -   [NLVR2]: iter 51204 Ep: 18.97 loss 0.025 score 0.479 lr 2.87658e-07 
12/02/2021 23:11:48 - INFO - volta.train_utils -   [NLVR2]: iter 51244 Ep: 18.99 loss 0.025 score 0.478 lr 2.83541e-07 
12/02/2021 23:12:45 - INFO - volta.train_utils -   Eval task TASK12 on iteration 51262 
12/02/2021 23:12:45 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.357 score 70.900 
Epoch:  95%|| 19/20 [7:57:06<24:57, 1497.40s/it]12/02/2021 23:13:07 - INFO - volta.train_utils -   [NLVR2]: iter 51302 Ep: 19.01 loss 0.023 score 0.491 lr 2.78498e-07 
12/02/2021 23:13:29 - INFO - volta.train_utils -   [NLVR2]: iter 51342 Ep: 19.02 loss 0.020 score 0.482 lr 2.73455e-07 
12/02/2021 23:13:50 - INFO - volta.train_utils -   [NLVR2]: iter 51382 Ep: 19.04 loss 0.026 score 0.476 lr 2.69338e-07 
12/02/2021 23:14:12 - INFO - volta.train_utils -   [NLVR2]: iter 51422 Ep: 19.05 loss 0.028 score 0.477 lr 2.65222e-07 
12/02/2021 23:14:33 - INFO - volta.train_utils -   [NLVR2]: iter 51462 Ep: 19.07 loss 0.028 score 0.478 lr 2.61105e-07 
12/02/2021 23:14:54 - INFO - volta.train_utils -   [NLVR2]: iter 51502 Ep: 19.08 loss 0.025 score 0.482 lr 2.56988e-07 
12/02/2021 23:15:16 - INFO - volta.train_utils -   [NLVR2]: iter 51542 Ep: 19.10 loss 0.027 score 0.480 lr 2.52871e-07 
12/02/2021 23:15:37 - INFO - volta.train_utils -   [NLVR2]: iter 51582 Ep: 19.11 loss 0.021 score 0.480 lr 2.48755e-07 
12/02/2021 23:15:59 - INFO - volta.train_utils -   [NLVR2]: iter 51622 Ep: 19.13 loss 0.018 score 0.480 lr 2.44638e-07 
12/02/2021 23:16:20 - INFO - volta.train_utils -   [NLVR2]: iter 51662 Ep: 19.14 loss 0.027 score 0.480 lr 2.40521e-07 
12/02/2021 23:16:42 - INFO - volta.train_utils -   [NLVR2]: iter 51702 Ep: 19.16 loss 0.027 score 0.480 lr 2.36404e-07 
12/02/2021 23:17:03 - INFO - volta.train_utils -   [NLVR2]: iter 51742 Ep: 19.17 loss 0.027 score 0.475 lr 2.32288e-07 
12/02/2021 23:17:25 - INFO - volta.train_utils -   [NLVR2]: iter 51782 Ep: 19.19 loss 0.026 score 0.475 lr 2.28171e-07 
12/02/2021 23:17:46 - INFO - volta.train_utils -   [NLVR2]: iter 51822 Ep: 19.20 loss 0.027 score 0.481 lr 2.24054e-07 
12/02/2021 23:18:08 - INFO - volta.train_utils -   [NLVR2]: iter 51862 Ep: 19.22 loss 0.030 score 0.473 lr 2.19937e-07 
12/02/2021 23:18:29 - INFO - volta.train_utils -   [NLVR2]: iter 51902 Ep: 19.23 loss 0.032 score 0.474 lr 2.15821e-07 
12/02/2021 23:18:51 - INFO - volta.train_utils -   [NLVR2]: iter 51942 Ep: 19.24 loss 0.030 score 0.480 lr 2.11704e-07 
12/02/2021 23:19:12 - INFO - volta.train_utils -   [NLVR2]: iter 51982 Ep: 19.26 loss 0.018 score 0.481 lr 2.07587e-07 
12/02/2021 23:19:33 - INFO - volta.train_utils -   [NLVR2]: iter 52022 Ep: 19.27 loss 0.026 score 0.479 lr 2.0347e-07 
12/02/2021 23:19:55 - INFO - volta.train_utils -   [NLVR2]: iter 52062 Ep: 19.29 loss 0.028 score 0.481 lr 1.99354e-07 
12/02/2021 23:20:16 - INFO - volta.train_utils -   [NLVR2]: iter 52102 Ep: 19.30 loss 0.019 score 0.482 lr 1.95237e-07 
12/02/2021 23:20:38 - INFO - volta.train_utils -   [NLVR2]: iter 52142 Ep: 19.32 loss 0.020 score 0.480 lr 1.9112e-07 
12/02/2021 23:21:00 - INFO - volta.train_utils -   [NLVR2]: iter 52182 Ep: 19.33 loss 0.025 score 0.482 lr 1.87003e-07 
12/02/2021 23:21:21 - INFO - volta.train_utils -   [NLVR2]: iter 52222 Ep: 19.35 loss 0.021 score 0.480 lr 1.82887e-07 
12/02/2021 23:21:43 - INFO - volta.train_utils -   [NLVR2]: iter 52262 Ep: 19.36 loss 0.026 score 0.476 lr 1.7877e-07 
12/02/2021 23:22:04 - INFO - volta.train_utils -   [NLVR2]: iter 52302 Ep: 19.38 loss 0.027 score 0.475 lr 1.74653e-07 
12/02/2021 23:22:25 - INFO - volta.train_utils -   [NLVR2]: iter 52342 Ep: 19.39 loss 0.023 score 0.480 lr 1.70536e-07 
12/02/2021 23:22:47 - INFO - volta.train_utils -   [NLVR2]: iter 52382 Ep: 19.41 loss 0.030 score 0.480 lr 1.6642e-07 
12/02/2021 23:23:08 - INFO - volta.train_utils -   [NLVR2]: iter 52422 Ep: 19.42 loss 0.024 score 0.480 lr 1.62303e-07 
12/02/2021 23:23:30 - INFO - volta.train_utils -   [NLVR2]: iter 52462 Ep: 19.44 loss 0.024 score 0.479 lr 1.58186e-07 
12/02/2021 23:23:51 - INFO - volta.train_utils -   [NLVR2]: iter 52502 Ep: 19.45 loss 0.021 score 0.480 lr 1.54069e-07 
12/02/2021 23:24:13 - INFO - volta.train_utils -   [NLVR2]: iter 52542 Ep: 19.47 loss 0.025 score 0.482 lr 1.49953e-07 
12/02/2021 23:24:34 - INFO - volta.train_utils -   [NLVR2]: iter 52582 Ep: 19.48 loss 0.019 score 0.479 lr 1.45836e-07 
12/02/2021 23:24:56 - INFO - volta.train_utils -   [NLVR2]: iter 52622 Ep: 19.50 loss 0.025 score 0.478 lr 1.41719e-07 
12/02/2021 23:25:17 - INFO - volta.train_utils -   [NLVR2]: iter 52662 Ep: 19.51 loss 0.025 score 0.478 lr 1.37602e-07 
12/02/2021 23:25:39 - INFO - volta.train_utils -   [NLVR2]: iter 52702 Ep: 19.53 loss 0.031 score 0.475 lr 1.33486e-07 
12/02/2021 23:26:00 - INFO - volta.train_utils -   [NLVR2]: iter 52742 Ep: 19.54 loss 0.018 score 0.484 lr 1.29369e-07 
12/02/2021 23:26:22 - INFO - volta.train_utils -   [NLVR2]: iter 52782 Ep: 19.56 loss 0.023 score 0.477 lr 1.25252e-07 
12/02/2021 23:26:43 - INFO - volta.train_utils -   [NLVR2]: iter 52822 Ep: 19.57 loss 0.017 score 0.483 lr 1.21135e-07 
12/02/2021 23:27:04 - INFO - volta.train_utils -   [NLVR2]: iter 52862 Ep: 19.59 loss 0.023 score 0.480 lr 1.17019e-07 
12/02/2021 23:27:26 - INFO - volta.train_utils -   [NLVR2]: iter 52902 Ep: 19.60 loss 0.024 score 0.477 lr 1.12902e-07 
12/02/2021 23:27:47 - INFO - volta.train_utils -   [NLVR2]: iter 52942 Ep: 19.62 loss 0.025 score 0.482 lr 1.08785e-07 
12/02/2021 23:28:09 - INFO - volta.train_utils -   [NLVR2]: iter 52982 Ep: 19.63 loss 0.030 score 0.478 lr 1.04668e-07 
12/02/2021 23:28:30 - INFO - volta.train_utils -   [NLVR2]: iter 53022 Ep: 19.65 loss 0.025 score 0.478 lr 1.00552e-07 
12/02/2021 23:28:52 - INFO - volta.train_utils -   [NLVR2]: iter 53062 Ep: 19.66 loss 0.022 score 0.479 lr 9.64349e-08 
12/02/2021 23:29:13 - INFO - volta.train_utils -   [NLVR2]: iter 53102 Ep: 19.67 loss 0.026 score 0.481 lr 9.23181e-08 
12/02/2021 23:29:35 - INFO - volta.train_utils -   [NLVR2]: iter 53142 Ep: 19.69 loss 0.036 score 0.477 lr 8.82014e-08 
12/02/2021 23:29:56 - INFO - volta.train_utils -   [NLVR2]: iter 53182 Ep: 19.70 loss 0.024 score 0.480 lr 8.40846e-08 
12/02/2021 23:30:18 - INFO - volta.train_utils -   [NLVR2]: iter 53222 Ep: 19.72 loss 0.022 score 0.481 lr 7.99679e-08 
12/02/2021 23:30:39 - INFO - volta.train_utils -   [NLVR2]: iter 53262 Ep: 19.73 loss 0.027 score 0.482 lr 7.58511e-08 
12/02/2021 23:31:01 - INFO - volta.train_utils -   [NLVR2]: iter 53302 Ep: 19.75 loss 0.024 score 0.480 lr 7.17344e-08 
12/02/2021 23:31:22 - INFO - volta.train_utils -   [NLVR2]: iter 53342 Ep: 19.76 loss 0.022 score 0.479 lr 6.76176e-08 
12/02/2021 23:31:44 - INFO - volta.train_utils -   [NLVR2]: iter 53382 Ep: 19.78 loss 0.021 score 0.482 lr 6.35009e-08 
12/02/2021 23:32:05 - INFO - volta.train_utils -   [NLVR2]: iter 53422 Ep: 19.79 loss 0.030 score 0.479 lr 5.93841e-08 
12/02/2021 23:32:27 - INFO - volta.train_utils -   [NLVR2]: iter 53462 Ep: 19.81 loss 0.020 score 0.487 lr 5.52674e-08 
12/02/2021 23:32:48 - INFO - volta.train_utils -   [NLVR2]: iter 53502 Ep: 19.82 loss 0.020 score 0.479 lr 5.11506e-08 
12/02/2021 23:33:10 - INFO - volta.train_utils -   [NLVR2]: iter 53542 Ep: 19.84 loss 0.022 score 0.484 lr 4.70339e-08 
12/02/2021 23:33:31 - INFO - volta.train_utils -   [NLVR2]: iter 53582 Ep: 19.85 loss 0.025 score 0.481 lr 4.29171e-08 
12/02/2021 23:33:53 - INFO - volta.train_utils -   [NLVR2]: iter 53622 Ep: 19.87 loss 0.024 score 0.484 lr 3.88004e-08 
12/02/2021 23:34:14 - INFO - volta.train_utils -   [NLVR2]: iter 53662 Ep: 19.88 loss 0.021 score 0.476 lr 3.46836e-08 
12/02/2021 23:34:36 - INFO - volta.train_utils -   [NLVR2]: iter 53702 Ep: 19.90 loss 0.023 score 0.479 lr 3.05669e-08 
12/02/2021 23:34:57 - INFO - volta.train_utils -   [NLVR2]: iter 53742 Ep: 19.91 loss 0.023 score 0.482 lr 2.64501e-08 
12/02/2021 23:35:18 - INFO - volta.train_utils -   [NLVR2]: iter 53782 Ep: 19.93 loss 0.023 score 0.482 lr 2.23334e-08 
12/02/2021 23:35:40 - INFO - volta.train_utils -   [NLVR2]: iter 53822 Ep: 19.94 loss 0.031 score 0.478 lr 1.82166e-08 
12/02/2021 23:36:01 - INFO - volta.train_utils -   [NLVR2]: iter 53862 Ep: 19.96 loss 0.024 score 0.482 lr 1.40999e-08 
12/02/2021 23:36:23 - INFO - volta.train_utils -   [NLVR2]: iter 53902 Ep: 19.97 loss 0.022 score 0.479 lr 9.98312e-09 
12/02/2021 23:36:44 - INFO - volta.train_utils -   [NLVR2]: iter 53942 Ep: 19.99 loss 0.018 score 0.482 lr 5.86637e-09 
12/02/2021 23:37:41 - INFO - volta.train_utils -   Eval task TASK12 on iteration 53960 
12/02/2021 23:37:41 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.369 score 71.029 
Epoch: 100%|| 20/20 [8:22:02<00:00, 1496.90s/it]
